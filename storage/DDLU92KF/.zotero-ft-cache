用于 RoboMaster 比赛的自动瞄准系统
1
1 绪论
1.1 自动瞄准系统的研究背景及意义
RoboMaster 比赛是由大疆创新发起的全国大学生机器人大赛旗下的赛事之一,是专
为全球科技爱好者打造的机器人竞技与学术交流平台。自 2013 年创办至今,始终秉承
“为青春赋予荣耀,让思考拥有力量”的理念,旨在通过机器人竞技和学术交流,激发
青年学生的创新精神和实践能力,推动机器人技术的发展和应用。RoboMaster 比赛分为
超级对抗赛和高校联盟赛两个阶段。超级对抗赛是 RoboMaster 比赛的高水平竞技阶段,
旨在考察参赛队员对理工学科的综合应用与工程实践能力。高校联盟赛是 RoboMaster 比
赛的基础竞技阶段,旨在为广大机器人爱好者提供一个展示自己、提升自己、交流学习
的平台。RoboMaster 比赛已经成为了国内最具影响力和最具参与度的机器人竞技赛事之
一,也是国内最具代表性的机器人品牌之一。
在 RoboMaster 比赛中,参赛队伍需要设计制造具备自主辨识、自主控制及自主攻击
的机器人,其中自动瞄准系统是其中一个非常重要的子系统, 它可以帮助机器人在比赛中
更好地识别和瞄准目标。在 RoboMaster 比赛中,规则要求机器人需要精准命中敌方机器
人身上的四块装甲板才能视为有效击打,而自动瞄准系统的目标是让机器人能够自动锁
定敌方机器人的装甲板并精确打击目标,从而提高比赛胜率。
图 1.1 RoboMaster 比赛机器人示意图
过去几年来,随着计算机技术、机器学习技术的发展以及传感器、计算设备成本的


用于 RoboMaster 比赛的自动瞄准系统
2
降低,RoboMaster 比赛自动瞄准系统的研究也得到了迅速发展。各种基于计算机视觉、
深度学习等方法的自动瞄准系统被提出,并在比赛中取得了不错的成绩。同时自动瞄准
系统的研究有助于提高机器人的智能化水平,使机器人能够更好地适应复杂多变的环境,
更好地完成任务,它可以通过图像处理和目标检测等技术实现对目标的识别和定位,并
通过控制机器人的运动实现对目标的瞄准。自动瞄准系统在机器人领域具有广泛的应用
前景,可以应用于军事、工业、医疗等领域,为人们的生产和生活带来更多便利。
总之,RoboMaster 比赛自动瞄准系统的研究背景包括计算机视觉、控制工程、机器
学习等领域的发展,并受到越来越多的研究者的关注。
1.2 国内外研究现状
在 2019 年,于立强[1]等在《基于机器视觉的手写数字识别与目标追踪技术研究》一
文提出的自动瞄准系统使用了传统视觉方法及支持向量机,对图像进行二值化后识别到
目标再用支持向量机的方法对装甲板中央的数字进行识别,该文提出的自动瞄准系统并
没有对多目标的情况进行处理,也没有考虑目标的运动速度,只能以滞后的形式跟踪目
标,没有考虑目标的运动速度,不能够在目标运动的时候对其进行有效的击打。
在 2020 年,卫超奇[2]等在《基于卷积神经网络的自动反击的研发设计》一文提出的
自动瞄准系统为解决复杂环境下的非线性光照多目标识别与定位问题使用了 YOLO 算法作
为系统的识别器,但由于机载运算设备的算力限制,在识别速度上并没有达到预期目标,
并且该系统依旧没有考虑目标的运动速度。
在 2020 年,Xinyang Tang[3]等在《Development of Tracking and Control System
Based on Computer Vision for RoboMaster Competition Robot》一文出提出的自动瞄
准系统使用传统视觉方案识别灯条同时使用 CNN 进行数字图案的分类,同时使用 CA 运动
模型的卡尔曼滤波器进行目标的状态估计,在目标自旋时特化处理,计算装甲板跳变周
期来估计目标的角速度,实现目标自旋时的预测击打。但是,这种方法在应对目标旋转
平移时效果必然是不佳的,因为当目标旋转平移时完全不符合假设的运动模型,只能应
对目标原地自旋的情况。同时使用 CNN 应对印刷图案分类的速度不够快,在屏幕中出现
多目标时将造成非常严重的延时。
在 2020 年,宋珣[4]等在《基于运动学建模的自动瞄准系统》一文中创新性的提出了
使用运动学建模来应对目标机器人自旋的情况,但该文对于目标机器人未知参数的求解
使用的是解方程组的形式,这种方式对于观测的准确度要求非常高,在笔者实际测试中
实际表现效果不好。
在 2021 年,梁睿哲[5]等在《基于 RoboMaster 机甲大师赛的计算机视觉应用开发》一
文提出的自动瞄准系统使用传统视觉方法及 BP 神经网络作为识别器,同时考虑了目标的


用于 RoboMaster 比赛的自动瞄准系统
3
运动,将目标变换到惯性系后通过帧差取平均近似计算目标的运动状态。但由于实际比
赛中目标往往会同时存在平移及旋转运动,帧差法对于这种运动状态的估计效果非常差。
通过上面的介绍,在 RoboMaster 自动瞄准任务中目标识别的方法大体可以分为:传
统方法识别灯条结合机器学习进行图像分类,使用神经网络直接回归装甲板角点。目标
运动估计方法分为:帧差法,使用 CV/CA 运动模型的卡尔曼滤波,通过运动学建模使用
历史装甲板信息求解目标中心位置进行预测。在比赛自动瞄准的实际应用中,考虑到实
时性及准确性的要求,以及目标复杂的运动情况,以上方法都存在着一定的缺陷,所以
研究在复杂比赛环境中的自动瞄准系统设计具有重要意义。


用于 RoboMaster 比赛的自动瞄准系统
4
2计
2.1 算法设计目标
在 RoboMaster 比赛中,机器人需要精准的命中敌方机器人身上搭载的四块装甲板才
能造成有效伤害,这就需要我们精准的获取目标装甲板的位置用于计算发射时的云台姿
态 。 在 比 赛 中 , 有 两 种 不 同 的 装 甲 模 块 , 大 型 装 甲 板 ( 230mm*127mm ) 和 小 型 装 甲 板
(135mm*125mm)。它们都贴有数字标签(从 1 到 5)以及一些特殊图案,并且在装甲模块
的边缘有两个灯条,灯条的灯光可以是红色或蓝色。当己方为红队时,机器人上的灯光
将是红色的,目标机器人上的灯光将是蓝色的。同时装甲模块上的数字标签用于区分不
同的机器人。不同的机器人在装甲模块上有不同的数字标签。
图 2.1 不同类型的装甲板模块
同时由于比赛中发射的是塑胶弹丸,弹速一般为 10~15m/s,会在出膛后有一定的飞
行时间,因此估计出目标的速度进行目标的预测是非常有必要的。


用于 RoboMaster 比赛的自动瞄准系统
5
图 2.2 没有进行预测时的射击效果
如图 2.2 所示,在左图状态下发射一枚弹丸,当弹丸到达目标在发射时的位置时,
目标已经离开了瞄准的位置。
总的来说,想要在比赛中实现良好的自动瞄准效果,我们需要:
(1) 在图像中实时的识别目标并精准的获取目标相对己方机器人的三维位置;
(2) 较为精确的估计目标的运动状态以获得实时的预测瞄准位置。
2.2 三维重建、识别、跟踪及状态估计算法选型
2.2.1三维重建算法
由于我们需要获取目标相对己方机器人的三维位置才可计算出弹丸发射时的云台姿
态,因此我们需要使用三维重建算法。
三维重建方法有很多种,包括但不限于:
(1) 基于 RGB-D 深度相机[8]或融合相机及激光雷达[9]直接获取深度信息计算对应三
维位置;
(2) 基于深度学习的深度估计[10];
(3) 通过单目 PnP 从单张图像中恢复物体的三维位置姿态[6]。
方法(1)可以直接通过硬件实现获取深度信息,因此在合适的距离下的距离精度应
当是最高的,但受制于目前市面上的深度相机及激光雷达 FOV 较大,在远距离情况下得
到的深度图较为稀疏,取装甲板大小的深度信息抖动较大,并且由于相机 FOV 较大,识
别器的有效识别距离不足,以 Intel Realsense D455 深度相机为例,最远识别距离仅为
3m,无法满足比赛的需求。方法(2)分为绝对深度估计及相对深度估计,在该任务场景
下我们需要绝对深度估计,而由于绝对深度估计泛化能力极差,并且由于网络推理延时
较高,也不满足自动瞄准任务的需求。方法(3)的劣势主要为需要知晓目标三维角点的
先验信息,但在 RoboMaster 比赛中目标都是固定且可知的,并且方法(3)只需要单目


用于 RoboMaster 比赛的自动瞄准系统
6
RGB 图像即可获取目标的位置姿态,而一般工业相机都可以提供高帧率的 RGB 图像,还可
根据不同机器人识别距离的需求更换不同焦距的镜头,故笔者选用方法(3)作为自动瞄
准系统的三维重建算法。
2.2.2目标识别算法
由 2.2.1 中可知,我们需要获得图像中的目标对应角点的信息,因此需要选用合适
的目标识别算法。由 1.2 可知,目前在 RoboMaster 比赛中应用的识别算法主要分为传统
方法识别灯条结合机器学习进行图像分类以及使用神经网络直接回归装甲板角点。传统
方法一般为对图像二值化中找寻符合装甲板灯条特征的轮廓,再对候选灯条进行匹配。
图像分类任务与常见的数字分类任务比较接近,数字分类方法一般有:
(1) 逻辑回归[11](Logistic Regression),用于预测二元结果,如是/否,通过/
失败等。
(2) 朴素贝叶斯[12](Naive Bayes),用于计算一个数据点属于某个类别的概率,
基于特征之间的独立性假设。
(3) K-最近邻[13](K-Nearest Neighbors),用于根据训练数据集中最接近的 k 个
数据点来对新数据点进行分类。
(4) 决策树[14](Decision Tree),用于通过不断将数据集分割为更小的子集来构
建分类或回归模型。
(5) 支持向量机[15](Support Vector Machines),用于通过寻找能够最大化两个
类别之间边界距离的超平面来进行分类。
(6) 多层感知机[16](Multilayer Perceptron),用于分类或回归问题,通过反向
传播算法来学习网络的权重和偏置,以最小化损失函数。
(7) 卷积神经网络[17](Convolutional Neural Network),它的人工神经元可以响
应一部分覆盖范围内的周围单元,对于大型图像处理有出色表现。
而通过神经网络回归装甲板角点主要分为 1-stage 方法及 2-stage 方法,代表方法为:
(1) 1-stage 的单发多框检测器[18](Single Shot MultiBox Detector)及 YOLO[19]
(You Only Look Once),可以在一次前向传播中完成目标的定位和分类,而
不需要借助候选区域生成的步骤。
(2) 2-stage 的 Fast RCNN[20],先使用选择性搜索(selective search)算法在图
像中提取候选区域(region proposals),再将原始图像输入卷积神经网络
(CNN)中,得到整个图像的卷积特征图(feature map),再通过神经网络进
行分类及回归。
考虑到自动瞄准系统对于算法实时性以及角点定位精确度的高要求,笔者选择采用传


用于 RoboMaster 比赛的自动瞄准系统
7
统方法识别灯条结合机器学习进行图像分类的方法。在分类器的选择上,考虑到目标图
案为印刷体数字,并且不会有位移及形变,而且需要进行多分类,故笔者选择使用多层
感知机作为装甲板中图案的分类器。
2.2.3跟踪算法
由于图像中会同时出现多个目标,在自动瞄准时云台应该保持持续锁定同一目标,
所以跟踪算法是非常有必要的。跟踪算法主要有基于图像信息的 KCF 跟踪算法[21],是一
种基于核相关滤波(Kernel Correlation Filter)的目标跟踪算法,它是在 CSK 算法的
基础上进行了改进,提高了跟踪的准确度和鲁棒性,以及使用卡尔曼滤波器(Kalman
Filter)对每个目标的状态进行预测和更新同时仅使用 IoU 作为数据关联的指标的多目
标跟踪算法 SORT[6](Simple online and realtime tracking)等。考虑到对于实时性的
要求以及在该自动瞄准任务中,目标的图像特征都十分相似,KCF 不适合用于该任务的跟
踪,故笔者选用 SORT 算法中对于目标滤波及关联的处理思路作为单目标跟踪器的算法基
底。
2.2.4状态估计算法
由 2.1 可知我们需要对于运动目标有一定的预测,这需要我们对于目标的运动状态
(例如目标的运动速度)有一定的估计,而除位置姿态外其他的状态是无法直接被我们
的系统所观测的,这就需要状态估计器来从观测数据来推断系统状态。
状态估计算法有很多种,其中比较常见的有:
(1) 卡尔曼滤波(Kalman Filter):一种基于线性系统模型和高斯噪声假设的最
优状态估计算法,它利用系统的状态转移方程和观测方程,通过预测和更新
两个步骤,来递归地求解最小均方误差的状态估计。
(2) 扩展卡尔曼滤波(Extended Kalman Filter):一种基于非线性系统模型的状
态估计算法,它通过对系统的状态和观测方程进行线性化近似,然后应用卡
尔曼滤波的框架,来处理非线性系统的状态估计问题。
(3) 无迹卡尔曼滤波(Unscented Kalman Filter):一种基于非线性系统模型的
状态估计算法,它通过对系统的状态分布进行采样,然后根据采样点的变换
和加权,来近似系统的非线性变换和预测分布,从而避免了线性化近似带来
的误差。
(4) 粒子滤波(Particle Filter):一种基于蒙特卡洛方法的状态估计算法,它
通过对系统的状态空间进行随机采样,然后根据观测数据对采样点进行重要
性加权和重采样,来近似系统的后验分布和最优状态估计。


用于 RoboMaster 比赛的自动瞄准系统
8
(5) 多变量状态估计技术(Multivariate State Estimation Technique, MSET):
一种基于非线性多元预测诊断技术的状态估计算法,它通过分析对比实际监
测参数与设备正常运行时的健康数据为基础,对正常运行时的各个参数进行
运算并做出估计,以这种正常的状态估计作为标准。
考虑到在 RoboMaster 比赛中,目标机器人为了规避弹丸的击打,运动状态一般为旋
转运动叠加平移运动,而我们观测的对象为目标机器人上所搭载的装甲板,为了获取最
佳的击打效果,我们应该估计出目标机器人的整体运动状态而非单一装甲板的运动状态,
而这意味着状态空间到观测空间的转换是一非线性过程,所以卡尔曼滤波是不能直接使
用的。同时考虑到这一过程的非线性程度不大,再加上系统对于实时性的要求,故笔者
采用扩展卡尔曼滤波作为自动瞄准系统的状态估计算法。
综上所述,由于我们需要在图像中实时的识别目标并精准的获取目标相对己方机器
人的三维位置以及较为精确的估计目标的运动状态以获得实时的预测瞄准位置,我们需
要使用三维重建、识别、跟踪及状态估计算法来实现这一过程。考虑到比赛中击打距离
的需求、待识别目标的特征、整体运动状态以及系统对于实时性的要求,笔者选用单目
PnP 算法进行三维重建,传统方法识别灯条结合机器学习进行图像分类进行目标识别,采
用 SORT 思想的单目标跟踪器进行目标跟踪,以及扩展卡尔曼滤波进行状态估计。
2.3 算法系统框架


用于 RoboMaster 比赛的自动瞄准系统
9
图 3.1 自动瞄准系统整体框架示意图
该算法系统的输入为单目 RGB 图像以及相机的内参矩阵及镜头畸变系数,以及云台
姿态信息,最终输出在惯性系下跟踪着的机器人状态,其中包含机器人中心位置及机器
人的运动线速度和角速度,以及两对装甲板的相对位置关系。
2.4 传统视觉方法结合多层感知机的装甲板目标识别器
考虑到装甲板的视觉特征为一对自发光的红色或蓝色灯条以及中心的数字图案,笔
者采用传统视觉方案以获得可能的装甲板灯条配对,再提取其中的图案使用多层感知器
进行多分类,最后通过 PnP 解算出目标在相机坐标系下的三维位置姿态信息。
2.4.1通过传统方法获取候选目标的角点
由于一般工业相机的动态范围不够大,导致若要能够清晰分辨装甲板的数字,得到
的相机图像中灯条中心就会过曝,灯条中心的像素点的值往往都是 R=B。根据颜色信息
来进行二值化效果不佳,因此此处选择了直接通过灰度图进行二值化,将灯条的颜色判
断放到后续处理中。
图 3.2 原图像、通过颜色二值化及通过灰度二值化的示意图
再在二值化图像中寻找轮廓,获得轮廓的最小外接矩形,对其进行长宽比和倾斜角
度的判断,可以高效的筛除形状不满足的亮斑。判断灯条颜色这里采用了对轮廓内的的
R/B 值求和,判断两和的的大小的方法,若 R 通道值的总和大于 B 通道值的总和则认为是
红色灯条,反之则认为是蓝色灯条。
图 3.3 提取出的红蓝颜色灯条示意图
根据机器人自身颜色选择相对应敌方颜色的灯条进行两两配对,首先筛除掉两条灯
条中间包含另一个灯条的情况,然后根据两灯条的长度之比、两灯条中心的距离、配对


用于 RoboMaster 比赛的自动瞄准系统
10
出装甲板的倾斜角度来筛选掉条件不满足的结果,得到形状符合装甲板特征的可能灯条
配对。
2.4.2通过角点提取其中的图案使用多层感知机进行分类
根据上文所述方法获取到灯条配对后,将每条灯条上下的角点拉伸到装甲板的上下
边缘作为待变换点,进行透视变换,再对变换后的图像取 ROI。考虑到数字图案实质上就
是黑色背景+白色图案,所以此处使用了大津法进行二值化。
图 3.4 原图像、经过透视变换、取 ROI、二值化的示意图
由图 3.4 可见,该方法对于数字的提取效果较好,数字图案的特征清晰明显,装甲
板的远近、旋转都不会使图案产生过多畸变,且图案像素点少,所以我们使用多层感知
机(MLP)进行分类。
多层感知机是一种人工神经网络,可以用于分类、回归或其他任务。MLP 的基本结构
包括输入层、隐层和输出层,每一层都由若干个神经元组成,相邻层之间是全连接的,
即每个神经元都与上一层和下一层的所有神经元有连接。MLP 的核心要素有权重、偏置和
激活函数,它们决定了神经元的输出和网络的性能。MLP 的训练和学习通常采用反向传播
算法,通过不断更新权重和偏置来最小化代价函数,从而提高网络的泛化能力。
图 3.5 网络结构图
在该分类任务中,我们定义了一个三层全连接多层感知机,网络结构中定义了两个
隐藏层和一个分类层,激活函数选用 Relu 函数,网络的输入为二值化后的数字展平成
20x28=560 维的向量,送入网络进行分类,最后输出为比赛中可能出现的图案+无效图案
的概率(8 目标+1 负类)。最后再通过 SoftMax 方法对输出的 1x9 概率进行处理,选择最
大的概率作为分类结果。


用于 RoboMaster 比赛的自动瞄准系统
11
图 3.5 训练集和验证集的损失及正确率
经过充分训练,该网络能够在测试集中获得 99.8%的正确率。
2.4.3PnP 解算获取目标的三维位置姿态
PnP 是透视 n 点的缩写,它是一种计算机视觉中的经典问题,目的是根据给定的 n 个
三维空间点和它们在图像上的投影点,求解相机的位置和姿态。PnP 问题的难点在于它是
一个非线性的最优化问题,需要求解多个未知参数,同时考虑噪声和异常点的影响。
PnP 问题有很多种求解方法,根据所需的匹配点数目,可以分为 P3P、P4P、P5P 等。
根据所用的数学工具,可以分为代数方法、几何方法、优化方法等。常见的 PnP 算法有
DLT、EPnP、UPnP、RPnP 等。
考虑到装甲板的四个点在同一平面上,这种问题实际上是共面姿态估计问题 PPE
(Perspective-n-Point with known coplanar points),因此笔者选用 IPPE[5]
(Infinitesimal Plane-based Pose Estimation)方法来进行该 P4P 问题的求解。
IPPE 的基本思想是将平面目标的三维位姿分解为两个部分:一个是平面目标的法向
量,另一个是平面目标上的一个参考点。IPPE 首先利用 SVD 分解和反正切函数来求解平
面目标的法向量,然后利用最小二乘法来求解参考点的位置。由于 PPE 问题存在两个可
能的解,IPPE 会返回两个候选的位姿,并根据重投影误差来选择最佳的位姿。


用于 RoboMaster 比赛的自动瞄准系统
12
图 3.6 PnP 解算原理图
最后,识别器模块通过上述识别方法得到的装甲板一对灯条的四个角点与相机参数,
对图像中识别到的装甲板使用 IPPE 方法进行 PnP 解算,将重投影误差最小的解作为识别
器的输出。
至此,该系统获得了当前图像内所有装甲板在相机坐标系下的位置与姿态。
2.5 扩展卡尔曼滤波结合三维位置关联的单目标跟踪器
考虑到比赛中的相机一般安装在云台上,并且上一步做观测的坐标系是相机坐标系,
该坐标系会随着云台运动而变化,在进行目标跟踪时云台会随着目标一起运动,若在相
机坐标系下做状态估计得到的速度会耦合云台自身的运动以及目标的运动,无法得到正
确的目标状态,因此需要获取云台的姿态将观测的坐标系变为以云台中心为原点的惯性
系。
由于在比赛时相机同一画面中经常会出现多个目标,并且同一机器人在旋转时也会
出现视野中的装甲板跳变成另一块装甲板的情况,因此在自动瞄准系统中使用跟踪器是
非常有必要的。
根据 2.2.3,笔者选用 SORT 算法作为跟踪器的基底。SORT[6]是 Simple Online and
Realtime Tracking 的缩写,它是一种多目标跟踪算法,可以有效地关联目标,并提升跟
踪的实时性。SORT 的核心主要是卡尔曼滤波和匈牙利算法的结合,分别处理运动预测和
数据关联这两个分量。


用于 RoboMaster 比赛的自动瞄准系统
13
SORT 的基本思想是将目标的状态和标识等信息传播到下一帧,然后根据检测框和预
测框之间的交并比 (IOU) 来计算分配代价矩阵,再用匈牙利算法求解最大匹配问题,从
而实现当前帧与对象之间的关联。
SORT 的优点是简单、快速、准确,可以达到实时跟踪的效果。SORT 的缺点是没有考
虑目标的外观特征,容易出现 ID 切换和目标丢失的问题,而且对检测结果依赖性较高。
笔者参考 SORT 算法中对于 IOU 作为前后帧数据关联依据的处理以及其对卡尔曼滤波
的应用,设计了单目标跟踪器,使用目标的三维位置以及装甲板分类结果作为关联条件,
去除其中匈牙利算法的部分仅用作单目标跟踪,跟踪器工作过程如图 3.7 所示。
图 3.7 跟踪器工作流程图
跟踪主要分为初始化和更新两个步骤:
2.5.1初始化
跟踪器默认选择离相机光心最近的目标作为跟踪对象,选择目标后初始化扩展卡尔
曼滤波器,滤波器的初值根据当前跟踪对象设r为 0.2m 计算处对应的(xc, yc), za, θ与当
前跟踪目标对象一致,速度都默认为 0。


用于 RoboMaster 比赛的自动瞄准系统
14
2.5.2 更新
跟踪器的更新步骤首先由扩展卡尔曼滤波器得到当前帧的预测状态,再通过观测方
程h(⋅)将状态空间映射到观测空间得到对应的预测装甲板位置,根据然后遍历当前帧中的
目标位置与预测位置进行匹配,若当前帧不存在目标或所有目标位置与扩展卡尔曼滤波
器的预测位置的偏差都过大则认为目标丢失,重置扩展卡尔曼滤波器。最后选取位置相
差最小的目标作为最佳匹配项作为观测量更新扩展卡尔曼滤波器。
2.5.3 跟踪器状态转换与最终估计状态的输出
为了避免识别器出现误识别以及目标短暂丢失时跟踪器保持跟踪,跟踪器共设计了
四个状态,其中状态转换过程如图 3.8 所示。
图 3.8 跟踪器状态转换示意图
只有当跟踪器为“跟踪目标中”状态时才会输出更新后的估计状态,而当跟踪器为
“短暂丢失目标”状态时会输出预测的状态,有效避免了出现一帧误识别时云台错误响
应,同时当目标短暂丢失时机器人云台仍然能够保持跟踪。


用于 RoboMaster 比赛的自动瞄准系统
15
2.5.4 跟踪器中扩展卡尔曼滤波器的设计
图 3.9 装甲板与机器人中心的运动学示意图
考虑到比赛中各参赛队为了规避击打,机器人自身底盘运动往往不是单纯的平移运
动而是旋转与平移的叠加,因此采用常规的匀速直线运动模型对装甲板做状态估计效果
不佳。考虑到四块装甲板与机器人中心在 XOY 平面上的运动学关系如图 3.9 所示,用公
式表达为:
{xc = xa + r ∗ cos(θ)
yc = ya + r ∗ sin(θ) (2.1)
观测的装甲板位姿和机器人整体底盘状态可以由上式联系在一起,并且该状态空间
与观测空间的变换是非线性的,因此笔者选择使用扩展卡尔曼滤波对机器人的整体状态
做状态估计。
扩展卡尔曼滤波(Extended Kalman Filter,EKF)是一种针对非线性系统的状态估
计方法,它是在卡尔曼滤波(Kalman Filter,KF)的基础上进行的改进。
卡尔曼滤波是一种利用线性系统的状态方程和观测方程,结合贝叶斯理论和最小均
方误差原则,通过预测和更新两个步骤来递推地估计系统状态的方法。
扩展卡尔曼滤波的主要思想是利用泰勒展开,将非线性系统在某个参考点处近似为
线性系统,然后应用卡尔曼滤波的预测和更新公式来进行状态估计。
扩展卡尔曼滤波的主要步骤如下:
预测:根据非线性状态方程,利用上一时刻的状态后验估计和控制输入,预测当前
时刻的状态先验估计和误差协方差矩阵。
线性化:在预测的状态先验估计处,对非线性状态方程和非线性观测方程进行一阶
泰勒展开,得到相应的线性化状态转移矩阵和观测矩阵。


用于 RoboMaster 比赛的自动瞄准系统
16
更新:根据非线性观测方程,利用预测的状态先验估计和观测数据,计算观测残差
和卡尔曼增益,然后根据卡尔曼滤波的更新公式,得到当前时刻的状态后验估计和误差
协方差矩阵。
扩展卡尔曼滤波的优点是可以处理非线性系统,并且相比于其他非线性滤波方法,
如无迹卡尔曼滤波(Unscented Kalman Filter,UKF)和粒子滤波(Particle Filter,
PF),具有较低的计算复杂度和内存需求。
扩展卡尔曼滤波的缺点是对于高度非线性或多峰分布的系统,一阶泰勒展开可能不
足以近似真实的系统行为,并且可能导致过度自信或发散的问题。考虑到当前任务状态
观测转移的非线性程度不高以及系统对于实时性有较高的要求,故扩展卡尔曼装滤波比
较适合作为该任务的状态估计器。
考虑到自动瞄准任务中对于目标只有观测没有控制,所以扩展卡尔曼滤波中的输入
-控制模型B和控制器向量u可忽略。扩展卡尔曼滤波的预测步如下:
xk|k−1 = f( xk−1|k−1) (2.2)
Pk|k−1 = F ∗ Pk−1|k−1 ∗ FT + Q (2.3)
更新步为:
K = Pk|k−1 ∗ HT ∗ (H ∗ Pk|k−1 ∗ HT + R)−1 (2.4)
xk|k = xk|k−1 + K ∗ (zk − h(xk|k−1)) (2.5)
Pk|k = (I − K ∗ H) ∗ Pk|k−1 (2.6)
假设目标机器人的运动模型为底盘匀速直线运动,仅在 XOY 平面有旋转运动叠加,则 EKF
的状态量x为机器人的中心坐标、在 XOY 平面下的旋转角度、线速度、角速度以及机器人
中心到当前观测装甲板的距离:
x = [xc, yc, za, θ, vxc, vyc, vz, vθ, r]T (2.7)
观测量z为惯性系下的装甲板位置以及在 XOY 平面下的旋转角度:
z = [xa, ya, za, θ]T (2.8)
状态转移方程组f(⋅)是线性的:
{
xc′ = xc + vxc ∗ dt
yc′ = yc + vyc ∗ dt z′a = za + vz ∗ dt
θ′ = θ + vθ ∗ dt
(2.9)
状态转移矩阵F为:


用于 RoboMaster 比赛的自动瞄准系统
17
[
1 0 0 0 dt 0 0 0 0 0 1 0 0 0 dt 0 0 0 0 0 1 0 0 0 dt 0 0 0 0 0 1 0 0 0 dt 0 0000 1 0 0 0 0 0000 0 1 0 0 0 0000 0 0 1 0 0 0000 0 0 0 1 0
0 0 0 0 0 0 0 0 1]
(2.10)
根据方程组(2.1)可得观测方程组h(⋅)为:
{
xa = xc − r ∗ cos(θ) ya = yc − r ∗ sin(θ) za = za θ=θ
(2.11)
由方程组(2.11)求得雅可比矩阵Jh为:
[
1 0 0 r ∗ sin(θ) 0 0 0 0 − cos(θ) 0 1 0 −r ∗ cos(θ) 0 0 0 0 − sin(θ) 001 0 0000 0 000 1 0000 0
] (2.12)
最后,根据实际观测的噪声情况设置R矩阵,根据系统运行的频率及观测的准确性设
置Q矩阵,即可获得良好的效果。
2.5.5对于装甲板跳变的处理
同一机器人有四块装甲板,在对其中一块装甲板跟踪时若目标机器人在旋转,就会
出现 ID 相同但实际上不是跟踪着的目标的装甲板,考虑到图 3.6 所示另一对装甲板的情
况,需要在装甲板跳变时对扩展卡尔曼滤波器进行一定的处理。
在目标机器人旋转时发生装甲板跳变,则对应着扩展卡尔曼滤波器状态量中的za, θ, r
发生了跳变,但状态量中的中心位置以及线速度,角速度并没有突变,所以笔者的处理
方式为使用滤波器外的一个变量 z2 存下滤波器状态量中的za,并根据观测到的跳变装甲
板信息修改za, θ。注意到图 3.6 所示另一对装甲板与中心也有一个固定的距离关系,所以
此时还需要另一个变量 r2 与滤波器状态量中的 r 做值的交换。通过这种方式,扩展卡尔
曼滤波器中的状态量就变成了机器人中心状态与跳变后装甲板的关系。
至此,结合扩展卡尔曼滤波器的状态量以及变量 z2,r2,即可根据假设的运动情况
推导出目标在一段时间后的目标中心位置,进而可以推断出对应的四块装甲板位置。通
过对四块装甲板的简单选择后计算对应的云台姿态并进行控制,就可以实现对旋转平移
的敌方机器人实现精准的击打。
综上所述,自动瞄准系统的算法模块包含传统视觉方法结合多层感知机的装甲板目
标识别器,以及扩展卡尔曼滤波结合三维位置关联的单目标跟踪器。传统视觉方法结合


用于 RoboMaster 比赛的自动瞄准系统
18
多层感知机的装甲板目标识别器的输入为单目 RGB 图像以及对应相机参数,通过传统方
法获取候选装甲板灯条配对后,提取其中的图案使用多层感知机进行分类筛除无效目标,
再通过 PnP 解算获取目标在相机坐标系下的三维位姿作为识别器的输出。扩展卡尔曼滤
波结合三维位置关联的单目标跟踪器的输入为目标在相机坐标系下的三维位姿以及云台
姿态,该跟踪器首先将目标的三维位姿通过输入的云台姿态变换到惯性系下,再通过跟
踪器的更新过程关联前后帧目标,最后将跟踪的目标位姿作为观测更新扩展卡尔曼滤波
器,并将扩展卡尔曼滤波器中目标机器人在惯性系下的状态作为自动瞄准系统算法模块
最终的输出。


用于 RoboMaster 比赛的自动瞄准系统
19
3 现 测试结
3.1 仿真器实现
为了验证算法的效果,考虑到算法的输入需要实时的单目 RGB 低曝光图像信息以及
实时的云台姿态,笔者采用 Unity 引擎搭建了用于仿真的比赛场景,同时在 Unity 端使
用 Ros2-for-Unity 开源项目调用 ROS2 的 Fast-DDS 通讯框架实现与 ROS2 系统通信的原
生接口,传输实时的图像及姿态,经测试在 CPU: i7-9750H, RAM: 16G, GPU: RTX 2060
的硬件条件下,同时启用 Unity 仿真器、自动瞄准系统程序、Foxglove Studio 可视化界
面,系统从 Unity 获取 640x480 分辨率图像到最终输出状态估计的整体延迟约为 6ms,程
序运行频率为 45hz,可实现实时在线仿真。
3.2 自动瞄准系统在仿真器中的测试结果
通过仿真器模拟靶面大小为1/2.9′的工业相机配合 8mm 镜头的单目 RGB 画面,在
1440x1080p 分辨率下,如图 4.1 所示自动瞄准系统的静态最远识别距离为 7.5m,误差约
为 0.14m(1.8%),可见静态测距效果良好。
图 4.1 静态单目测距仿真效果
通过仿真器设定目标机器人进行 0.5m/s 的平移运动叠加 5rad/s 的旋转运动,通过
自动瞄准系统估计目标机器人状态为线速度 0.53m/s,角速度为 4.65rad/s,同时通过反
投影观察四块装甲板的估计位置,如图 4.2 右侧可见都比较准确。


用于 RoboMaster 比赛的自动瞄准系统
20
图 4.2 动态目标状态估计仿真效果
在仿真器中设置目标进行 5rad/s 的旋转叠加 0.5m/s 的往复平移运动,测量 20s 的
数据,如图 4.3 及图 4.4 所示,可见该自动瞄准系统有效估计出目标运动状态,并且跟
踪效果较好。
图 4.3 角速度估计效果


用于 RoboMaster 比赛的自动瞄准系统
21
图 4.4 线速度估计效果
综上所述,笔者通过 Unity 引擎搭建的仿真器中可实现实时的自动瞄准系统仿真,
整体延迟仅为 6ms。同时在仿真器中,自动瞄准系统的静态表现与动态表现都十分优秀。


用于 RoboMaster 比赛的自动瞄准系统
22
4 现 战测试结
4.1 硬件平台介绍
图 4.1 实体机器人外观
实体机器人包括装载有四块装甲板的底盘以及装载发射模块、工业相机、机载运算
平台、控制下位机的云台。其中云台 Pitch 轴与 Yaw 轴电机为 GM6020 云台电机,额定扭
矩(最大持续扭矩)为 1.2N·m,额定扭矩下的最大转速为 132rpm。发射模块的摩擦轮
电机为 Snail 2305 直流无刷电机,空载转速为 21000rpm,扭矩常数为 10.9 mN•m/A。工
业 相 机 为 海 康 MV-CA016-10UC 全 局 彩 色 工 业 相 机 , 靶 面 尺 寸 为 1/2.9" , 分 辨 率 为
1440×1080,帧率为 166 fps,动态范围为 71 dB,镜头焦距选用 6mm。MiniPC 为派勤
TL500CA 工控板,CPU 为 i7-1165G7,运行内存为 DDR4 4G*2。控制下位机为 RoboMaster
开发板 C 型,主控芯片为 STM32F407,IMU 为 BMI088。
4.2 实战测试结果
在上述硬件平台下,机载运算平台程序整体输入输出延时稳定为 3ms,满足自动瞄准
系统的实时性需求。由于实际条件下目标运动状态的真值难以获得,此处笔者以实战命
中率来衡量自动瞄准系统的效果。控制目标机器人以约 3rad/s 的旋转速度、约 0.5m/s


用于 RoboMaster 比赛的自动瞄准系统
23
的平移速度运动,测试命中率如表 4.1 所示。
表 4.1 实战命中率数据
击打方式 目标机器人运动方式
平移 旋转 平移+旋转
手动瞄准 13.2% 35.7% 9.6%
自动瞄准 60.7% 80.6% 65.3%
由表 4.1 可见,在上述硬件平台下,使用自动瞄准系统相对于手动瞄准具有非常明
显的效果。


用于 RoboMaster 比赛的自动瞄准系统
24
5结
通过使用传统视觉方法结合多层感知机的装甲板目标识别器及扩展卡尔曼滤波结合
三维位置关联的单目标跟踪器,该自动瞄准系统相对于手动瞄准在实战中展现出非常显
著的优势。
实现该自动瞄准系统的关键点在于实时正确精准的目标装甲板角点识别,以及通过
IMU 数据实现良好的惯性系变换效果,再通过可靠的目标跟踪保证观测对象不会跳变,最
终通过贴合实际机器人运动情况的运动模型对目标进行状态估计,得到估计误差足够小
的目标状态,从而实现对于运动目标的精确击打。
在 RoboMaster 2023 高校联盟赛广东站中,华南师范大学 PIONEER 战队在步兵机器
人以及哨兵机器人上应用了该自动瞄准系统,在 3V3 对抗赛(37 支参赛队)中取得了季
军的成绩,在 1V1 步兵(45 支参赛队)对抗赛中取得了亚军的成绩。