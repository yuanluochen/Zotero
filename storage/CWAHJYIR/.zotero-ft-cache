SHANDONGUNIVERSITY OF TECHNOLOGY
毕业设计说明书
机器人辅助瞄准控制系统设计
学 院:电气与电子工程学院
专 业: 自动化
学生姓名: 宋东阳
学 号: 21110402131
指导教师: 赵建荣
2025 年 6 月


中文摘要
I
摘要
随着控制技术与目标检测技术的发展,在以射击为核心的 RoboMaster 比赛
中,机器人辅助瞄准技术应运而生。该技术从充满误识别的胡乱击打,到精准识
别以及 Constant Velocity(CV)模型的状态观测,再到整车状态估计、弹道模型构
建以及云台运动控制。如何结合改进的控制技术,实现机器人目标精准击打是十
分必要的。
本设计运用改进的控制算法,设计了机器人辅助瞄准控制系统。具体工作如
下:1)借助图像处理算法识别灯条,利用灯条匹配装甲板,结合数字识别算法实
现精准的目标检测;2)利用 Perspective-n-Point (PNP)算法,实现二维像素坐标到
三维相机空间坐标系的三维重建,阐述相机透视成像模型和整个 PNP 算法的实
现三维重建的原理;3)根据机器人的检测目标和机器运动中心的关系,建立机器
人运动学模型,利用扩展卡尔曼滤波器观测目标运动状态;4)利用状态观测器,
结合延迟时间的量测和通过子弹模型计算出的子弹飞行时间,计算目标受到击打
时的目标状态,根据敌方受到击打时的状态,推断出最好的击打目标,根据击打
目标的坐标,利用迭代弹道模型通过云台的仰角设置来补偿弹丸飞行时的下坠,
利用云台的 PID 控制器来控制机器云台,实现目标的动态跟踪。
本设计对比其他方法,验证了系统在目标检测、机器人运动学建模与状态观
测与机器人目标精准击打的可行性和有效性,可促进机器人辅助瞄准控制的发展
与完善。
关键词:目标检测,三维重建,状态观测,弹道模型,PID 控制


Abstract
II
Abstract
With the advancement of control technology and target detection techniques,
robot-assisted aiming technology has emerged in shooting-centered RoboMaster
competitions. This technology has evolved from random shooting with
misidentification to precise recognition and state observation using Constant Velocity
(CV) models, further extending to holistic robot state estimation, ballistic model
construction, and gimbal motion control. Integrating improved control techniques to
achieve precise target engagement for robots remains essential.
This study proposes an enhanced control algorithm to design a robot-assisted
aiming control system. The specific contributions include: 1) Implementing accurate
target detection through image processing algorithms for light bar identification, armor
plate matching via light bars, and digital recognition algorithms; 2) Achieving 3D
reconstruction from 2D pixel coordinates to 3D camera spatial coordinates using the
Perspective-n-Point (PNP) algorithm, with detailed explanations of the camera
perspective imaging model and PNP principles; 3) Establishing a robot kinematic
model based on the relationship between detected targets and the robot’s motion center,
and observing target motion states via an Extended Kalman Filter; 4) Designing a state
observer to predict target status during impact by combining measured latency and
bullet flight time calculated from a projectile model. Based on the predicted state of
enemy targets, the system prioritizes optimal targets, compensates for bullet drop
during flight through iterative ballistic modeling by adjusting the gimbal elevation
angle, and employs a PID controller to achieve dynamic target tracking.
Compared with existing methods, this system demonstrates feasibility and
effectiveness in target detection, kinematic modeling, state observation, and precise
target engagement, thereby advancing the development of robot-assisted aiming control
technology.
Key words: object detection, 3D reconstruction, state estimation, ballistic model,
PID control


目录
III
目录
摘 要............................................................................................................................ I
ABSTRACT.................................................................................................................. II
目 录..........................................................................................................................III
第 1 章 引 言..............................................................................................................1
1.1 课题社会背景及意义 .........................................................................................1
1.2 课题国内外研究历程及现状 .............................................................................2
1.3 机器人辅助瞄准控制系统的整体设计 .............................................................3
1.4 本论文各部分的主要内容 .................................................................................4
第 2 章 目标检测..........................................................................................................5
2.1 本章简述 .............................................................................................................5
2.2 灯条识别 .............................................................................................................6
2.2.1 图像预处理..................................................................................................7
2.2.2 灯条检测......................................................................................................8
2.2.3 灯条的颜色判断........................................................................................10
2.3 通过灯条匹配装甲板 ....................................................................................... 11
2.4 数字识别 ...........................................................................................................13
2.5 效果演示 ...........................................................................................................14
2.5.1 准确的目标检测效果................................................................................14
2.5.2 高效的目标检测........................................................................................15
2.5 本章小结 ...........................................................................................................15
第 3 章 三维重建与坐标变换..................................................................................16
3.1 本章简述 ...........................................................................................................16
3.2 相机模型 ...........................................................................................................16
3.2.1 相机成像原理............................................................................................16
3.2.2 相机模型中各坐标系之间的变换............................................................17
3.3 装甲板的三维世界的重建 ...............................................................................21
3.3.1 使用 PNP 算法求解外参平移矩阵简述 ..................................................21
3.3.2 在相机空间坐标系下装甲板的目标定位................................................22
3.4 坐标变换 ...........................................................................................................23
3.5 效果演示 ...........................................................................................................24


目录
IV
3.6 本章小结 ...........................................................................................................24
第 4 章 机器人运动学建模与状态观测..................................................................25
4.1 本章简述 ...........................................................................................................25
4.2 扩展卡尔曼滤波器(EKF) ...........................................................................26
4.2.1 使用扩展卡尔曼滤波器的缘由.................................................................26
4.2.2 扩展卡尔曼滤波器原理简述....................................................................27
4.3 机器人运动学建模 ...........................................................................................27
4.4 单目标跟踪器的实现 .......................................................................................30
4.5 效果演示 ...........................................................................................................31
4.5.1 机器人运动学建模效果演示....................................................................31
4.5.2 扩展卡尔曼滤波器观测目标运动状态效果演示....................................31
4.5.3 单目标跟踪器效果演示............................................................................32
4.6 本章小结 ...........................................................................................................33
第 5 章 机器人目标的精准打击..............................................................................34
5.1 本章简述 ...........................................................................................................34
5.2 目标状态预测 ...................................................................................................35
5.2.1 目标状态预测实现....................................................................................35
5.2.2 图像以及数据处理延迟的量测................................................................36
5.2.3 发射延迟的量测........................................................................................36
5.2.4 延迟时间较低的延迟的省略....................................................................37
5.3 整车运动状态计算 ...........................................................................................38
5.4 装甲板筛选 .......................................................................................................39
5.5 迭代弹道模型 ...................................................................................................40
5.5.1 迭代弹道模型构建的缘由........................................................................40
5.5.2 弹道模型的构建........................................................................................40
5.5.3 迭代法求解下坠补偿后的仰角................................................................42
5.6 云台运动控制 ...................................................................................................42
5.7 开火控制 ...........................................................................................................45
5.8 效果演示 ...........................................................................................................46
5.8.1 静止目标击打效果....................................................................................46
5.8.2 旋转目标击打效果.....................................................................................46
5.8.3 平动目标击打效果.....................................................................................47
5.9 本章小结 ...........................................................................................................47


目录
V
第 6 章 总结和展望....................................................................................................48
6.1 总结....................................................................................................................48
6.2 展望....................................................................................................................48
参考文献...................................................................................................................... 49
致 谢..........................................................................................................................52
附 录..........................................................................................................................53


第1章 引 言
1
第1章 引 言
1.1 课题社会背景及意义
RoboMaster 赛事是由大疆创新发起的一项全国性大学生机器人大赛,自
2013 年创办以来,始终秉持着”为青春赋予荣耀,让思考拥有力量”的理念,致力
于为全球科技爱好者打造一个集机器人竞技与学术交流于一体的平台。该赛事通
过机器人竞技和学术交流,有效激发了青年学生的创新精神和实践能力,有力推
动了机器人技术的创新发展和实际应用。
图 1.1 机器人对战
如图 1.1 所示,在 RoboMaster 比赛的基本规则为两方机器人对局,通过发
射弹丸击打对方机器人的建筑或者机器人装甲板从而降低敌方血量取胜。比赛之
初主要以机器人操作手,通过机器上的图传设备,人工瞄准敌方机器人或者建筑
的装甲板进行目标击打,命中率较低。后来随着 RM 参赛队伍的技术不断的迭代
进步,逐渐出现了以计算机视觉和自动控制控制技术为基础的机器人辅助瞄准系
统。
对机器人辅助瞄准系统深入研究不仅提升了机器人的智能化水平,使其能够
更好地适应复杂多变的环境,同时也推动了相关技术在更广泛领域的应用。本系
统通过图像处理[1]、目标检测[2-3]、三维重建等技术实现对目标的精准识别和定位,
同时对机器人进行运动学建模设计状态观测器观测目标运动状态同时进行目标


第1章 引 言
2
跟踪[4-6],并使用控制算法[7-11]实现机器人的精确瞄准。这种技术突破为自动瞄准
系统在军事、工业、医疗等领域的应用开辟了广阔前景,有望为人类社会带来更
多便利。
1.2 课题国内外研究历程及现状
在 2019 年于立强在《基于机器视觉的手写数字识别与目标跟踪技术的研究》
[12]中提出了用传统图像处理的方法对目标装甲板进行识别,同时使用支持向量
机(Support Vector Machines,SVM)[13-16]对装甲板上数字进行识别,极大提升装甲
板识别的精准度,解决了装甲板的误识别的问题,但是随着 RoboMaster 机器人
技术的进步以及导电滑环技术广泛使用,机器人都拥有了“陀螺(装甲板绕机器
人中心旋转)”的能力,这使得纯粹的精准识别,以及对静态目标的精准定位,
难以实现对于绕轴自旋运动的目标精准跟踪以及击打。
在 2020 年宋珣等在《基于运动学建模的自动瞄准系统》[17]中提出了通过对
装甲板以及机器人自身进行运动学建模,构建从装甲板到机器人中心的旋转运动
学方程,同时使用扩展卡尔曼滤波器(Extended Kalman Filter,EKF)[18-19]根据
机器人运动学模型进行运动状态估计,实现对绕轴旋转目标的跟踪,由此机器人
“反陀螺”技术出现,促进了机器人辅助瞄准系统的进步。极大的提升了机器人辅
助瞄准系统的动态目标跟踪能力。自从这篇论文的发表,机器人辅助瞄准系统迈
入了一个崭新的台阶,进入了反陀螺时代。
在 2021 年王洪玺等在《基于卡尔曼滤波的目标识别跟踪与射击系统设计》
[20]上全面的介绍了机器人辅助瞄准系统的全貌,包括通过二值化对灯条进行特
征提取、通过 PNP 算法对目标中心进行定位、通过 IMU 计算机器人位姿[21-22],
并通过坐标变换将目标坐标从相机相对坐标系转换到机体相对坐标系,再通过四
元数将机体相对坐标系转换为机体惯性坐标系,并且同时介绍了弹道补偿[23-24]等
问题的处理。为广大机器人辅助瞄准系统的研发者,提供的宝贵资料。
基于上述资料,自于立强提出用传统图像处理进行装甲板的初步识别并使用
SVM 进行数字识别,降低了误识别的可能并极大的提升了目标检测的稳定性开
始,到宋珣在《基于运动学建模的自动瞄准系统》中提出了通过对装甲板与机器
人中心建立运动学模型以此为基础提升辅助瞄准系统跟踪动态目标的能力,最后
到王洪熙在《基于卡尔曼滤波的目标识别跟踪与射击系统设计》中完整的介绍了
基础机器人辅助瞄准系统各个功能模块的实现。本系统在前人的基础上,构建出
来的拥有良好的动态目标跟踪能力,精准击打能力的一版机器人辅助瞄准系统。


第1章 引 言
3
1.3 机器人辅助瞄准控制系统的整体设计
图 1.2 机器人辅助瞄准系统的整体设计
辅助瞄准系统的系统框图如上图 1.2 所示,系统通过与云台固联相机采集图
像,NUC(Next Unit of Computing)根据目标外观特征使用 OpenCV 库函数对机
器人装甲板进行初步匹配,然后使用神经网络[25-27]进行数字识别以此进一步确定
为识别目标,通过 PNP(Perspective-n-Point)算法[28-34]求解出相机坐标系下目标
的空间坐标,通过串口通信获取当前机器人位姿(Yaw 轴,Pitch 轴,Roll 轴的
角度),利用机器人位姿数据将目标在相机相对坐标系下的坐标转换为惯性坐标
系下的坐标,然后通过扩展卡尔曼滤波器(Extended Kalman Filter,EKF)[35-37],
观测目标运动状态,将目标的运动状态通过串口通信发送到控制板,机器人控制
板根据目标运动状态,利用抛体的完全空气阻力模型计算子弹预期落点,利用迭
代法进行子弹重力下坠补偿,以及运动预测法,计算目标在子弹击中时的运动位
置,将预测的运动位置转换为机器人云台 yaw 轴以及 pitch 轴的角度控制量,通
过单片机控制板控制云台电机[38-40]转到相应角度,以此实现目标的跟踪与精准击
打。


第1章 引 言
4
1.4 本论文各部分的主要内容
第一章主要为对机器人辅助瞄准系统研究的简介,从机器人辅助瞄准系统的
研究背景以及意义到机器人辅助瞄准系统的研发现状,最后在 1.3 介绍了本论文
机器人辅助瞄准系统的整体设计。第二章、第三章、第四章和第五章分别说明了
目标检测、三维重建与坐标变换、运动学建模与卡尔曼滤波器和机器人目标的精
准打击的具体实现。第六章为总结和展望,最后几章为参考文献、致谢和附录。


第 2 章 目标检测
5
第 2 章 目标检测
2.1 本章简述
图 2.1 机器人装甲板
机器人装甲板如图 2.1 所示,在 RoboMaster 比赛中我方机器人通过发射弹
丸,弹丸击打到机器人装甲板上,装甲板内部拥有压力感应装置,能够感应到弹
丸对装甲板的击打,当装甲板感觉到受击打后机器人机器人在比赛中生命值就会
减弱。在 RoboMaster 比赛中想要精准击打敌方机器人装甲板,就必须要引入机
器人辅助瞄准系统,机器人辅助瞄准系统的第一步就是通过图像处理算法检测敌
方机器人装甲板。
图 2.2 装甲板灯条的长度以及两个灯条距离的定义


第 2 章 目标检测
6
分析机器人装甲板图像特征,最明显的特征就是拥有两个平行的灯条,同时
由于装甲板是一个固定大小的,那么装甲板两侧灯条的长度与距离的比例是一个
常数如图 2.2 所示,同时装甲板两个灯条内侧拥有数字。根据上述两点特征我们
可以提出一个基本的机器人装甲板识别思路。
图 2.3 装甲板识别的基本思路
如图 2.3 所示,我们可以先进行灯条检测,然后把检测到的灯条进行逐一按
照灯条长度与灯条距离的固定比例进行装甲板初步识别,最后对通过灯条匹配识
别到的装甲板,提取数字部分,通过神经网络算法进行数字识别,两层条件判断
为装甲板。以下将对各个模块进行详细阐述。本章节代码见附录 1-1 目标检测部
分的程序代码。
2.2 灯条识别
图 2.4 灯条识别
如图 2.4 所示,灯条识别主要包括图像预处理和灯条检测,首先对相机采集
的图像进行图像灰度化提取整个装甲板的亮度信息,由于灯条的灰度值在相机低
曝光的条件下明显高于其他部分所以通过图形二值化提取灯条的轮廓,然后通过
轮廓检测函数查找灯条轮廓,然后为方便后续计算通过提取轮廓的最小外接矩形
对灯条轮廓进行标准化,通过对标准化后的外接矩形,根据矩形的倾斜量和长宽
比来判断是否是灯条。


第 2 章 目标检测
7
2.2.1 图像预处理
图 2.5 红色装甲板图像 RGB 分布
图像预处理要经历图像灰度化和图形二值化,由于灯条在比赛中会发出红色
或者蓝色的光,如图 2.5 所示,在低曝光条件下,以红色灯条装甲板为例,图像
中在灯条位置 RGB 分量尤其是 R 分量会远高于周围位置。基于这一特点我们可
以选择使用图形灰度化算法来提取灯条。
Gray = R ⋅ 0.299 + G ⋅ 0.587 + B ⋅ 0.114 (2.1)
如公式(2.1),通过使用图像灰度化,将图像的 RGB 值转化为灰度值。
图 2.6 红色以及蓝色装甲板灰度化后的颜色值
如图 2.6 所示在相机低曝光条件下,图形灰度化以后,不管是红色灯条还是
蓝色灯条,灰度值明显高于其他位置。所以在图像灰度化以后通过图形进行固定
阈值的二值化操作,将灰度值明显高于周围部分的灯条提取出来。图形预处理过
程中的装甲板图片如图 2.7 所示。


第 2 章 目标检测
8
图 2.7 图像预处理
2.2.2 灯条检测
图 2.8 轮廓提取
图像二值化以后通过 Opencv 内置的轮廓检测算法提取灯条轮廓如图 2.8 所
示。在灯条识别层面,要判断是否为一个灯条最基本的条件是灯条的长宽比例
ratio以及灯条的倾斜量θ在一点范围之内,条件如公式(2.2)所示
{
ratiomin ≤ ratio = width
length ≤ ratiomax
θmin ≤ θ ≤ θmax, (2.2)
图 2.9 灯条最小外接矩形


第 2 章 目标检测
9
这要求要计算灯条的长与宽,通过提取的灯条轮廓来计算灯条的长与宽难度
很大,但是可以通过获取灯条轮廓的最小外接矩形来对灯条的轮廓形态进行标准
化,这样就可以很好的计算灯条的长度与宽度甚至倾斜,如上图 2.9 所示。
图 2.10 灯条参数求解
如图 2.10 所示,OpenCV 的获取轮廓最小外接矩形的函数会返回外接矩形
的四个角点 A、B、C、D,计算灯条的长度与宽度的方法如下,首先对四个角点
的 y 坐标分量进行排序,提取两个 y 分量最大的点 A、B 以及最小的两个点 C、
D。通过公式(2.3)求解矩形的宽度。
width =∥ A − B ∥ (2.3)
通过公式(2.4)计算出灯条矩形中心位置最高与最低点 D、E。
D = A+B
2 ,E = C+D
2 (2.4)
通过公式(2.5)可以求解出灯条的长度length。
length =∥ D − E ∥ (2.5)
通过公式(2.6)可以求解出灯条外接矩形的中心坐标。
center = D + E
2 (2.6)
计算向量 D 与向量 E 的差向量,并提取差向量的x与y分量通过公式(2.7)就
可以得到矩形的倾斜量。
θ = arctan (y
x) (2.7)


第 2 章 目标检测
10
将上述计算结果通过公式(2.2),判断是否为灯条。
2.2.3 灯条的颜色判断
由于比赛在匹配装甲板时要保证灯条是同一颜色的,所以在通过灯条匹配装
甲板之前要对灯条进行颜色提取,具体实现如下。
图 2.11 灯条颜色提取
如图 2.11,在灯条检测期间,获取了灯条轮廓的最小外接矩形,通过
ROI(region of intrest)剪切灯条部分,由图 2.12 我们可以发现在红色灯条中 R 分
量的密度远远高于 B 分量,所以可以通过对整个轮廓内的像素点 R 和 B 值进行
求和运算,比较求和值的 R 通道量和 B 通道量的大小,R 大就是红色灯条,B 大
就是蓝色灯条。


第 2 章 目标检测
11
图 2.12 提取红色灯条各个颜色分量的分布
最后将符合长宽比、倾斜和颜色的灯条存放在一个容器内,以便后期进行灯
条匹配。
2.3 通过灯条匹配装甲板
在灯条识别时,获取了图像中所有灯条的位置、长度和宽度等信息,当拥有
了以上信息之后,可以根据装甲板的形态特征,用灯条进行装甲板的识别,具体
实现如下。
图 2.13 装甲板的形态特征


第 2 章 目标检测
12
如图 2.13 所示由于装甲板是固定大小的,灯条的位置也在装甲板的特定位
置处,那么在装甲板成像后即使装甲板与相机之间存在倾斜,也能保证灯条的长
度与灯条之间的距离在一个固定尺寸范围内。故可以通过以下条件来筛选装甲板,
lengtharmer 为 装 甲 板 的 长 度 或 者 说 灯 条 中 心 位 置 的 距 离 , centerligt1 或 者
centerligth2 为两侧灯条的中心位置的像素坐标,lenthligth 为灯条长度,C 为实际
装甲板的长宽比例。
lengtharmer =∥ centerlight1 − centerlight2 ∥
armerRadio = lengtharmer
lengthlight
= C, (2.8)
但是在实际系统中,由于装甲板在相机拍摄时,装甲板没能正对相机,成像
如图 2.14 所示。
图 2.14 倾斜条件下的装甲板成像
明显一侧灯条的长度要大于另一侧,所以在灯条匹配层面,本系统对匹配函
数进行修改,用两侧灯条的平均长度(avglengthlight )做长宽比例计算,在做最后一
步比例是否符合装甲板比例时,引入范围(ratiomix, ratiomax)判断是否匹配到一
个装甲板。为了处理装甲板的倾斜问题,计算了装甲板的倾斜量(θ)是否在一个
范围内,由于在一个平面内的灯条,长度不会有很大的偏差,所在引入了一个灯
条长度比例变量lightRadio,通过判断这个变量是否在一定范围内,判断是否是
一个装甲板的灯条。


第 2 章 目标检测
13
在用长宽比例匹配灯条之前,需要先判断在两根灯条之间是否存在第三根灯
条,实现方法如下,首先用要匹配的灯条的四个角点构建一个矩形,用然后逐个
遍历其他识别到的灯条,判断其他灯条的外接矩形是否在用欲要匹配的灯条构建
矩形内,如图 2.15 所示。
图 2.15 判断内部是否有灯条
2.4 数字识别
图 2.16 复杂条件下的轮廓提取效果
根据装甲板的长宽比例固定这一特征,利用轮廓提取和最小外接矩形初步定
位灯条,通过对所有定位的灯条进行长宽匹配可以初步定位装甲板。但是仅利用
这种方法去做目标检测,是会出现大量的误识别,如图 2.16 所示,这是在复杂光
线条件下,对图像二值化和轮廓提取的效果,图中出现了大量的轮廓,基于轮廓
提取的视觉识别方法,在这种条件下误识别可能性会大幅度提升。为了提升识别
精度,消除掉由于环境影响而产生的误识别的可能,需要进行数字识别对通过灯
条匹配的装甲板进行进一步过滤。


第 2 章 目标检测
14
图 2.17 数字提取
为了提升神经网络的识别能力,在进行网络推理之前,先对通过灯条匹配获
取的可疑装甲板对其进行数字提取,具体方法如图 2.17 所示,首先通过透视变
换,将原始图像进行矫正,同时为了提升系统实时性,降低网络模型的大小,将
图像从原始图像大小等比透视为一个与实际装甲板等比例的一个图像,然后通过
ROI 提取出矫正后的图像的数字部分,由于在提取后的图像中仅有黑白两色,所
以可以通过大津二值化算法,清晰的提取出数字部分。在这种条件下,尽管图像
角度拍摄角度如何,都可以获取一张清晰且标准的图像,可以大幅度提升识别的
精准度。
2.5 效果演示
2.5.1 准确的目标检测效果
图 2.18 近距离与远距离条件下的识别
如图 2.18 所示在近距离与远距的条件下,能够通过图像处理算法进行灯条
识别,并且通过对灯条遍历,对任意两根灯条进行长宽比例匹配进行装甲板的初
步识别,然后通过神经网络算法对可疑目标进行数字识别,通过上述两层判断可
以精准的识别装甲板。


第 2 章 目标检测
15
图 2.19 近距离光线复杂的条件下识别
如图 2.19,即使在光线复杂的条件下,传统图像处理算法经常出现误识别的
情况下也能通过第二层神经网络算法保证识别的精准性。
2.5.2 高效的目标检测
图 2.20 目标检测模块的硬件设备
如图 2.20,本系统在目标检测模块使用海康威视 MV-CS016-10UM/UC 相机
和雷神 MIX 迷你主机。工业相机为一个全局快门和最高 165fps 的高帧率相机,
能够清晰的采集动态目标。运算设备为一个搭载 12 代 i5-12450H CPU 的高性能
计算机。由于识别模块采用传统目标检测算法与小型实现数字识别功能的神经网
络算法融合的思路,即使在无 GPU 加持的条件下也可保持极高的目标检测的实
时性,实测效果为目标检测时间大于在 2ms~5ms 这个范围内,有极好的实时性。
2.5 本章小结
本章节介绍了本论文的目标检测算法的设计思路,第一层为传统算法寻找可
疑的目标,第二层对可疑目标使用神经网络算法进行识别。在满足图像识别的精
准度的同时也获得了高效的处理速度。


第 3 章 三维重建与坐标变换
16
第 3 章 三维重建与坐标变换
3.1 本章简述
图 3.1 三维重建与坐标变换
通 过 机 器 人 装 甲 板 检 测 ,获 取 了 敌 方 机 器 人 装 甲 板 在 图 像 坐 标 系 下 的
像素坐标。在本章节将通过 PNP(Perspective-n-Point)算法求解相机坐标系
到 物 体 /世 界 坐 标 系 之 前 的 旋 转 和 平 移 关 系 ,并 通 过 平 移 矩 阵 获 取 在 相 机 坐
标系下物体的坐标,并最后通过坐标的变换,获取在惯性坐标系下,被识
别对象的空间坐标。本章节代码见附录 1-2 三维重建与坐标变换部分的程
序代码。
3.2 相机模型
3.2.1 相机成像原理
在讲述 PNP 之前,先从相机成像原理开始讲起,相机成像原理是基于
凸透镜成像,以一个工业针孔相机为例。
图 3.2 工业相机组成


第 3 章 三维重建与坐标变换
17
如图 3.2 所示,工业相机主要由两部分组成,分别为镜头和相机本体,
镜头由多个镜片组成,多个镜片可以等效为一个凸透镜,相机本体主要为
CMOS 传感器,负责感受光信号。相机的成像本质就是镜头将物体发出的
光聚集在相机本体的 CMOS 传感器上,CMOS 传感器通过把光信号转化为
电信号,最终转化为数字信号,变成我们所熟知的图片。具体成像原理如
下。
图 3.3 相机成像原理
如图 3.3 所示,实际物体一点会向等效凸透镜发出光线,其中穿过凸
透 镜 光 心 点 的 光 线 经 过 凸 透 镜 光 心 不 会 发 生 折 射 。平 行 射 入 凸 透 镜 的 光 线
会 发 生 折 射 ,所 有 通 过 凸 透 镜 射 向 凸 透 镜 的 光 线 ,透 过 凸 透 镜 会 交 于 一 点 。
在相机对焦较好的情况下,这一点就是相机本体感光面,即 CMOS 传感器
所在的位置。由于相机成像多为倒像,这不利于进行图像的分析,所以我
们 可 以 把 成 像 面 的 像 通 过 一 个 等 效 三 角 形 ,把 三 维 世 界 的 物 体 在 相 机 光 心
点后侧的倒像,等效为在光心点前侧的正像进行图像的分析。
3.2.2 相机模型中各坐标系之间的变换
根 据 相 机 的 成 像 原 理 ,可 以 分 析 出 三 维 坐 标 系 下 的 物 体 的 空 间 坐 标 与
图 像 的 像 素 坐 标 系 下 的 像 素 坐 标 之 间 的 变 换 关 系 。在 阐 述 以 上 关 系 之 前 先
定义以下四个坐标系。


第 3 章 三维重建与坐标变换
18
1. 世界坐标系:空间中某一点为原点,以一个特定方位构建一个三维
的笛卡尔坐标系。
2. 相机空间坐标系:以相机光心为原点,以相机正前方向为 Z 轴,X
和 Y 轴平行且同方向于图像像素坐标系的 X 和 Y 轴的三维坐标系。
3. 相机图像坐标系:以相机成像面中心为原点,X 和 Y 轴平行且同方
向于图像像素坐标系的 X 和 Y 轴的二维图像坐标系。
4. 像素坐标系:以相机成像面右上角为原点,X 轴为从左向右为正方
向,Y 轴为从上到下为正方向。
图 3.4 相机各坐标系之间的变换关系
以上四个坐标系之间的关系如图 3.4 所示,点 M 在世界坐标系下有一个坐
标,可以通过相机外参数将世界坐标系下的坐标映射到相机空间坐标系下,通过
相机的内参数把相机空间坐标系下的坐标点映射到像素坐标系下,具体实现如下,
以下推导建立在相机已经完成标定,无图像畸变的条件下。
图 3.5 坐标系之间的详细的变换关系


第 3 章 三维重建与坐标变换
19
由图 3.5 所示,通过使用旋转和平移等欧式变换的方法,把图 3.4 在
世界坐标系下的点 M 转化为相机空间坐标系下的点 M,这两个坐标系之
间 的 变 换 关 系 由 相 机 的 外 参 矩 阵 进 行 描 述 , 具 体 的 关 系 如 公 式 (3.1)所 示 ,
其中[R t] 矩阵为相机的外参矩阵,R 矩阵为一个3 × 3的旋转矩阵,t矩阵
为一个3 × 1的平移矩阵
[
xCM yCM zCM
] = [R t]
[
xMW yMW
zMW
1]
(3.1)
通过相机的外参矩阵获取了在相机空间坐标系下的点 M 坐标。回顾图
3.3,分 析 负 焦 平 面 等 效 的 图 像 的 像 与 实 际 物 体 的 大 小 ,可 以 等 到 如 下 等 式 ,
公 式 (3. 2)中 highreal 为 实 际 物 体 的 高 度 ,highimage 图 像 中 物 体 的 高 度 ,两 者
的单位相同。
u
v = highreal
highimage
(3.2)
将等式推广到图 3.4 所示的三维空间内会等到如下关系,如公式(3.3)
所示,其中(xM, yM, zM)为相机空间坐标系下的空间坐标,(xm, ym) 为在相机
图像坐标系下的图像坐标。
zM
d = xM
xm
= yM
ym
(3.3)
由公式(3.3)可得公式(3.4)所示,其中d为光心到成像平面的像距。
xm = d
zM
⋅ xM, ym = d
zM
⋅ yM (3.4)
变成矩阵的形式如公式(3.5)所示。
[
xm
ym 1
]=
[
d
zM
00
0d
zM
0
001
zM]
[
xM yM zM
] (3.5)
整理得。


第 3 章 三维重建与坐标变换
20
[
xm
ym 1
]= 1
zM
[
d00 0d0 001
][
xM yM zM
] (3.6)
公 式 (3.6)就 是 一 点 从 相 机 空 间 坐 标 系 到 相 机 图 像 坐 标 系 之 间 的 变 换
关系。当获得了图像坐标系下的与相机空间坐标系单位相同的图像坐标,
要 变 换 为 像 素 坐 标 系 下 的 像 素 坐 标 。为 实 现 这 个 变 换 需 要 将 图 像 坐 标 系 下
的单位通过相似变换变化为像素。要实现这个变换需要明确相机成像面一
个成像单元的大小。
图 3.6 成像面成像单元
在不考虑成像单元存在错切量的条件下,成像单元的长度为 xunit宽度
为yunit,那么从图像坐标系到像素坐标系的尺度变换关系如公式 (3.7)所示。
[
x′ y′
1
]=
[
1
xunit
00
01
yunit
0
0 0 1]
[
xm
ym 1
] (3.7)
由 于 像 素 坐 标 系 的 原 点 位 于 图 像 左 上 角 处 ,但 是 在 公 式 (3.7)坐 标 系 原
点在图像中心处。所以要进行一次平移变换,将原点移到左上角处,故从
图像坐标系到像素坐标系的变换关系如公式(3.8)所示。
[
x y 1
]=
[
1
xunit
0 txunit
01
yunit
tyunit
0 0 1]
[
xm
ym 1
] (3.8)


第 3 章 三维重建与坐标变换
21
公式(3.5)与公式(3.8)的结合即为描述相机空间坐标系到像素坐标系之
间的变换关系。
[
x y 1
]= 1
zM
[
1
xunit
0 txunit
01
yunit
tyunit
0 0 1]
[
d00 0d0 001
][
xM yM zM
] (3.9)
对上述等式进行简化得公式(3.10)。
[
x y 1
]= 1
zM
[
fx 0 txunit
0 fy tyunit
00 1
][
xM yM zM
] (3.10)
那 么 ,世 界 坐 标 系 下 的 点 到 像 素 坐 标 系 下 的 变 换 就 如 公 式 (3.11)所 示 。
[
x y 1
]= 1
zM
[
fx 0 txunit
0 fy tyunit
00 1
] [R t]
[
xMW yMW
zMW
1]
(3.11)
其中[
fx 0 txunit
0 fy tyunit
00 1
]为 相 机 的 内 参 矩 阵 ,描 述 相 机 空 间 坐 标 系 到 像 素 坐
标系的变换关系,而矩阵 [R t]为相机的外参数矩阵描述世界坐标系与相
机空间坐标系的变换关系。想要通过一个相机获取目标在相机空间坐标系
下 的 位 置 , 本 质 上 就 是 计 算 相 机 的 外 参 数 矩 阵 的 平 移 矩 阵 t。
3.3 装甲板的三维世界的重建
3.3.1 使用 PNP 算法求解外参平移矩阵简述
图 3.7 PNP 求解相机空间坐标系下物体的位置


第 3 章 三维重建与坐标变换
22
PNP 算法本质上就是在已知相机内存矩阵的条件下,通过多组对应的
像素坐标系下的坐标点与真实世界坐标系下的坐标点,推导或者拟合出两
者之间的关系,由于相机内参矩阵已知,那么可以通过用相机的内参数矩
阵 对 求 解 或 者 拟 合 的 结 果 求 逆 变 换 得 到 相 机 的 外 参 数 矩 阵 , 其 中 R矩 阵 描
述相机空间坐标系为父坐标系到世界坐标系的旋转关系,而 t矩阵则描述平
移关系,如图 3.7 所示,本文主要是计算t矩阵获取两者之间的平移关系,
以此获取在相机空间坐标系下物体/世界坐标系的原点的位置。
3.3.2 在相机空间坐标系下装甲板的目标定位
图 3.8 以装甲板中心为原点的世界坐标系
在实际装甲板定位中,由于之间在装甲板检测中,获取了装甲板上两
根灯条 A,B,C,D 点的像素坐标,由于装甲板大小恒定,可以通过机械
测量,计算出以装甲板的中心位置为原点,与图 3.8 同一坐标轴下的,A,
B,C,D 四点物理坐标,通过上述 PNP 方法,求解相机的外参数矩阵,以
此获得在相机空间坐标系下装甲板中心的空间坐标。


第 3 章 三维重建与坐标变换
23
3.4 坐标变换
图 3.9 机器人各组件分布
上一节通过 PNP 算法获取了在相机空间坐标系下的识别对象的三维空间坐
标,本节将在上一部分基础上将目标在相机空间坐标系下的坐标变换到以机器人
云台转轴为原点的惯性坐标系下,具体方法如下。
在进行坐标变换之间先定义以下三个坐标系,如图 3.9 所示,
1. 相机空间坐标系:该坐标系与 3.2 节所定义的相机空间坐标系定义
相同。
2. 云台坐标系:该坐标系原点位于机器人云台转轴交点处,坐标轴方
向为以机器人云台 pitch 从坐标系原点到 pitch 轴发射原点为 x 轴正
方向,从原点指向上侧为 z 轴正方向的一个笛卡尔坐标系。
3. 惯性坐标系:该坐标系原点与机器人云台坐标系原点相同,坐标系
方向与世界坐标系方向相同。


第 3 章 三维重建与坐标变换
24
在实现坐标变换时,首先通过平移变换将相机空间坐标系下的坐标变换到云
台坐标系,然后利用机器人云台的 IMU 数据将云台坐标系下的坐标进行旋转变
换变换到惯性坐标系下。
3.5 效果演示
图 3.10 三维重建与坐标变换效果
如图 3.10 所示,该图为对检测到的目标进行三维重建,在重建之后对
目标使用 IMU 数据进行坐标变换,将识别到的目标变换到惯性坐标系下。
在图 3.10 中,机器人自身云台发生转动,但是检测到的目标的位置不会发
生变化,坐标变换正常运行,且效果符合预期。
3.6 本章小结
本章介绍了在进行目标检测同时获取目标的像素坐标之后,通过 PNP
算法进行三维重建,获取目标在相机空间坐标系下的三维坐标,同时通过
坐标的平移和旋转变换,利用 IMU 数据将目标从相机空间坐标系变换到
惯性坐标系下的过程。


第 4 章 机器人运动学建模与状态观测
25
第 4 章 机器人运动学建模与状态观测
4.1 本章简述
在上一章,通过 PNP 进行三维重建和利用 IMU 数据将目标坐标从相
机 空 间 坐 标 系 变 换 到 惯 性 坐 标 系 下 。传 统 的 机 器 人 辅 助 瞄 准 算 法 在 这 一 步
就已经结束。但是仅仅于此,机器人辅助瞄准系统是不完善的,无法击打
动态目标,原因如下。
图 4.1 静态目标击打与动态目标击打
机 器 人 辅 助 瞄 准 系 统 的 本 原 理 是 对 目 标 进 行 定 位 ,然 后 根 据 定 位 到 的
目标三维坐标,计算机器人云台的 yaw 轴和 pitch 轴的角度,然后使用 PID
控制器控制机器人云台到达对应的角度,然后进行打击。如图 4.1,在传统
机 器 人 辅 助 瞄 准 系 统 中 ,由 于 仅 对 从 相 机 中 采 集 的 当 前 时 间 的 图 像 中 的 目
标进行定位,然后根据定位信息进行击打,在这种情况下仅能完成对与静
态目标的打击,但是对于具有移动能力的动态目标,会产生当弹丸落到目
标 位 置 时 ,目 标 发 生 了 位 移 ,弹 丸 会 落 到 过 去 的 位 置 ,最 终 弹 丸 无 法 命 中 。


第 4 章 机器人运动学建模与状态观测
26
图 4.2 动态目标的击打
如图 4.2,想解决传统机器人辅助瞄准系统无法击打动态目标的问题,
最 基 础 的 方 式 是 观 测 目 标 的 运 动 状 态 ,根 据 目 标 的 当 前 的 位 置 和 速 度 信 息
来推断弹丸飞至目标距离时,目标的位置,这样就可以实现精准的打击。
本章主要就是介绍击打动态目标的第一步,目标运动状态观测的实现。本
章节代码见附录 1-3 机器人运动学建模与状态观测部分的程序代码。
4.2 扩展卡尔曼滤波器(EKF)
4.2.1 使用扩展卡尔曼滤波器的缘由
由于在对目标做三维重建是通过 PNP 算法进行实现,不可避免的会因
为像素波动等原因,目标在相机空间坐标系下的目标会产生噪声。数据非
常不稳定且数值相较于真实值有所差距,同时由于系统在建模时存在非线
性因素,所以在实现目标运动状态观测时,本系统选择使用扩展卡尔曼滤
波器进行状态观测,不仅能够完成状态观测的功能,同时也能够降低噪声
获取当前时刻的一个最优的估计值。


第 4 章 机器人运动学建模与状态观测
27
4.2.2 扩展卡尔曼滤波器原理简述
图 4.3 卡尔曼滤波器原理
在介绍扩展卡尔曼滤波器之前,先简要介绍一下卡尔曼滤波器。如图
4.3 所示,卡尔曼滤波器是对通过数学模型获取的先验估计值和通过传感
器测量获得的测量值进行数据融合,在数据融合之前,通过先验误差协方
差矩阵计算数据融合后的后验误差协方差矩阵最小时的增益,利用这个增
益获取最优当前时刻的后验估计值。
而扩展卡尔曼滤波器是建立在卡尔曼滤波器的基础上进一步设计而
产生的。卡尔曼滤波器主要为了处理线性系统的状态观测问题。而扩展卡
尔 曼 滤 波 器 主 要 是 处 理 非 线 性 系 统 的 状 态 观 测 问 题 。扩 展 卡 尔 曼 滤 波 器 在
先验估计时对系统使用泰勒级数在工作点处做线性化,然后利用线性化的
结果做先验估计。
4.3 机器人运动学建模
图 4.4 小陀螺技术


第 4 章 机器人运动学建模与状态观测
28
如图 4.4 所示,由于在 RoboMaster 比赛中导电滑环的广泛应用,机器
人底盘不仅能够完成简单的平移运动,而且还能够完成旋转运动,甚至能
够完成平移与旋转运动的叠加。在这种条件下,传统目标跟踪使用的 CV
(constant velocity)模型,即恒定速度运动模型,无法解决这种平移加旋
转运动的描述。为描述这种平移与旋转运动迭代的运动。本系统设计了如
下运动学模型。
图 4.5 机器人运动学建模
如图 4.5,图中装甲 板坐标为 (xa, ya)机器人中心位置坐标为(xc, yc), r
为机器人的半径,θ为这一坐标对应的 yaw 角,由图可知,从机器人装甲
板 到 机 器 人 中 心 的 几 何 关 系 如 公 式 (4.1)所 示
xc = xa + r × cos(θ), yc = ya + r × sin(θ) (4.1)
通过上述公式建立了装甲板坐标到目标机器人中心坐标的映射关系,
通过该映射关系,可以通过识别到的装甲板目标计算机器人中心的位置,
通过机器人中心位置和当前装甲板的偏航角推导其他装甲板的位置,这样
就完成了整车的运动学观测。


第 4 章 机器人运动学建模与状态观测
29
由于在实际赛场中机器人的底盘装甲板的运动为平动和旋转运动的
叠加,但是机器人中心却只存在平移运动,在设计扩展卡尔曼滤波器的状
态 转 移 矩 阵 时 ,可 以 设 计 针 对 机 器 人 中 心 的 状 态 转 移 矩 阵 ,如 公 式 (4.2)所
示。
xck = xck−1 + vxck−1 × dt
yck = yck−1 + vyck−1 × dt
zck = zck−1 + vzck−1 × dt
θk = θk−1 + vθk−1 × dt
(4.2)
设 系 统 的 状 态 变 量 为x = [xc, vxc, yc, vyc, zc, vzc, θ, vθ, r]T, 故 系 统 的 状 态
转移矩阵如公式(4.3)所示
A=
[
1 dt 0 0 0 0 0 0 0 010000000 0 0 1 dt 0 0 0 0 0 000100000 0 0 0 0 1 dt 0 0 0 000001000 0 0 0 0 0 0 1 dt 0 000000010
0 0 0 0 0 0 0 0 1]
(4.3)
设系统的观测变量为 y = [xa, ya, za, θ]T,由公式(4.1)机器人运动学关系,
可得观测方程如公式(4.4)所示。
xa = xc − r × cos(θ) ya = yc − r × sin(θ) za = za θ=θ
(4.4)
由于要使用扩展卡尔曼滤波器,故非线性的观测方程对状态变量x求
导得观测方 程的雅 可 比矩阵 HJacobi,然后利用 观 测方程的雅 可比矩 阵 输入
到扩展卡尔曼滤波器中进行状态观测。


第 4 章 机器人运动学建模与状态观测
30
4.4 单目标跟踪器的实现
图 4.6 乱战
在使用扩展卡尔曼滤波器时,要保证是一直对同一个目标进行跟踪。
如图 4.6 所示,但是在实际比赛中多为乱战,这就引发一个问题,要保证
一直跟踪一个目标,不能用错误目标以及和错误的数据来做扩展卡尔曼滤
波器的估计。所以在使用扩展卡尔曼滤波在获取先验估计值和先验误差之
后,计算卡尔曼增益、后验估计和误差协方差矩阵之前要对,通过相机获
得的测量值进行筛选和过滤,要一直保证用同一个目标的数据。具体方法
如下。
图 4.7 单目标跟踪的实现
如图 4.7 所示,单目标跟踪实现的根本思想是通过扩展卡尔曼滤波器
预 测 获 得 的 先 验 估 计 值 和 观 测 器 的 测 量 值 进 行 数 据 匹 配 ,匹 配 通 过 进 行 扩
展卡尔曼滤波器的更新操作,获取后验估计值。在进行数据匹配时,由于


第 4 章 机器人运动学建模与状态观测
31
在 第 二 章 装 甲 板 识 别 层 面 在 第 二 层 判 断 使 用 神 经 网 络 进 行 了 数 字 识 别 ,故
在本章节,单目标跟踪的实现,是根据装甲板上的数字进行过滤,保证一
直识别统一目标。同时为了防止卡尔曼滤波错误估计,在数据匹配时在完
成数字匹配后,同时进行了数据的匹配,将先验估计值和测量值的位置求
差值,然后取模,根据模值,判断是否差别过大,如果差别过大且长时间
都是差距过大的状态会重置扩展卡尔曼滤波器。
4.5 效果演示
4.5.1 机器人运动学建模效果演示
图 4.8 机器人运动学建模效果演示
机器人运动学建模的效果如图 4.8 所示,图中展示了我方机器人识别
前侧旋转目标的效果,右图为机器人运动学建模的展示,通过识别到的目
标推导机器人的中心,通过中心位置,计算其他装甲板的位置。
4.5.2 扩展卡尔曼滤波器观测目标运动状态效果演示
图 4.9 扩展卡尔曼滤波器效果演示
如图 4.9 所示,该图通过扩展卡尔曼滤波观测旋转装甲板的估计量,
在视觉识别稳定且 PNP 三维重建和坐标变换稳定的条件下,数据明显完成


第 4 章 机器人运动学建模与状态观测
32
收敛,由于使用扩展卡尔曼滤波器,估计数据相较于真实值误差极小并且
数据也比较稳定可以用于目标预测。
4.5.3 单目标跟踪器效果演示
图 4.10 单目标跟踪器效果演示
图 4.10 为单目标跟踪效果演示,图中为我方机器人当遇到地方多台机
器人时,尽管视觉识别敌方多台机器人,但是目标跟踪仅对单一对象,另
外 一 个 对 象 在 单 目 标 跟 踪 的 数 据 匹 配 时 就 直 接 被 筛 选 掉 。在 视 觉 跟 踪 层 面 ,
尽管存在多个识别目标,在扩展卡尔曼滤波器后验估计之前,也会通过单
目 标 跟 踪 器 ,利 用 神 经 网 络 识 别 到 的 数 字 和 数 据 匹 配 度 去 除 掉 不 符 合 要 求
的对象,使用符合要求的数据进行后验估计。


第 4 章 机器人运动学建模与状态观测
33
4.6 本章小结
在本章节,通过建立机器人运动学模型,然后通过扩展卡尔曼滤波器
对目标的运动状态进行观测,获取最优的观测量,同时为了防止出现错误
的后验估计,通过数据匹配设计了单目标跟踪,保证尽管在出现多目标的
情况下也能保证持续跟踪同一个目标。


第 5 章 机器人目标的精准打击
34
第 5 章 机器人目标的精准打击
5.1 本章简述
回顾前三章的内容,在第二章,通过传统图像处理算法结合神经网络
算法实现了在图像中检测出装甲板的位置 。在第三章,通过 PNP 算法利用
相 机 内 参 矩 阵 获 取 外 参 ,进 而 获 取 从 相 机 空 间 坐 标 系 到 目 标 坐 标 系 之 间 的
变换关系,完成了三维的重建。在第四章,通过装甲板与机器人中心的几
何关系,建立了能够描述机器人旋转和平移的运动学模型,通过扩展卡尔
曼滤波器观测这个非线性系统的运动状态,本章节,将完成本系统最终的
目标,机器人目标的精准打击。
图 5.1 机器人精准打击流程图
具体的实现如图 5.1 所示,利用观测到的目标运动状态以及子弹飞行
时间以及数据延迟时间完成目标的状态预测,然后利于预测到的状态,利
用装甲板到机器人中心的几何关系计算在预测位置处的各个装甲板的位
置。然后根据各个装甲板的位置选择一块最好完成击打的装甲板,然后针
对这块装甲板,利用迭代法通过子弹飞行模型计算下坠补偿和仰角补偿,


第 5 章 机器人目标的精准打击
35
利用控制器控制机器人云台到达迭代弹道模型计算的仰角和被选择装甲
板,利用绝对坐标做反函数计算的偏航角,然后根据当前数据,判断是否
要进行开火。以下将分别介绍各个模块的实现。本章节代码见附录 1-4 机
器人目标的精准打击部分的程序代码。
5.2 目标状态预测
5.2.1 目标状态预测实现
扩展卡尔曼滤波获取的后验估计值为图像采集时刻的最优的估计值,
但 是 图 像 采 集 到 数 据 传 输 到 单 片 机 中 要 经 历 图 像 处 理 ,扩 展 卡 尔 曼 滤 波 器
计算,这两个环节都要花费一定的时间。
图 5.2 机器人发射机构
如图 5.2 所示,同时由于机器人发射机构的设计,弹丸通过左侧拨弹
盘 M2006 电机转动将弹丸通过弹链拨至右侧云台 pitch 轴摩擦轮让子弹打
出,从单片机命令发送到弹丸打出存在很大的发射延迟。这就导致一个问
题,即仅仅通过子弹飞行时间预测目标受击打时的状态是不够的,预测目
标运动状态要考虑图像以及数据处理延迟、发射延迟和子弹飞行时间,用
这三者的时间预测目标在受击时目标的状态,如公式(5.1)所示。
tpredic = tdelay + tfly
xcpredic = xccur + vxccur × tpredic
ycpredic = yccur + vyccur × tpredic
zcpredic = zccur + vzccur × tpredic
θpredic = θcur + vθcur × tpredic
(5.1)


第 5 章 机器人目标的精准打击
36
5.2.2 图像以及数据处理延迟的量测
图 5.3 延迟计算
由于图像以及数据处理部分是使用计算机进行完成,如图 5.3 所示,
计算机的接口函数可以获取计算机当前时间,时间精度达微妙级,所以在
计算图像以及数据处理通过在图像获取时在图像中附加获取的时间的信
息,在串口发送前一刻,将数据图像时间与当前时间做差值运算,所得时
间为图像以及数据处理时间,通过 USB 虚拟串口将数据传输至单片机。
5.2.3 发射延迟的量测
虽 然 原 理 相 同 ,但 是 子 弹 发 射 延 迟 的 量 测 不 同 于 图 像 以 及 数 据 处 理 的
延迟的量测,原因如下,可以通过单片机获取子弹发射命令的时间,但是
无法获得子弹发射出去的时间,针对这个问题,需要一个测量装置,测量
出子弹发出时的时间。
图 5.4 微动开关


第 5 章 机器人目标的精准打击
37
如图 5.4 所示,本文通过微动开关以及 STM32 的中断触发机制来获取
弹丸发射时的时间,基本思路是将微动开关安装至机器人发射机构前端,
摩擦轮位置处,微动开关一段连接单片机 5v 引脚另一端接至单片机 GPIO
口,当微动开关,GPIO 与 5V 引脚导通,利用 STM32 的高电平触发的外
部 中 断 ,来 实 时 判 断 是 否 微 动 开 关 按 下 ,按 下 说 明 弹 丸 打 出 ,在 此 刻 记 时 ,
通过与弹丸发射命令使能的时间做差值运算,即可获得发射延迟。
5.2.4 延迟时间较低的延迟的省略
延迟时间较低的延迟的省略 在实际系统中延迟相较于上文所提延迟
要更多,上述图像以及数据处理延迟和发射延迟为两个延迟大于 3ms 甚至
大于 50ms 的延迟,为两个主要的延迟,其他延迟时间如数据传输延迟,
单片机数据计算等延迟基本直接省略,省略原因如下。
图 5.5 RoboMaster 开发板 C 型
如图 5.5 所示,由于本系统在机器人控制板层面使用 RoboMaster C 型
开发板,开发板芯片 STM32F407IG 拥有高达 168MHz 的时钟频率数据运
算性能强劲,对视觉数据处理时间基本为微妙级。同时也因为单片机与计
算机之间的数据通信采用 USB 虚拟串口,数据传输速度极快,基本也为微
妙级。笔者在实际测试时发现基本可以不用考虑二者也能保证精准的击打,
故省略。


第 5 章 机器人目标的精准打击
38
5.3 整车运动状态计算
图 5.6 整车状态计算
如图 5.6 所示,在上一节通过延迟时间的量测计算出目标受击打时的
目标运动状态,利用 4.3 节构建出机器人中心到机器人装甲板之间的几何
关系,可以推导出在目标受击打时的目标机器人所有装甲板的位置如图 5.7
所示。
图 5.7 装甲板位置计算


第 5 章 机器人目标的精准打击
39
5.4 装甲板筛选
图 5.8 装甲板受击姿态
为 了 实 现 精 准 的 目 标 打 击 效 果 ,选 择 一 个 比 较 好 击 打 的 目 标 这 一 步 时
必不可少的。如图 5.8 所示,在实际测试中击打目标率高的目标其特点为
目标的姿态大多正对击打方向,如果装甲板姿态过于倾斜,由于各种误差
的存在,容易出现子弹飞出的现象,所以在筛选装甲板时要选择一块姿态
尽可能正对与受击打方向的装甲板。
图 5.9 装甲板选择


第 5 章 机器人目标的精准打击
40
由于在建模时使用装甲板的偏航角建立了装甲板与机器人中心的关
系,同时在通过扩展卡尔曼滤波进行状态观测时,将偏航角作为机器人的
状态变量的一部分。如图 5.9 所示,可以很清晰的看到姿态正对于受击打
方 向 的 装 甲 板 的 偏 航 角 与 我 方 机 器 人 到 敌 方 机 器 人 中 心 的 偏 航 角 相 同 。故
想要很好的击打目标,要在选择装甲板时,要选择偏航角与我方机器人到
敌方机器人中心偏航角误差最小的装甲板。
5.5 迭代弹道模型
5.5.1 迭代弹道模型构建的缘由
图 5.10 弹道轨迹
如图 5.10 所示,由于子弹的飞行受到重力和空气阻力的影响,导致子
弹飞行会产生下坠的现象,为了保证能够打中目标,就要构建弹道模型,
对子弹的下坠进行仰角补偿
5.5.2 弹道模型的构建
由于 RoboMaster 比赛中机器人发射的弹丸为一个均质的球体,所以
在构建弹道模型时,可以将其等效为一个小球抛体运动模型。


第 5 章 机器人目标的精准打击
41
图 5.11 弹道模型对比
由于建模复杂度的影响,笔者构建了三种弹道模型,依次为弹丸仅受
重 力 影 响 的 理 想 模 型 、弹 丸 不 仅 受 重 力 影 响 而 且 受 到 来 自 水 平 方 向 的 空 气
阻力影响的单方向空气阻力模型、弹丸受到重力和来自水平以及竖直方向
的空气阻力影响的完全空气阻力模型,图 5.11 为三种模型的效果对比,击
打的初始角度相同,弹丸初速度相同,但是子弹的轨迹不尽相同。
在实际测试中,笔者发现理想模型由于不考虑空气阻力,想要打中目
标,往往需要每间隔一段距离,通过改变弹速,来模拟落点位置,且子弹
飞行时间与实际飞行时间有一定差距,目标状态预测很容易不正确,所以
这种模型直接否绝。
单方向空气阻力模型由于只考虑水平方向的控制阻力,不考虑竖直方
向的空气阻力,在仰角较大的时候与实际弹道误差较大,故不采用。本文
使用完全空气阻力模型做弹丸下坠补偿,弹道基本和实际弹道相仿,具体
的完全空气阻力模型的编写,见附录 1-4 机器人目标的精准打击部分的程序代
码。


第 5 章 机器人目标的精准打击
42
5.5.3 迭代法求解下坠补偿后的仰角
图 5.12 牛顿迭代法求解仰角补偿
上 一 节 通 过 完 全 空 气 阻 力 模 型 输 入 目 标 距 离 和 仰 角 ,输 出 子 弹 弹 道 落
点。如图 5.12 所示,在这个基础上,要想计算仰角补偿,就可以通过牛顿
迭代法通过不断的试射、误差补偿,得出最后的仰角补偿的结果。
5.6 云台运动控制
图 5.13 机器人云台结构


第 5 章 机器人目标的精准打击
43
如图 5.13 所示,该图为辅助瞄准系统下,机器人云台的机械结构设计,
云台的 yaw 轴通过 yaw 轴电机带动机器人 yaw 轴进行角度控制,pitch 轴
通过 pitch 轴电机带动连杆进行角度控制,角度控制方法通过如下控制器
进行实现。
图 5.14 云台电机控制器设计
如图 5.14 所示,由于系统要跟踪高速运动目标,为了提升跟踪能力降
低跟踪误差,机器人云台采用了一个双环带速度前馈的 PID 控制器做云台
电机的控制。
图 5.15 前馈部分设计
由于观测器输出为直线速度和位置,电机控制输入为角度和角速度,
所以在电机控制的前馈部分需要把直线速度变为电机的角速度进行前馈。
前馈控制部分设计如图 5.15 所示,通过把目标的位置向量 pos逆时针 90 度


第 5 章 机器人目标的精准打击
44
的 旋 转 变 换 , 同 时 将 旋 转 后 的 结 果 做 单 位 化 为 posI , 然 后 将 目 标 的 速 度 向
量 v与 posI做 向 量 的 点 乘 获 取 目 标 的 速 度 向 量 在 云 台 线 速 度 方 向 的 投 影 vl
这个向量即为前馈控制器的速度输入。上述实现的系统框图如图 5.16 所
示。
图 5.16 前馈控制器设计
经过双环 PID 控制和前馈控制的结合,控制器的跟踪效果如图 5.17 所
示。
图 5.17 控制器跟踪效果


第 5 章 机器人目标的精准打击
45
图 5.17 所示,该图建立在有速度前馈的条件下,上图为电机位置环跟
踪效果,下图为电机速度环跟踪效果。在无速度前馈的条件下云台跟踪速
度信号效果较差,如图 5.18 所示。
图 5.18 有无速度前馈跟踪误差对比
红 色 曲 线 为 无 速 度 前 馈 的 条 件 下 的 跟 踪 误 差 ,误 差 会 持 续 存 在 无 法 消
除。黑色曲线为有速度前馈的条件下的跟踪误差,稳态误差为零。
5.7 开火控制
图 5.19 开火控制逻辑


第 5 章 机器人目标的精准打击
46
如图 5.19 所示,机器人开火控制主要是判断当前云台的转角与目标转
角是否在误差允许范围内,允许范围的计算主要是根据当前机器人与目标
之间的距离和目标大小而定。当云台的位置进入误差允许范围内,则开火
击打。
5.8 效果演示
5.8.1 静止目标击打效果
图 5.20 静止目标击打效果
如同 5.20 所示,该图为静止靶下不通距离目标击打展示,命中率为
100% ,说 明 本 系 统 在 目 标 检 测 ,三 维 重 建 ,坐 标 变 换 ,状 态 估 计 ,弹 道 补
偿数据能够稳定且正确的运行,弹无虚发。
5.8.2 旋转目标击打效果
图 5.21 旋转目标击打效果
如图 5.21 所示,该图为旋转目标的击打效果,统计命中率为 9/10,命
中率接近 100%,说明本系统在目标受击打位置预测,装甲板筛选层面是可
以稳定且正确运行的,可以稳定的击打旋转目标。


第 5 章 机器人目标的精准打击
47
5.8.3 平动目标击打效果
图 5.22 平动目标击打效果
如图 5.22 所示,该图为平动目标的击打效果,命中率为 7/10,命中率
较高,说明云台控制器可以稳定跟踪动态目标,且可以消除跟踪误差。
5.9 本章小结
本 章 在 前 几 个 章 节 的 基 础 上 ,完 成 了 机 器 人 辅 助 瞄 准 系 统 的 最 后 一 环 ,
实现了云台受击打位置的预测,整车状态的计算,装甲板弹道补偿,设计
控制器实现云台动态目标的快速跟踪。


第 6 章 总结和展望
48
第 6 章 总结和展望
6.1 总结
在 第 二 章 ,根 据 装 甲 板 的 形 态 特 征 用 传 统 的 图 像 处 理 算 法 识 别 装 甲 板
的灯条,然后用长宽匹配,匹配装甲板,将识别到的可疑装甲板用神经网
络算法进行分类,两层判断识别装甲板。这种传统图像处理算法附加神经
网络算法进行目标检测,不仅在检测准确度上高于传统算法,也在运行效
率高于纯神经网络算法。
在第三章,讲述了利用 PNP 进行三维重建原理,同时介绍了本系统如
何通过 PNP 算法实现装甲板目标从二维到三维变换,获取在相机空间坐标
系下的装甲板坐标。在最后将目标从相机空间坐标系到惯性坐标系的变换。
在第四章,介绍了机器运动学模型的构建,以及利用构建的运动学模
型同扩展卡尔曼滤波器,观测当前目标的运动状态,以便进行目标的受击
打位置的预测。
在第五章,介绍了机器人受击打时刻状态的预测的实现,以及机器人
整体运动状态的计算和最好受击打装甲板的选择。在选择完装甲板后,为
了 计 算 弹 道 下 坠 补 偿 ,构 建 了 完 全 空 气 阻 力 弹 道 模 型 和 用 迭 代 法 求 解 云 台
仰角补偿。在最后为了提升云台跟踪动态目标的能力,建立了双环带速度
前馈的机器人云台控制器进行云台跟踪控制。
6.2 展望
在系统实际测试中三维重建部分,由于使用单目视觉测距算法,目标
三维重建的精度较低,误差为厘米级别,随着测距位置的变化,误差也在
不断的变化,同时加上机械结构装配问题而产生的误差难以量测,致使观
测器难以收敛,下一步想考虑使用双目测距算法进行三维重建 以提升精度,
同时研究误差的量测方法,抑制误差对系统的干扰。
在弹丸下坠补偿中由于建模精度的影响,子弹的轨迹与模型轨迹在远
距离或者大仰角的情况下拟合度较低,机器人仰角容易出现错误的补偿,
下一步将建立更加精准的模型,提升精度。


参考文献
49
参考文献
[1] 周振杰, 李绍辉, 李杏华. 基于机器视觉的海上单桩图像处理与垂直度数据
获取方法研究[J]. 自动化与仪表, 2025, 40(05): 134-139.
[2] 尹宏鹏, 陈波, 柴毅, 等. 基于视觉的目标检测与跟踪综述[J]. 自动化学报,
2016, 42(10): 1466-1489.
[3] 鲍阚. 智能车辆近场物体探测及其状态识别方法研究[D]. 吉林大学, 2016.
[4] 万为康. RoboMaster 步兵机器人基于视觉识别及跟踪移动目标算法实现[D].
南昌大学, 2022.
[5] 张泊宁, 杜忠华, 鲍科著. 基于机器视觉的二轴云台的目标跟踪设计[J]. 电
子设计工程, 2019, 27(12): 152-157.
[6] 朱朔. 基于机器视觉的无人平台目标识别与跟踪系统设计[D]. 南京理工大
学, 2018.
[7] 曹奇. RoboMaster 步兵机器人控制系统设计[D]. 南昌大学, 2022.
[8] Park, F. C .Computational aspects of the product-of-exponentials formula for
robot kinematics[J]. IEEE Transactions on Automatic Control, 1994, 39(3): 643
647.
[9] Aspragathos NA, Dimitros JK. A comparative study of three methods for robot
kinematics[J]. IEEE Trans Syst Man Cybern B Cybern. 1998; 28(2): 135-45.
[10] Liu Z, Zhang Y, Wang Y. A Type-2 Fuzzy Switching Control System for Biped
Robots[J]. IEEE Transactions on Systems Man & Cybernetics Part C, 2007, 37(6):
1202-1213
[11] Zhang H, Cheng P, Shi L, et al. Optimal DoS Attack Scheduling in Wireless
Networked Control System[J]. IEEE Transactions on Control Systems
Technology, 2015, 24(3): 1-1
[12] 于立强. 基于机器视觉的手写数字识别与目标追踪技术研究[D]. 燕山大学,
2019.
[13] Gupte S, Masoud O, Martin R F K, et al. Detection and Classification of
Vehicles[J]. IEEE Transactions on Intelligent Transportation Systems, 2002, 3(1):
37-47.
[14] Barron J L, Fleet D J, Beauchemin S S. Performance of Optical Flow
Techniques[J]. International Journal of Computer Vision, 1994, 12(1): 43-77.


参考文献
50
[15] Ha M, Wang C, Chen J. The Support Vector Machine Based on Intuitionistic
Fuzzy Number and Kernel Function[J]. Soft Computing, 2013, 17(4): 635 -641.
[16] Song H, Ding Z, Guo C, et al. Research on Combination Kernel Function of
Support Vector Machine[C]// International Conference on Computer Science &
Software Engineering. IEEE, 2008: 838-841.
[17] 宋珣, 马智博. 基于运动学建模的自动瞄准系统[J]. 现代计算机, 2020(36):
9-14.
[18] 李美红, 尹健, 徐劲祥. 基于 EKF 的机载光电吊舱目标定位研究[J]. 弹箭
与制导学报, 2016, 36(06): 157-161.
[19] Hoshiya M , Saito E .Structural Identification by Extended Kalman Filter[J].
Journal of Engineering Mechanics, 1984, 110(12): 1757-1770.
[20] 王洪玺, 计泽贤, 张兰勇. 基于卡尔曼滤波的目标识别跟踪与射击系统设计
[J]. 兵器装备工程学报, 2022, 43(11): 286-296.
[21] 储开斌, 赵爽, 冯成涛. 基于 Mahony-EKF 的无人机姿态解算算法[J]. 电子
测量与仪器学报, 2020, 34(12): 12-18.
[22] 康国华, 刘建业, 熊智. 导航系统中量测滞后异步多传感器集中滤波算法
[J]. 东南大学学报(自然科学版), 2005(05): 60-64.
[23] 范磊, 周琳. 基于四阶龙格-库塔法的多弹道并行计算研究[J]. 航空科学技
术, 2024, 35(09): 101-110.
[24] 徐亚军, 王钰, 宋贤龙. 基于四阶龙格-库塔公式的火控系统瞄准角修正模
型[J]. 火力与指挥控制, 2020, 45(05): 111-114+124.
[25] 卫超奇, 李威. 基于卷积神经网络的自动反击的研发设计 [J]. 农业装备与
车辆工程, 2020, 58(05): 139-141
[26] REDMON J, DIVVALA S, GIRSHICK R, et al. You only look once: Unified,
real-time object detection[C]//Proceedings of the IEEE conference on computer
vision and pattern recognition,2016: 779-788
[27] Meier T, Ngan K N. Video Segmentation for Content-Based Coding[J]. IEEE
Transactions on Circuits and Systems for Video Technology, 1999, 9(8): 1190
1203.
[28] 李明磊. 计算机视觉三维测量与建模[M]. 北京: 电子工业出版社, 2022.
[29] 周泽华, 吴向东, 陈自洋, 等. 基于颜色形状识别和 PnP 算法的单目视觉轨
道边坡位移检测方法[J]. 湘南学院学报, 2023,44(02): 37-41.


参考文献
51
[30] 郭克友, 杨民, 张沫, 等. 基于透视 N 点模型的实时单目深度估计方法[J].
激光与光电子学进展, 2021, 58(06): 329-338.
[31] 冷大炜. 基于单目视觉的三维刚体目标测量技术研究[D]. 清华大学, 2011.
[32] 郑伟. 基于视觉的微小型四旋翼飞行机器人位姿估计与导航研究[D]. 中国
科学技术大学, 2014.
[33] 吴福朝, 胡占义. PnP 问题的线性求解算法[J]. 软件学报, 2003, (03): 682-688.
[34] 孙潇雨, 雷腾, 丁源, 等. 一种基于 PnP-ADMM 的快照式关联成像图像重
构算法[J]. 半导体光电, 2025, 46(01): 135-141.
[35] 王天威, 黄军魁. 控制之美[M]. 北京: 清华大学出版社, 2023.
[36] 王海军, 刘进忙. 基于卡尔曼滤波的无源雷达目标跟踪分析[J]. 战术导弹
技术, 2005, (06): 43-45+48.
[37] 崔乃刚, 张龙, 王小刚, 等. 自适应高阶容积卡尔曼滤波在目标跟踪中的应
用[J]. 航空学报, 2015, 36(12): 3885-3895
[38] RYOO Y J. Development of an autonomous mobile robot platform for smart
farms[J]. International Journal of Fuzzy Logic and Intelligent Systems, 2023,
23(2): 107-116.
[39] MOHANRAJ D, ARULDAVID R, VERMA R, et al. A review of BLDC motor:
state of art, advanced control techniques, and applications[J]. IEEE Access,
Institute of Electrical and Electronics Engineers(IEEE), 2022 (10): 54833-54869.
[40] CHINTHAMALLA R, KARAMPURI R, JAIN S, et al. Dual solar photovoltaic
fed three-phase open-end winding induction motor drive for water pumping sys
tem application[J]. Electric Power Components and Systems,Informa UK Limited,
2018, 46(16-17): 1896-1911


致谢
52
致谢
非常感谢我的毕业设计指导老师——赵建荣老师,对我毕业设计工作
的 辛 勤 指 导 以 及 大 力 支 持 。非 常 感 谢 我 的 母 校 — — 山 东 理 工 大 学 对 我 的 四
年以来的辛勤培养。我非常荣幸能够成为一名自动化专业的学子,我非常
感谢自动化专业的老师们对我的培养。
我非常感谢我的父母对我一直以来支持。没有父母的支持,我在自动
化技术以及机器人技术上的追求就难以继续;没有父母的支持,我大学四
年的成就难以实现。我对父母的感激无以言表。
我非常感谢我的同学——程建,是他为我点燃了机器人技术之火,是
他带领我进入了陪伴我四年的实验室——齐奇。在齐奇,我见到我的学长
——夏齐隆,是他向我展示了一个用 IMU 与 PID 实现自稳定的机器人云
台,那一刻我爱上了控制技术。
我 非 常 感 谢 齐 奇 哨 兵 组 的 同 伴 — — 高 启 发 和 王 亚 栋 ,是 他 们 陪 我 完 成
了我的 RoboMaster2023 赛季。回顾那个赛季,我们三人在实验室奋战,把
所有的课余时间都献给了辅助瞄准系统的构建,理解着庞大的相关的知识
体系,不断的写代码测代码,不断的去发现问题解决问题。那一段时光是
我觉得最累的,但是也是最有收获的。
我非常感谢陈君学长对我们哨兵组机器人辅助瞄准技术的大力支持。
我非常感谢我的学弟——齐浩龙,是他为我提供了完整的资料,为机器人
辅 助 瞄 准 技 术 的 再 研 发 提 供 了 基 础 。我 非 常 感 谢 我 的 哨 兵 组 的 学 弟 — — 陈
浩然,他为我完成机器人辅助瞄准技术的最后一环提供了巨大的帮助。


附录
53
附录