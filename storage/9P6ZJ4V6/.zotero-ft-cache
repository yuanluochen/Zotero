1
目录
第一章 复杂性分析初步 ........................1
第一节 空间复杂性 ..........................1
第二节 时间复杂性......................... 5
第三节渐进符号........................... 11
第四节线性递归方程求解 ...................... 15
习题 一 .............................. 17
第二章 图与遍历算法 ....................... 20
第一节 图的基本概念和性质 .......... ......... 20
第二节 图的遍历算法 ........................ 27
第三节 2-连通图与网络可靠性 ................. 34
第四节 对策树 .......................... 38
习题 二 ............................... 44
第三章 分治算法 ...........................46
第一节 算法基本思想 ....................... 46
第二节 排序算法 ......................... 50
第三节 选择问题 .......................... 59
第四节 关于矩阵乘法 ....................... 61
第五节 快速 Fourier 变换..................... 63
第六节 最接近点对问题 ...................... 66
习题 三 .............................. 69
第四章 贪心算法 ...........................80
第一节 算法基本思想 .........................80
第二节 调度问题 .......................... 83
第三节 最优生成树问题 ....................... 89
第四节 单点源最短路径问题...................... 93
第五节 Huffman 编码 ......................... 96
第六节 贪心算法优性理论 ...................... 99
习题 四 ..............................102
第五章 动态规划算法 ......................... 107
第一节 算法基本思 ......................... 107
第二节 多段图问题.......................... 113


2
第三节 0/1 背包问题 .........................115
第四节 流水作业调度问题 ..................... 122
第五节 最优二叉搜索树 ....................... 126
习题 五 ............................... 130
第六章 回溯法............................. 133
第一节 算法基本思想 ........................ 133
第二节 定和子集问题和 0/1 背包问题 ................ 136
第三节 n-皇后问题和旅行商问题 ................... 140
第四节 图的着色问题 ........................144
第五节 回溯算法的效率分析 ..................... 147
习题 六 ............................... 152
第七章 分枝-限界算法 ....................... 158
第一节算法基本思想 ........................ 158
第二节 0/1 背包问题的分枝限界算法 ................ 160
第三节 电路板布线问题 ...................... 164
第四节 优先级的确定与 LC-检索 .................. 167
第五节 旅行商问题的分枝限界算法 ................. 173
习题 七 ............................... 176
第八章 NP-完全问题 ..........................180
第一节 关于问题及算法的描述 .................... 180
第二节 图灵机与确定性算法......................182
第三节 NP-类问题...........................184
第四节 NP-完全问题..........................191
第五节 证明新问题是 NP-完全问题的方法 .............193
第六节 图灵归约与 NP-困难问题 ................... 204
习题 八 ...............................206
第九章 近似算法设计与分析.......................211
第一节 近似算法概述 .......................... 211
第二节 集合覆盖问题与子集合问题的近似算法............. 213
第三节 近似算法的性能比 ........................217
附录 1 关于 C++程序设计 ........................223


3
第一节 模板函数.............................223
第二节 动态存储分配与异常引发....................228
第三节 C++的类与模板函数 .......................230
第四节 重载与友元 ..........................236
第五节 检测与调试 ..........................240
附录 2 几种常用的数据结构.......................244
第一节 栈和队列 ...........................244
第二节 二叉树 ........................... 248
第三节 堆 ...............................256
第四节 集合树 ............................262
第五节 图的表示 ...........................267
附录 3 ALGEN 语言 ........................... 272


第一章 复杂性分析初步 1
第一章 复杂性分析初步
程序性能(program performance)是指运行一个程序所需的内存大小和时
间多少。所以,程序的性能一般指程序的空间复杂度和时间复杂度。性能评估主
要包含两方面,即性能分析(performance analysis)与性能测量(performance
measurement),前者采用分析的方法,后者采用实验的方法。
考虑空间复杂性的理由
1) 在多用户系统中运行时,需指明分配给该程序的内存大小;
2) 想预先知道计算机系统是否有足够的内存来运行该程序;
3) 一个问题可能有若干个不同的内存需求解决方案,从中择优;
4) 用空间复杂性来估计一个程序可能解决的问题的最大规模。
考虑时间复杂性的理由
1) 某些计算机用户需要提供程序运行时间的上限(用户可接受的);
2) 所开发的程序需要提供一个满意的实时反应。
选取方案的原则:如果对于解决一个问题有多种可选的方案,那么方案的选
取要基于这些方案之间的性能差异。对于各种方案的时间及空间的复杂性,最好
采取加权的方式进行评价。但是随着计算机技术的迅速发展,对空间的要求往往
不如对时间的要求那样强烈。因此我们这里的分析主要强调时间复杂性的分析。
§1 空间复杂性
程序所需的空间主要包括:指令空间、数据空间、环境栈空间。
1. 指令空间 用来存储经过编译之后的程序指令。大小取决于如下因素:
1) 把程序编译成机器代码的编译器;
2) 编译时实际采用的编译器选项;
3) 目标计算机。
所使用的编译器不同,则产生的机器代码的长度就会有差异;有些编译器带
有选项,如优化模式、覆盖模式等等。所取的选项不同,产生机器代码也会不同。
采用优化模式可以缩减机器代码,但要多消耗时间。此外,目标计算机的配置也
会影响代码的长度。例如,如果计算机具有浮点处理硬件,那么,每个浮点操作
可以转化为一条机器指令。否则,必须生成仿真的浮点计算代码,使整个机器代
码加长。
2. 数据空间 用来存储所有常量和变量的值。
1) 存储常量和简单变量;所需的空间取决于所使用的计算机和编译器,以及
变量与常量的数目;


第一章 复杂性分析初步
2
2) 存储复合变量;包括数据结构所需的空间及动态分配的空间;
计算方法:结构变量所占空间等于各个成员所占空间的累加;数组变量所占
空间等于数组大小乘以单个数组元素所占的空间。例如
double a[100]; 所需空间为 100×8=800
int matrix[r][c]; 所需空间为 4×r×c
C++基本数据类型(32 位字长机器)
3. 环境栈空间 保存函数调用返回时恢复运行所需要的信息。当一个函数
被调用时,下面数据将被保存在环境栈中:
1) 返回地址;
2) 所有局部变量的值、递归函数的传值形式参数的值;
3) 所有引用参数以及常量引用参数的定义(此部分参看附录 1)。
注:问题的实例特征是决定问题规模的那些因素,主要指输入和输出数据的
数量或相关数的大小。如 对 n 个元素进行排序、n×n 矩阵的加法等, n 作为实
例特征;两个 m×n 矩阵的加法,以 n 和 m 两个数作为实例特征。本讲义算法的
复杂性主要考虑复杂度与问题实例输入数据规模(信息量大小)的关系,所以,
实例特征就取问题实例的输入数据规模。
一般情况下,指令空间的大小对于所解决的问题的实例特征不够敏感。常量
类型名 说明 字节数 范围
char 字符型 1 -128~127
signed char 有符号字符型 1 -128~127
unsigned char 无符号字符型 1 0~255
short[int] 短整型 2 -32768~32767
signed short[int] 有符号短整型 2 -32768~32767
unsigned short[int] 无符号短整型 2 0~65535
int 整型 4 -2147483648~2147483647
signed[int] 有符号整型 4 -2147483648~2147483647
unsigned[int] 无符号整型 4 0~4294967295
long[int] 长整型 4 -2147483648~2147483647
signed long[int] 有符号长整型 4 -2147483648~2147483647
unsigned long[int] 无符号长整型 4 0~4294967295
float 单精度浮点型 4 约 6 位有效数字
double 双精度浮点型 8 约 12 位有效数字
long double 长双精度浮点型 16 约 15 位有效数字


第一章 复杂性分析初步 3
及简单变量所需要的数据空间也独立于所解决的问题的实例特征,除非相关数的
大小对于所选定的数据类型来说实在太大。这时,要么改变数据类型要么使用多
精度算法重写该程序,然后再对新程序进行分析。定长复合变量和未使用递归函
数所需要的环境栈空间也都独立于问题的实例特征。而递归函数所需要的栈空间
主要依赖于局部变量及形式参数所需要的空间。除此外,该空间还依赖于递归的
深度(即嵌套递归调用的最大层次)。
程序所需要的空间可分为两部分:
S(P) = c + SP(实例特征)
1) 固定部分 c,它独立于实例的特征。主要包括指令空间、简单变量、常
量以及定长复合变量所占用的空间;
2) 可变部分 SP,主要包括复合变量所需的空间(其大小依赖于所解决的具
体问题)、动态分配的空间(依赖于实例的特征)、递归栈所需的空间(依赖
于实例特征)。
注:一个精确的分析还应当包括编译期间所产生的临时变量所需的空间,这
种空间与编译器直接相关联,在递归程序中除了依赖于递归函数外,还依赖于实
例特征。但是,在考虑空间复杂性时,一般都被忽略。
程序 1-1-1 利用引用参数
template < class T >
T Abc(T& a, T& b, T& c)
{
return a+b+c+b*c\
+(a+b+c)/(a+b)+4;
}
若函数 Abc 的参数是传值参数,则每个参数需要分配 sizeof(T)的空间,于
是 a,b,c 所需的空间为 3×sizeof(T)。函数 Abc 所需的其他空间都与 T 无关,
故 SAbc(实例特征)=3×sizeof(T)。
程序 1-1-2 顺序搜索
template < class T >
int SeqSearch(T a[], const T& x, int n)
在程序 1-1-1 中,采用数据类
型 T 作为实例特征。由于 a,b,
c 都是引用参数,在函数中不需
要为它们的值分配空间,但需保
存指向这些参数的指针。若每个
指针需要 2 个字节,则共需要 6
字节的指针空间。此时函数所需
要的总空间是一个常量,而
SAbc(实例特征)=0。


第一章 复杂性分析初步
4
{
//在 a[0:n-1]中搜索 x,若找到则返回所在的位置,否则返回-1
int i;
for (i=0; i<n && a[i]=!x; i++);
if (i==n) return -1;
return i;
}
在程序 1-1-2 中,假定采用被查数组的长度 n 作为实例特征,并取 T 为 int
类型。数组中每个元素需要 4 个字节,实参 x 需要 4 个字节,传值形式参数 n 需
要 4 个字节,局部变量 i 需要 4 个字节,整数常量-1 需要 2 个字节,所需要的
总的数据空间为 18 个字节,其独立于 n,所以 SSeqSearch(n)=0。这里,我们并未
把数组 a 所需要的空间计算进来,因为该数组所需要的空间已在定义实际参数
(对应于 a)的函数(如主函数)中分配,不能再加到函数 SeqSearch 所需要的
空间上去。
再比较下面两个程序,它们都是求已知数组中元素的和。在第一个程序中
采用累加的办法,而在第二个程序中则采用递归的办法。我们取被累加的元素个
数 n 作为实例特征。在第一个函数中,a,n,i 和 tsum 需要分配空间,与上例
同样的理由,程序所需的空间与 n 无关,因此,SSum(n)=0。在第二个程序中,
递归栈空间包括参数 a,n 以及返回地址。对于 a 需要保留一个指针,对于 n 则
需要保留一个 int 类型的值。如果是 near 指针(需占用 2 个字节),则返回地址
需占用 2 个字节,n 需占用 4 个字节,那么每次调用 Rsum 函数共需 8 个字节。
该程序递归深度为 n+1,所以需要 8(n+1)字节的递归栈空间。SRsum(n)=8(n+1)。
累加 a[0:n-1] 递归计算 a[0:n-1]
template<class T> template<class T>
T Sum(T a[], int n) T Rsum(T a[], int n)
{//计算 a[0:n-1]的和 {//计算 a[0:n-1]的和
T tsum=0; if (n>0)
for (int i=0; i<n; i++) return Rsum(a,n-1)+a[n-1];
tsum+=a[i]; return 0;
return tsum; }
}
嵌套调用一直进行到 n=0。可见,递归计算比累加计算需要更多的空间。


第一章 复杂性分析初步 5
上述递归程序的嵌套调用层次
§2 时间复杂性
1. 时间复杂性的构成
一个程序所占时间 T(P)=编译时间+运行时间。
编译时间与实例特征无关,而且,一般情况下,一次编译过的程序可以运行
若干次,所以,人们主要关注的是运行时间,记做 tP(实例特征);如果了解所用
编译器的特征,就可以确定程序 P 进行加、减、乘、除、比较、读、写等所需的
时间,从而得到计算 tP 的公式。令 n 代表实例特征(这里主要是问题实例的规
模),则有如下的表示式:
tP(n)=caADD(n)+csSUB(n)+cmMUL(n)+cdDIV(n)+ccCMP(n)+···
其中,ca,cs,cm,cd,cc 分别表示一次加、减、乘、除及比较操作所需的时间,
函数 ADD,SUB,MUL,DIV,CMP 分别表示代码 P 中所使用的加、减、乘、除及比
较操作的次数;
注:一个算术操作所需的时间取决于操作数的类型(int、float、double
等等),所以,有必要对操作按照数据类型进行分类;在构思一个程序时,影响
tP 的许多因素还是未知的,所以,在多数情况下仅仅是对 tP 进行估计。估算运
行时间的方法主要有两种:A. 选一种或多种关键操作,确定这些关键操作所需
要的执行时间(对于前面所列举的四种算术运算及比较操作,一般被看作是基本
操作,并约定所用的时间都是一个单位)及每种关键操作执行的次数;B. 确定
程序总的执行步数。
2. 操作计数
首先选择一种或多种操作(如加、乘和比较等),然后计算这些操作分别执
行了多少次。关键操作对时间复杂性影响最大。
程序 1-2-1 寻找最大元素
template<class T>
int Max(T a[], int n)
Rsum(a, n)
Rsum(a, n-1)
.
.
.
Rsum(a, 1)
Rsum(a, 0)


第一章 复杂性分析初步
6
{//寻找 a[0:n-1]中的最大元素
int pos=0;
for (int i=1; i<n; i++)
if (a[pos]<a[i])
pos=i;
return pos;
}
这里的关键操作是比较。for 循环中共进行了 n-1 次比较。Max 还执行了其
它比较,如 for 循环每次比较之前都要比较一下 i 和 n。此外,Max 还进行了其
他的操作,如初始化 pos、循环控制变量 i 的增量。这些一般都不包含在估算中,
若纳入计数,则操作计数将增加到一个常数倍。
程序 1-2-2 n 次多项式求值
template<class T>
T PolyEval(T coeff[], int n, const T& x)
{//计算 n 次多项式的值,coeff[0:n]为多项式的系数
T y=1, value=coeff[0];
for (int i=1; i<=n; i++) //n 循环
{//累加下一项
y*=x; //一次乘法
value+=y*coeff[i]; //一次加法和一次乘法
}
return value;
} //3n 次基本运算
Horner 法则:
P(x)=(···(cn*x+cn-1)*x+cn-2)*x+cn-3)*x+···)*x+c0
程序 1-2-3 利用 Horner 法则求多项式的值
template<class T>
T Horner(T coeff[], int n, const T& x)
{//计算 n 次多项式的值,coeff[0:n]为多项式的系数
T value=coeff[n];
for(i=1; i<=n; i++) //n 循环


第一章 复杂性分析初步 7
T value=value*x+coeff[n-i]; //一次加法和一次乘法
return value;
} //2n 次基本运算
这里,关键操作是加法与乘法运算。在程序 1-2-2 中,for 循环的每一回都
执行两次乘法运算和一次加法运算。所以程序的总的运算次数为 3n。 在程序
1-2-3 中,for 循环的每一回都执行乘法与加法运算各一次,程序总的运算次数
为 2n。再考察下面两例:
程序 1-2-4 计算名次 程序 1-2-5 选择排序
template<class T> template<class T>
void Rank(T a[], int n, int r[]) void SelectSort(T a[], int n)
{//计算 a[0:n-1]中元素的排名 {//对数组 a[0:n-1]中元素排序
for(int i=0; i<n; i++) for(int size=n; size>1; size--)
r[i]=0; //初始化 { int j=Max(a,size);
//逐对比较所有的元素 Swap(a[j],a[size-1]);
for(int i=1; i<n; i++) }
for(int j=0; j<i; j++) }
if(a[j]<=a[i]) r[i]++; 其中函数 Max 定义如程序 1-2-1
else r[j]++; 而函数 Swap 由下述程序给出
} 程序 1-2-6 交换两个值
在这两个程序中,关键操作都是
比较。在 1-2-4 中,对于每个 i ,
执行比较的次数是 i,总的比较次
数为 1+2+ ··· + n-1=(n-1)n/2。
在此,for 循环的额外开销、初始
化数组 r 的开销、以及每次比较 a
中两个素时对 r 进行的增值开销都未列入其中。在程序 1-2-5 给出的排序中,首
先找出最大元素,把它移到 a[n-1],然后在余下的 n-1 个元素中再寻找最大的
元素,并把它移到 a[n-2].如此进行下去,此种方法称为选择排序(SelectSort).
从程序 1-2-1 中已经知道,每次调用 Max(a,size)需要执行 size-1 次比较,所
以总的比较次数为 1+2+ ··· + n-1=(n-1)n/2.每调用一次函数 Swap 需要执
行三次元素移动,所需要总的移动次数为 3(n-1)。
考虑冒泡排序(SubbleSort)。冒泡排序是从左向右逐个检查,对相邻的元
template<class T>
inline void Swap(T& a, T& b)
{//交换 a 和 b
T temp=a; a=b; b=temp;
}


第一章 复杂性分析初步
8
素进行比较,若左边的元素比右边的元素大,则交换这两个元素的位置。如数组
[5,3,7,4,11,2]:比较 5 和 3,交换;比较 5 和 7,不交换;比较 7 和 4,交换;
比较 7 和 11,不交换;比较 11 和 2,交换。这个行程称为一次冒泡,经一次冒
泡后,原数组变为[3,5,4,7,2,11].可见,数组中最大的数被移动到最右的位置。
下一次冒泡只对数组[3,5,4,7,2]进行即可。如此进行下去,最后将原数组按递
增的顺序排列。
程序 1-2-7 一次冒泡 程序 1-2-8 冒泡排序
template<class T>
void Bubble(T a[], int n)void
{
for(int i=0; i<n-1; i++)
if(a[i]>a[i+1]) Swap(a[i],a[i+1]);
}
在程序 1-2-7 中,for 循环的每一回都执行了一次比较和至多三次元素的
移动,因而总的操作数为 4(n-1)。在程序 1-2-8 中,对于每个 i,调用函数
Bubble(a,i)需要执行 4(i-1)次操作,因而总的操作数为 2n(n-1).这里我们照例
忽略了非关键操作。
分析程序 1-2-7 发现,在问题实例中,如果数组本身是递增的,则每一次
冒泡都不需要交换数据,而如果数组是严格递减的,则第一次冒泡要交换数据
n-1 次。这里我们都取数组元素个数为实例特征,但操作数却是不同的。因而,
人们往往还会关心最好的、最坏的和平均的操作数是多少。令 P 表示一个程序,
将操作计数 OP (n1, n2 ,, nk ) 视为实例特征 n1, n2 ,, nk 的函数。令 operationP (I ) 表
示程序对实例 I 的操作计数, S(n1, n2 ,, nk ) 为所讨论程序 的具有实例特征
n1, n2 ,, nk 的实例之集,则
P 最好的操作计数为
( 1, 2 , , k ) min{ P ( ) | ( 1, 2 , , k )}
BC
OP n n  n = operation I I  S n n  n
P 最坏的操作计数为
( 1, 2 , , k ) max{ P ( ) | ( 1, 2 , , k )}
WC
OP n n  n = operation I I  S n n  n
P 平均的操作计数为


=
(, ,, )
12
1, 2
12
()
| ( , , , )|
1
( ,,)
I S n n nk
P k
k
AVG
P operation I
Sn n n
O nn n



Template<class T>
BubbleSort(T a[], int n)
{
for(int i =n; i >1; i --)
Bubble(a, i );
}


第一章 复杂性分析初步 9
P 操作计数的期望值为


=
(, ,, )
1, 2
12
( , , ) () ()
I S n n nk
kP
AVG
OP n n n p I operation I


其中, p(I ) 是可被成功解决的实例 I 出现的概率。
在前面的例子中,一般计算的都是程序的最坏操作计数。如在冒泡程序
Bubble 中即是如此。在顺序搜索 SeqSearch(T a[], const T& x, int n)中,取
n 作为实例特征,关键操作数是比较。此时,比较的次数并不是由 n 唯一确定的。
若 n=100,x=a[0],那么仅需要执行一次操作;若 x 不是 a 中的元素,则需要执
行 100 次比较。当 x 是 a 中一员时称为成功查找,否则称为不成功查找。每回不
成功的查找,需要执行 n 次比较。对于成功的查找,最好的比较次数是 1,最坏
的比较次数为 n。若假定每个实例出现的概率都是相同的,则平均比较次数为
1
1
1 ( 1) 2
n
i
nn
ni
nn
=

+= +

++


再考察插入排序算法:
程序 1-2-9 向有序数组插入元素 程序 1-2-10 插入排序
template<class T> template<class T>
void Insert(T a[], int& n, const T& x) void InsertSort(T a[], int n)
{//向数组 a[0:n-1]中插入元素 x {//对 a[0:n-1]进行排序
//假定 a 的大小超过 n for(int i=1; i<n; i++) {
int i; T t =a[i];
for(i=n-1; i>=0 && x<a[i]; i--) Insert(a, i, t);
a[i+1]=a[i]; }
a[i+1]=x; }
n++; //添加了一个元素
}
在程序 1-2-9 中假定:a 中元素在 x 被插入前后都是按递增的顺序排列的。我们
取初始数组 a 的大小 n 作为实例特征,则程序 1-2-9 的关键操作是 x 与 a 中元素
的比较。显然,最少的比较次数为 1,这种情况发生在 x 被插在数组尾部的时候;
最多的比较次数是 n,发生在 x 被插在数组的首部或者数组的第一元素之后的时
候。如果 x 最终被插在 a 的 i+1 处(i>=0),则执行的比较次数是 n-i。如果 x
被插在 a[0]之前的位置,则比较的次数为 n。假定 x 有相等的机会被插在任何一
个可能的位置上,则平均比较次数是
/ 2 /( 1)
1
1
()
1
1
1
1
0
 = + +




+
+
= 

 
+ −
+  =
−
=
n j n nn
n
n ni
n
n
j
n
i


第一章 复杂性分析初步
10
在程序 1-2-10 中所执行的比较次数,最好情况下是 n-1,最坏情况下是 n(n-1)/2.
虽然在这些简单例子中,我们都给出了平均操作数,但是在一般情况下,平
均操作数不是很容易求得的,操作数的数学期望值就更不容易求得了。
3. 执行步数
利用操作计数方法估计程序的时间复杂性注意力集中在“关键操作”上,忽
略了所选择操作之外其他操作的开销。下面所要讲的统计执行步数(step-count)
的方法则要统计程序/函数中所有部分的时间开销。执行步数也是实例特征的函
数,通常做法是选择一些感兴趣的实例特征。如,若要了解程序的运行时间是如
何随着输入数据的个数增加而增加的,则把执行步数仅看作输入数据的个数的函
数。所谓程序步是一个语法或语意上的程序片断,该片段的执行时间独立于实例
特征。例如 语句:return a+b+b*c+(a+b+c)/(a+b)+4;和 x=y;都可以作为程序
步。一种直观的统计程序执行步数的方法是做执行步数统计表
矩阵加法程序执行步数统计表
其中 s/e 表示每次执行该语句所要执行的程序步数。一条语句的 s/e 就等于执行
该语句所产生的 count 值的变化量。频率是指该语句总的执行次数。
实际统计中,可以通过创建全局变量 count 来确定一个程序或函数为完成其
预定任务所需要的执行步数。将 count 引入到程序语句之中,每当原始程序或函
数中的一条语句被执行时,就为 count 累加上该语句所需要的执行步数。
程序 1-2-11 矩阵加法与执行步数统计
template<class T>
void Addm(T **a, T **b, T **c, int rows, int cols)
{//矩阵 a 和 b 相加得到矩阵 c
for(int i=0; i<rows; i++){
语 句 s/e 频率 总步数
Void Addm(T **a, ···) 0 0 0
{ 00 0
for(int i=0; i<rows; i++) 1 rows+1 rows+1
for(int j=0; j<cols; j++) 1 rows*(cols+1) rows*cols+rows
c[i][j]=a[i][j]+b[i][j]; 1 rows*cols rows*cols
} 00 0
总 计 2*rows*cols+2*rows+1


第一章 复杂性分析初步 11
count++; //对应于上一条 for 语句 (共执行了 rows 步)
for(int j=0; j<cols; j++){
count++; //对应于上一条 for 语句(共执行了 rows×cols 步)
c[i][j]=a[i][j]+b[i][j];
count++; //对应于赋值语句 (共执行了 rows×cols 步)
}
count++; //对应 j 的最后一次 for 循环 (共执行了 rows 步)
}
count++;//对应 i 的最后一次 for 循环 (共执行了 1 步)
}
若取 rows 和 cols 为实例特征,则,程序 1-2-11 总的执行步数为 2×rows×cols
+2×rows+1。据此,若 rows > cols,我们可以通过交换程序中 i 循环与 j 循
环的次序而使程序所用时间减少。
§3 渐近符号
确定程序的操作计数和执行步数的目的是为了比较两个完成同一功能的程
序的时间复杂性,预测程序的运行时间随着实例特征变化的变化量。设 T (n) 是
算法 A 的复杂性函数。一般说来,当 n 单调增加趋于  时,T (n) 也将单调增加趋
于  。如果存在函数 T~(n) ,使得当 n →  时有 ~( )) / ( ) 0
(T (n) − T n T n → ,则称T~(n)
是T (n) 当 n →  时的渐近性态,或称T~(n) 是算法 A 当 n →  的渐近复杂性。因
为在数学上,T~(n) 是T (n) 当 n →  时的渐近表达式,T~(n) 可以是T (n) 中略去低
阶项所留下的主项,所以它的形式无疑比T (n) 来得简单。
进一步分析可知,要比较两个算法的渐近复杂性,只要确定出各自的阶(作 为无穷大量)即可知道哪一个算法的效率高。换句话说,渐近复杂性分析只要关
心T~(n) 的阶就够了,不必关心包含在T~(n) 中的常数因子。所以,对T (n) 的分析
又常常做进一步简化,即假设算法中用到的所有不同的运算(基本)各执行一次 所需要的时间都是一个单位时间。
综上分析,我们已经给出了简化算法复杂性分析的方法和步骤,即只考虑当
问题的规模充分大时,算法复杂性在渐近意义下的阶。为此引入渐近符号,首先
给出常用的渐近函数。


第一章 复杂性分析初步
12
常用的渐进函数
在下面的讨论中,用 f(n)表示一个程序的时间或空间复杂性,它是实例特
征 n(一般是输入规模)的函数。由于一个程序的时间或空间需求是一个非负的
实数,我们假定函数 f(n)对于 n 的所有取值均为非负实数,而且还可假定 n>=0。
渐近符号  的定义:f(n)=O(g(n))当且仅当存在正的常数 c 和 n0,使得对于
所有的 n>=n0,有 f(n)<=cg(n)。此时,称 g(n)是 f(n)的一个渐近上界。
函数 f 至多是函数 g 的 c 倍,除非 n  n0 。即是说,当 n 充分大时,在不计
较相差一个非零常数倍的情况下,g 是 f 的一个上界函数。通常情况下,上界函
数取单项的形式,如表 1 所列。
C0 = O(1): f(n) 等于非零常数的情形。
3n+2 = O(n): 可取 c=4,n0=2 。
100n+6 = O(n): 可取 c=101,n0=6 。
10n2+4n+3 = O(n2): 可取 c=11,n0=5 。
6×2n+n2 = O(2n): 可取 c =7,n0=4 。
3×log n + 2×n + n2 =O(n2). 可取 c =2,n0=5 。
n×log n +n2= O(n2). 可取 c =2,n0=3 。
3n+2 = O(n2). 可取 c =1,n0=3 。
三点注意事项:
1. 用来作比较的函数 g(n)应该尽量接近所考虑的函数 f(n).
3n+2=O(n2) 是松散的界;3n+2=O(n) 是较好的界。
2. 不要产生错误界。
n2+100n+6,当 n<3 时,n2+100n+6<106n,由此就认为 n2+100n+6=O(n),这是不
对的。 事实上,对任何正的常数 c,只要 n>c-100 就有 n2+100n+6>c×n。同理,
3n2+4×2n=O(n2)是错误的界。
3. f(n)=O(g(n))不能写成 g(n)=O(f(n)),因为两者并不等价。
函数 名称 函数 名称
1 常数 n2 平方
log n 对数 n3 立方
n 线性 2n 指数
n log n n 倍 log n n! 阶乘


第一章 复杂性分析初步 13
实际上,这里的等号并不是通常相等的含义。按照定义,用集合符号更准确些:
O(g(n))={f(n)|f(n)满足:存在正的常数 c 和 n0,使得当 n>=n0 时,f(n)<=cg(n)}
所以,人们常常把 f(n)=O(g(n))读作:“f(n)是 g(n)的一个大 O 成员”。
大 O 比率定理:对于函数 f (n) 和 g(n) ,如果极限 lim( f (n) / g(n))
n→
存在,则
f (n) = O(g(n)) 当且仅当存在正的常数 c,使得 f n g n c
n
li→m( ( ) / ( )) .
例子 因为 3
32
lim =
+
→ n
n
n
,所以 3n + 2 = O(n) ;
因为 10
10 4 2
lim 2
2
=
++
→ n
nn
n
,所以10n2 + 4n + 2 = O(n2 ) ;
因为 6
2
6*2
lim
2
=
+
→ n
n
n
n ,所以 6 * 2n + n2 = O(2n ) ;
因为 0
2
3*
lim
16 2
=
+
→ n
n
n n ,所以 16 3 * 2 (2n )
n + n =O ,
但是,最后一个不是好的上界估计,问题出在极限值不是正的常数。
下述不等式对于复杂性阶的估计非常有帮助:
定理 1.3.1. 对于任意给定的正实数 c 、 x 和,有下面的不等式:
1) 存在某个 n0 使得对于任何 n  n0 ,有 ( log ) (log )
xx
c n n +
 。
2) 存在某个 n0 使得对于任何 n  n0 ,有 (log n)x  n 。
3) 存在某个 n0 使得对于任何 n  n0 ,有 ( )x x
c n n +
+ 。
4) 存在某个 n0 使得对于任何 n  n0 ,有 nx  2n 。
5) 对任意实数 y ,存在某个 n0 使得对于任何 n  n0 ,有 +
n x (log n) y  n x 。
例 子 根 据 定 理 1 , 我 们 很 容 易 得 出 : n3 + n2 log n = O(n3 ) ;
n4 + n2.5 log20 n = O(n4 ) ; 2n n4 log3 n+2n n5 / log3 n = O(2n n5 ) 。
符号  的定义: f (n) = (g(n)) 当且仅当存在正的常数 c 和 n0 ,使得对于所
有的 n  n0 ,有 f (n)  c(g(n)) 。此时,称 g(n)是 f(n)的一个渐近下界。
函数 f 至少是函数 g 的 c 倍,除非 n  n0 。即是说,当 n 充分大时,在不计
较相差一个非零常数倍的情况下, g 是 f 的一个下界函数。类似于大 O符号,我


第一章 复杂性分析初步
14
们可以参考定理 1.3.1 所列的不等式,来估计复杂性函数的渐近下界,而且有下
述判定规则:
大  比率定理:对于函数 f (n) 和 g(n) ,如果极限 lim( f (n) / g(n))
n→
存在,则
f (n) = (g(n)) 当且仅当存在正的常数 c,使得 f n g n c
n
li→m( ( ) / ( )) .
符号  的定义: f (n) = (g(n)) 当且仅当存在正的常数 c1, c2 和 n0 ,使得对
于所有的 n  n0 ,有 c1(g(n))  f (n)  c2 (g(n)) 。此时,称 f(n)与 g(n)同阶。
函数 f 介于函数 g 的 c1和 c2 倍之间,即当 n 充分大时,在不计较相差非零常
数倍的情况下, g 既是 f 的下界,又是 f 的上界。
例子 3n + 2 = (n); 2 2
10n + 4n + 2 = (n ) 。
2
5 2 (2 );
nn
 +n =
 比 率 定 理 : 对 于 函 数 f (n) 和 g(n) , 如 果 极 限 lim(g(n) / f (n))
n→
与
lim( f (n) / g(n))
n→
都存在,则 f (n) = (g(n)) 当且仅当存在正的常数 c1, c2 ,使得
12
lim( ( ) / ( )) , lim( ( ) / ( ))
nn
f n gn c gn f n c
→ →
 .
例子: tsum (n) = 2n + 3 = (n) ; tAdd (m, n) = 2mn + 2n + 1 = (mn) ;
t AVG (n) (n 7) / 2 (1 )(n 3) (n)
SeqSeach =  + + − + =  ,其中表示被查元素 x 在数组 a
中的概率。
比较大 O 比率定理和  比率定理,可知,  比率定理实际是那两种情况的
综合。对于多项式情形的复杂性函数,其阶函数可取该多项式的最高项,即
定理 1.3.2. 对于多项式函数 1 0
1
a n a 1nm a n a
m
m
m + −+ + +
−  ,如果  0
am ,
则
f (n) = O(nm ) , f (n) = (nm ) , f (n) = (nm )
一般情况下,我们不能对每个复杂性函数直接去估计它们的渐进上界、渐进
下界和“双界”,定理 1.3.1 和定理 1.3.2 给了一些直接确定这些界的阶函数(或
叫渐近函数)的参考信息。由这些信息可以给出多个函数经过加、乘运算组合起


第一章 复杂性分析初步 15
来的复杂函数的阶的估计。
小 o符号定义: f (n) = o(g(n)) 当且仅当 f (n) = O(g(n)) 和 g(n)  O( f (n)) 。
一般情况下, f (n) = o(g(n)) 的充分必要条件是 lim( ( ) / ( )) = 0
→ f n g n
n
。
最后给出折半搜索程序及算法复杂性估计,这里假定被查找的数组已经是单
调递增的。
程序 1-3-1 折半搜索
template<class T>
int BinarySearch(T a[], const T& x, int n)
{//在 a[0]<=a[1]<=···<=a[n-1]中搜索 x
//如果找到,则返回所在位置,否则返回 –1
int left=0; int right=n-1;
while(left<=right){
int middle=(left+right)/2;
if(x==a[middle]) return middle;
if(x>a[middle]) left=middle+1;
else right=middle – 1;
}
return –1; //未找到 x
}
while 的每次循环(最后一次除外)都将以减半的比例缩小搜索范围,所以,
该循环在最坏的情况下需要执行 (log n) 次。由于每次循环需耗时 (1) ,因此在
最坏情况下,总的时间复杂性为 (log n) 。
§4 求解线性递归方程
1) 1 阶递归方程
T (n) = aT (n −1) + b,T (1) = c
直接推导:
2
11
1
( ) ( ( 2) ) ( 2)
(1) ( 1)
( 1) / ( 1), 1
,1
nn
nn
T n a aT n b b a T n ab b
aT a a b
ca b a a a
c nb a
−−
−
= − + += − + +
= + + ++
 +− − 
= + =



第一章 复杂性分析初步
16
2) 2 阶递归方程
T (n) = aT (n −1) + bT (n − 2) + c, T (0) = p,T (1) = q
设, 是特征方程2 − a− b = 0 的两个复根,则
+  = a,  = −b
于是,
()
T (n) −T (n −1) =  T (n −1) −T (n − 2) + c ,
令 D(n) = T (n) −T (n −1) ,则
D(n) = D(n −1) + c ,
转化成 1 阶递归方程。
3)一般的 k(k  1) 阶递归方程
线性递归方程: n 1 n 1 2 n 2 k n k
R aR a R a R
−− −
= + ++ ,
初始条件: 0 0 1 1 1 1
, , ,k k
R cR c R c
−−
== =
将线性递归方程用矩阵乘积表示:
1
12 1
12
2
1
1
10 0 0
01 0 0
00 1 0
nn
kk
nn
n
nk
nk nk
RR
aa a a
RR
R
R
RR
−
−
−−
−
−+
−+ −
 

 
  
  

=
 
  


 

 
这样,就可以直接推导下去,得到
1 1
12 1
12
2
1
10
10 0 0
01 0 0
00 1 0
nk nk
kk
nk
n
nk
RR
aa a a
RR
R
R
RR
−+
−
−
−−
−
−+
  

  
   
   

=
  
   


  

  
假设已经计算出上面矩阵方冪为
12 1
** * *
** * *
kk
bb b b
−
    

就会得到递归方程的解


第一章 复杂性分析初步 17
n 1k1 2 k 2 k 0
R bc b c b c
−−
= + ++
习题 一
1. 试确定下述程序的执行步数,该函数实现一个 m×n 矩阵与一个 n×p 矩
阵之间的乘法:
矩阵乘法运算
template<class T>
void Mult(T **a, T **b, int m, int n, int p)
{//m×n 矩阵 a 与 n×p 矩阵 b 相成得到 m×p 矩阵 c
for(int i=0; i<m; i++)
for(int j=0; j<p; j++){
T sum=0;
for(int k=0; k<n; k++)
Sum+=a[i][k]*b[k][j];
C[i][j]=sum;
}
}
2. 函数 MinMax 用来查找数组 a[0:n-1]中的最大元素和最小元素,以下给
出两个程序。令 n 为实例特征。试问:在各个程序中,a 中元素之间的比较次数
在最坏情况下各是多少?
找最大最小元素 (方法一)
template<class T>
bool MinMax(T a[], int n, int& Min, int& Max)
{//寻找 a[0:n-1]中的最小元素与最大元素
//如果数组中的元素数目小于 1,则还回 false
if(n<1) return false;
Min=Max=0; //初始化
for(int i=1; i<n; i++){
if(a[Min]>a[i]) Min=i;
if(a[Max]<a[i]) Max=i;
}
return true;
}


第一章 复杂性分析初步
18
找最大最小元素 (方法二)
template<class T>
bool MinMax(T a[], int n, int& Min, int& Max)
{//寻找 a[0:n-1]中的最小元素与最大元素
//如果数组中的元素数目小于 1,则还回 false
if(n<1) return false;
Min=Max=0; //初始化
for(int i=1; i<n; i++){
if(a[Min]>a[i]) Min=i;
else if(a[Max]<a[i]) Max=i;
}
return true;
}
3.证明以下关系式不成立:
1).10n2 + 9 = O(n);
2). n2 log n = (n2 ) ;
4.证明:当且仅当 lim ( ) / ( ) = 0
→ f n g n
n
时, f (n) = o(g(n)) 。
5.下面那些规则是正确的?为什么?
1).f (n) = O(F (n)), g(n) = O(G(n)) f (n) / g(n) = O(F (n) / G(n)) ;
2).f (n) = O(F (n)), g(n) = O(G(n)) f (n) / g(n) = (F (n) / G(n)) ;
3).f (n) = O(F (n)), g(n) = O(G(n)) f (n) / g(n) = (F (n) / G(n)) ;
4).f (n) = (F (n)), g(n) = (G(n)) f (n) / g(n) = (F (n) / G(n)) ;
5).f (n) = (F (n)), g(n) = (G(n)) f (n) / g(n) = (F (n) / G(n)) 。
6). f (n) = (F (n)), g(n) = (G(n)) f (n) / g(n) = (F (n) / G(n))
6. 按照渐近阶从低到高的顺序排列以下表达式:
4n2 , log n, 3n , 20n, n2/3, n!
7. 1) 假设某算法在输入规模是 n 时为 n
T (n) = 3* 2 . 在某台计算机上实现
并完成该算法的时间是 t 秒.现有另一台计算机,其运行速度为第一台的 64 倍,


第一章 复杂性分析初步 19
那么,在这台计算机上用同一算法在 t 秒内能解决规模为多大的问题?
2) 若上述算法改进后的新算法的时间复杂度为 2
T (n) = n , 则在新机器上
用 t 秒时间能解决输入规模为多大的问题?
3)若进一步改进算法,最新的算法的时间复杂度为 T (n) = 8 ,其余条件不
变,在新机器上运行,在 t 秒内能够解决输入规模为多大的问题?
8. Fibonacci 数有递推关系:



−+ − 
=
=
=
( 1) ( 2), 1
1, 1
1, 0
()
Fn Fn n
n
n
Fn
试求出 F (n) 的表达式。


20 第二章 图与遍历算法
第二章 图与遍历算法
§1 图的基本概念和术语
⚫ 无向图(undirected graph)
图 2-1-1 哥尼斯堡七桥
图 2-1-2 Euler 图
无向图,简称图,是一个用线(边)连接在一起的节点(顶点)的集合。严
格地说,图是一个三元组 G = (V , E, I ) , 其中,V 是顶点的集合, E 是边的集
合,而 I 是关联关系,它指明了 E 中的每条边与V 中的每个顶点之间的关联关
系:每条边必定连接两个而且只有两个顶点,它们称为该边的端点。有边相连的
两个顶点称为相邻的,具有公共端点的边称为相邻边。连接顶点 v 的边的条数
称为 v 的度,记做 d (v) . 图 G = (V , E, I ) 中顶点的度与边数有如下的 Euler 公式
d(v) 2 | E |
vV
=


(2.1.1)
由公式(2.1.1)可知,图中奇度顶点的个数一定是偶数。
没有重复边的图称为简单图, n 阶完全图是指具有 n 个顶点而且每两个顶
点之间都有边连接的简单图,这样的图的边数为 n(n −1) / 2 .以下是 1~4 阶的完


第二章 图与遍历算法 21
全图:
图 2-1-3 几个完全图
另一类特殊的图是偶图(也叫二部图),它的顶点集分成两部分 1 2
V , V ,每
部分中的顶点之间不相邻(没有边连接)。
V1
V2
图 2-1-4 一个偶图
当然, k -部图,是指图的顶点集被分成 k 个部分,同部分的顶点之间不相邻。
设图 G 的顶点集是V = {v1,v2,,vn},边集是 E = {e1,e2,,em} ,则顶点与顶
点之间的相邻关系可以用如下矩阵表示:
A
aa a
aa a
aa a
v
v
v
vv v
n n nn
n
n
n
n
=













 




12
21 22 2
11 12 1
2
1
12
称为邻接矩阵,其中
1 , (, )
0,
ij ij
if v v is an edge of G
a otherwise
= 
顶点与边之间的关联关系可以用如下矩阵表示:
K1
K4
K3
K2


22 第二章 图与遍历算法
M
bb b
bb b
bb b
v
v
v
ee e
n n nm
m
m
n
m
=













 




11
21 22 2
11 12 1
2
1
12
称为关联矩阵,其中
1,
0,
ij ij
if v is an endpoint of e
b otherwise
= 
图 2-1-5 的邻接矩阵 A 、关联矩阵 M 分别为:






















=
0000110
0000101
0001011
0000100
1100000
1010000
0110000
A






















=
0000011
0000101
0001110
0001000
0110000
1100000
1010000
M
图的另一个重要概念是路径,区分为途径、迹和路。
途径:顶点与边交叉出现的序列
0112 2 n n
v e v e v e v (2.1.2)
其中 ei 的端点是 vi−1 和 vi 。 迹是指边不重复的途径,而顶点不重复的途径称为
路。起点和终点重合的途径称为闭途径,起点和终点重合的迹称为闭迹,顶点不
重复的闭迹称为圈。没有圈的图称为森林。
如果存在一条以 u 为起点、v 为终点的途径,则说顶点 u 可达顶点 v 。如
果图 G 中任何两个顶点之间都是可达的,则说图 G 是连通的。如果图 G 不是连
e5 e6
e7
e4
6
4
5
7
e1
1
e2
e3
3
2
图 2-1-5
一个具有 7
个顶点、7 条
边的图


第二章 图与遍历算法 23
通的,则其必能分成几个连通分支。图 2-1-6 是连通的,而图 2-1-5 不是连通的,
它有两个连通分支。
一条途径:
v1e1v2e10v4e5v3e9v1e1v2e2v8
一条迹:
v1e1v2e10v4e5v3e9v1e4v7
一条路:
v1e1v2e10v4e5v3e8v5e12v7
图 2-1-6 立方体
不含圈的连通图称为树。森林的每个连通分支都是树,也就是说,森林是
由树组成的。对于连通图,适当去掉一些边后(包括去掉零条边),会得到一个
不含圈、而且包含所有顶点的连通图,它是一棵树,称为原图的生成树。一棵具
有 n 个顶点的树的边数恰好为 n −1。所以,一个具有 k 个连通分支的森林恰好有
n − k 条边。一个具有 n 个顶点的连通图至少有 n −1 条边;一个具有 n 个顶点,
k 个连通分支的图至少有 n − k 条边.
定理 2.1.1 如果 G 是具有 n 个顶点、 m 条边的简单图,则下列结论成立:
1. 若 G 是树,则 m = n −1 ;
2. 若 G 是连通图,而且满足 m = n −1,则 G 是树;
3. 若 G 不包含圈,而且满足 m = n −1,则 G 是树;
4. 若 G 是由 k 棵树构成的森林,则 m = n − k ;
5. 若 G 有 k 个连通分支,而且满足 m = n − k ,则 G 是森林。
由图 G 的部分顶点和部分边按照它们在 G 中的关联关系构成的图称为 G 的
子图,如果子图 H 的顶点集恰是 G 的顶点集,则 H 称为 G 的生成子图。可见,
当 G 是连通图时,它的生成树是一种特殊的生成子图,它是 G 的既连通又边数
最少的一个生成子图。一个连通图的生成树不是唯一的。
⚫ 有向图
描述单行道系统就不能用无向图,因为它不能指明各条路的方向。所谓有
向图实际上是在无向图的基础上进一步指定各条边的方向。在有向图中每一条有
向边可以用一对顶点表示:e = (u,v) ,u 为始点,v 为终点,这条边是由顶点 u 指
向顶点 v 的。
V1 V2
V3 V4
V5 V6
V7 V8
e1
e2
e3
e5
e6
e7
e8
e9 e10
e11
e12
e4


24 第二章 图与遍历算法
图 2-1-7 具有单行线的交通示意图
图 2-1-8
一个有向图及其
双向连通分支
指向顶点 v 的有向边的条数称为顶点 v 的入度,记做 d − (v) ;而由顶点 u 出发
的有向边的条数称为顶点 u 的出度,记做 d + (u) 。一个顶点 w 的出度与入度之和
称为该顶点的度,记做 d (w) ,即 d(w) = d + (w) + d − (w) 。有向图 G = (V , E, I ) 的顶
点的度和边数之间有如下的关系:
  
+

= −=
vV vV
| E | d (v) d (v) (2.1.3)
类似地,有向图的表示也可以用邻接矩阵和关联矩阵,但是为指明边的方
向 , 只 用 0,1 两 个 元 素 是 不 够 的 。 设 有 向 图 G 的 顶 点 集 和 边 集 分 别 是
V = {v1,v2,,vn}和 E = {e1,e2,,em} ,则邻接矩阵定义如下:
单向
单向
单向
单向
街道 1 街道 3
街道 2
大街 1
大街 2
23
4 56
1
23
45 6
1 e1 e2
e3 e4 e5 e6
e7 e8


第二章 图与遍历算法 25
A
aa a
aa a
aa a
v
v
v
vv v
n n nn
n
n
n
n
=













 




12
21 22 2
11 12 1
2
1
12
其中
1 , (, )
0,
ij ij
if v v is a directed edge of G
a otherwise
= 
关联矩阵定义如下:
M
bb b
bb b
bb b
v
v
v
ee e
n n nm
m
m
n
m
=













 




11
21 22 2
11 12 1
2
1
12
其中
1,
1,
0,
ij
ij i j
if v is the startpoint of e
b if v is the endpoint of e
otherwise
=  −

如,图 2-1-8 的关联矩阵为


















−−
−−
−−
−−
=
0 0 0 0 0 10 1
0 0 0 11 0 11
00100010
01000100
1 10 1 10 0 0
10 10 0 0 0 0
M
每个列上恰有一个 1 和一个 -1,代表一条有向边的始点和终点。
在有向图中,许多概念都可以通过无向图的相关概念加“有向”二字得到,
如:有向边、有向途径、有向迹、有向路、有向圈,等等。有向图和无向图可以
相互转化:将一个无向图的每条边都规定方向后,即得到有向图,其称为原无向
图的一个定向图;将一个有向图的各条有向边的方向去掉,即得到一个无向图,
其称为原有向图的基础图。
有向图中也有一些概念不能由无向图通过简单地附加“有向”一词而得到。
如,连通。有向图 D 说是连通的是指其基础图是连通的。如果 D 中任意两个
顶点都是相互有向可达的,则说有向图 D 是双向连通的(或叫强连通)。这里,
顶点 u 可达顶点 v (有向可达)是指存在一条以 u 为起点、 v 为终点的有向


26 第二章 图与遍历算法
途径。这里的起点、终点不能互为替换,即, u 可达 v 不能保证 v 也可达 u 。
有向图 2-1-8 就是连通的,但不是双向连通的,因为从任何顶点出发,都
没有到达顶点 3 的有向路。非双向连通的有向图可以分解成几个双向连通分支。
图 2-1-8 共有 5 个双向连通分支,分别用不同的颜色标出。
⚫ 赋权图
一般的赋权图是指对图的每条边 e 赋予一个实数值 w(e) 。如架设连接各
城镇的交通路网,需考虑各段线路的修建费用;在运输网络中要考虑网络各段线
路的容量,在输电网络中要考虑各条线路上的电流以及各个结点处的电势,等等。
图 2-1-9 一个交通路网
注意,描述一个赋权图时,如果顶点 vi ,vj 之间有一条边连接,而且权值为 a ,则
其邻接矩阵中的 (i, j) 元素为 a (而不再是 1),其余元素统一取为 0 或一个充分
大的数,视问题而定。
⚫ 图的邻接链表表示
除了邻接矩阵表示和关联矩阵表示,在数据结构上也常常采用邻接链表的
方法表示一个图。这是把邻接于每个顶点的顶点做成一个表连接到这个顶点上。
图 2-1-10 给出了一个有向图(a)和它的邻接链表,其中,(b)是图 G 的邻接矩阵
表示;(c)是各点的邻接表;(d)给出各点之间链接起来的结构。
6
6 13 2
72
31 3
6
83
12
3
4
(a) (b)
0101
0010
0000
0110
1
2
3
4
1 23 4
9
87
6
5


第二章 图与遍历算法 27
图 2-1-10 图 G 及其邻接链表
§2 图的遍历(搜索)算法
⚫ 有根树与有向树
树是一个没有圈的连通图。如果指定树的一个顶点为根,则这棵树称为有根
树。有根树上的顶点称为节点。在有根树中,邻接根的节点称为根的子节点,而
根称为这些子节点的父节点。对于不是根的节点,除了它的父节点之外其它与之
邻接的节点都称为该节点的子节点,该节点也自然称为它的这些子节点的父节
点。没有子节点的节点称为叶节点。有根树实际上是给树定义了一个传承结构。
从根到每一个叶节点都有一条唯一的路。这些路的最长者的长度称为该树的
高度;不是根的节点 v 不通过其父节点而能到达的所有节点同 v 一起生成一棵以
v 为根的子树,这棵子树的高度称为节点 v 在原树中的高度。树的根到每个节点 v
都有一条唯一的路,这条路的长度称为节点 v 在树中的深度。如在图 2-2-1 的二
叉树中,树的高度为 4,节点 D, E 的深度都是 2 ;节点 G 的高度为1 ,深度为 3 。
可见,树中每个节点的高度与深度的和不超过树的高度。
二叉树是这样一棵有根树,它的每个节点至多有两个子节点。如果一棵二叉
树的叶节点深度都相同,而且除了叶顶点以外,每个节点都恰有两个子节点,则
称为完整的二叉树。高度为 h 的完整二叉树恰有 1
21
h+ − 个节点,它的所有节点按
照从上到下、从左到右的顺序可以编号为: 1
1, 2, , 2 1
h+ − 。从这样编号的完整二
2
0
40
0
Vertex 1
30
0
Vertex 2
Vertex 3 Empty list
2
0
30
0
Vertex 4
(c)
(d)
Vertices
Edges
5
7
0
8
26
40
30
29
30
HEAD NEXT
1
2
3
4
5
6
7
8
9


28 第二章 图与遍历算法
叉树中的某一位置开始,删掉后面编号的所有节点及与之关联的边所得到的二叉
树称为一棵完全二叉树。
一个二叉树通常用两个数组 Lson 和 Rson 表示。假设二叉树的节点标号为
1,2,, n ,则 Lson[i]=j 表示节点 j 是节点 i 的左儿子;同样,Rson[i]=j 表示节
点 j 是节点 i 的右儿子。一个完全的二叉树可以用一个数组来表示:设 T 是一棵
高度为 h 的完全二叉树,则数组的第一个元素是该树的根,第二个元素是根的左
儿子,第三个元素是根的右儿子。一般地,第 i 个元素的左儿子是数组的第 2i 个
元素,第 i 个元素的右儿子是数组的第 2i +1个元素。反之,数组中第 j( 1) 个元
素的父亲是数组中的第  j / 2个元素。
一棵有向树是满足下述条件的无圈有向图:
1.有一个称为根的顶点,它不是任何有向边的终点;
2.除了根以外,其余每个顶点的入度均为 1;
3.从根到每个顶点有一条有向路。
图 2-2-3 一个完
整的二
叉树
J
A
BC
DE F G
HI K M O
LN
从上到下、从左到
右,将完整二叉树
上的顶点编号为 1,2,,2h+1-1
图 2-2-2 一棵完全二叉树
A
BC
D EF G
HI
从一棵完整
的二叉树中
删掉标号为
2h-i , 1 i
 k 的 k 个顶
点
h 表示二叉树的高度
图 2-2-1 一棵二叉树
B
A
C
DE
FG
HI


第二章 图与遍历算法 29
图 2-2-4 是一棵高度为 4 的有向树。对于有向树有类似于有根树的全部术语。
⚫ 二叉树的搜索
二叉树的搜索主要有先根次序搜索、中根次序搜索和后根次序搜索,各种遍
历算法的伪代码写出如下,并在其后给出了搜索过程示意图。其中,Lson(T)表
示以树 T 的左儿子为根的子树;Rson(T)表示以树 T 的右儿子为根的子树。
程序 2-2-1 二叉树的中根次序遍历算法伪代码
InOder(T) // T 是一棵二叉树,T 的每个节点
//有三个信息段:Lson,Data,Rson
if T≠0 then
InOrder(Lson(T));
Visit(T);
InOrder(Rson(T));
end{if}
end{InOrder}
程序 2-2-2 二叉树的先根次序遍历算法伪代码
PreOder(T) // T 是一棵二叉树,T 的每个节点
//有三个信息段:Lson,Data,Rson
if T≠0 then
Visit(T);
PreOrder(Lson(T));
PreOrder(Rson(T));
end{if}
end{PreOrder}
C
D
G
A
EF
I
H
K
B
图 2-2-4 有向树
1
2
4
3
8
7
6
5
9
B
A
C
D
E
F
G
H
H
4
3
5
6
1
8
2
7
9
B
A
C
D
E
F
G
H
I 3


30 第二章 图与遍历算法
程序 2-2-3 二叉树的后根次序遍历算法伪代码
PostOder(T) // T 是一棵二叉树,T 的每个节点
//有三个信息段:Lson,Data,Rson
if T≠0 then
PostOrder(Lson(T));
PostOrder(Rson(T));
Visit(T);
end{if}
end{PostOrder}
⚫ 一般树的遍历算法
二叉树的遍历算法可以推广到一般有根树,这只要给同一个节点的子节点
排一个顺序即可。但是,中根优先次序遍历算法对于多子节点的情况不好确定根
居于哪个位置,所以,不宜照搬。
树的先根次序遍历算法:
i. 若 T 为空,则返回;
ii. 访问 T 的根;
iii. 按树的先根次序遍历 T 的第一棵子树;
iv. 按树的先根次序依次遍历 T 的其余子树。
树的后根次序遍历算法:
v. 若 T 为空,则返回;
vi. 按树的后根次序遍历 T 的第一棵子树;
vii. 按树的后根次序依次遍历 T 的其余子树;
viii. 访问 T 的根。
⚫ 一般图的遍历
无论是二叉树还是一般的树,由于其不含有圈,所以属于同根的各个子树之
间是相互独立的,遍历过程是对各个子树的分别遍历和对根遍历以及把这些遍历
有机地组合起来。无论是什么顺序搜索,都不会出现重叠和死循环现象。一般的
图没有这种独立性,所以上述方法不能施行。但是,上述方法的思想可以借鉴,
于是产生了深度优先搜索方法和宽度优先搜索方法。
问题:在一个给定的图 G=(V,E)中是否存在一条起于顶点 v 而终于顶点 u
1
5
4
2
9
6
7
3
8
B
A
C
DE
FG
HI 3


第二章 图与遍历算法 31
的路径?遍历与某一起点v有路相通的所有顶点。
➢ 宽度优先搜索算法(BFS)
开始:起点 v 和一个空的待访队列 Q。
将 v 标记为已访问的顶点,然后开始检查其所有邻点,把其中未被检索的
顶点依次放在待访队列 Q 的尾部。用队列 Q 的首元素 u 替换 v(并从队列 Q 中去
掉首元素 u),重复以上过程,直到队列 Q 空为止。
程序 2-2-4 由一点出发的宽度优先搜索算法伪代码
BFS(v) //宽度优先搜索 G,从顶点 v 开始执行,数组 visited 标示各顶点被
//访问的序数;数组 s 将用来标示各顶点是否被检索过,是则标记为 1,
//否则标记为 0;计数器 count 计数到目前为止已经被访问的顶点个数,
//其初始化为在 v 之前已经被访问的顶点个数
1. AddQ(v,Q);S[v]:=1; //将 Q 初始化为只含有一个元素 v 的队列
2. while Q 非空 do
3. u:=DelHead(Q); count:=count+1; visited[u]:=count;
4. for 邻接于 u 的所有顶点 w do
5. if s[w]=0 then
6. AddQ(w,Q); //将 w 放于队列 Q 之尾
7. s[w]:=1;
8. end{if}
9. end{for}
10. end{while}
11. end{BFS}
这里调用了两个函数:AddQ(w,Q)是将 w 放于队列 Q 之尾;DelHead(Q)是从
队列 Q 取第一个元素,并将其从 Q 中删除。
定理 2.2.1 图 G 的宽度优先搜索算法能够访问 G 中由 v 可能到达的所有顶
点。如果记T (n, m) 和 S(n, m) 为算法 BFS 在任意一个具有 n 个顶点和 m 条边的连
通图 G 上所花费的最大时间和占用的最大空间,则当 G 由邻接矩阵表示时有:
2
T (n, m) = (n ), S(n, m) = (n)
当 G 由邻接链表表示时;
T (n, m) = (n + m), S(n, m) = (n)
证明:除节点 v 外,只有当节点 w 满足 s[w]=0 时才被加到队列上,因此每
个节点至多有一次被放到队列上。需要的队列空间至多是 n −1;visited 数组变


32 第二章 图与遍历算法
量所需要的空间为 n ;其余变量所用的空间为 O(1) ,所以 S(n, m) = (n) 。
如果使用邻接链表,语句 4 的 for 循环要做 d(u)次,而语句 2~11 的 while
循环需要做 n 次,因而整个循环做 ( ) 2
u Vd u m
=
 次 O(1) 操作,又 visited、s
和 count 的赋值都需要 n 次操作,因而T (n, m) = (n + m) 。
如果采用邻接矩阵,则语句 2~11 的 while 循环总共需要做 n2 次 O(1) 操作,
visited、s 和 count 的赋值都需要 n 次操作,因而 2
T (n, m) = (n ) 。 证毕
由定理 2.2.1 可知,宽度优先搜索算法能够遍历图 G 的包含 v 的连通分支中
的所有顶点。对于不连通的图,可以通过在每个连通分支中选出一个顶点作为起
点,应用宽度优先搜索算法于每个连通分支,即可遍历该图的所有顶点。
程序 2-2-5 图的宽度优先遍历算法伪代码
BFT(G, n ) //count、s 同 BFS 中的说明,branch 是统计图 G 的
//连通分支数,n 是图 G 的顶点数。
count:=0; branch:=0;
for i to n do
s[i]:=0; //将所有的顶点标记为未被访问
end{for}
for i to n do
if s[i]=0 then
BFS(i); branch:=branch+1;
end{if}
end{for}
end{BFT}
关于 BFT 算法的时间和空间复杂性与 BFS 同样估计(注意空间的差别)。
如果 G 是连通图,则 G 有生成树。注意到 BFS 算法中,由 4~8 行,将所有
邻接于顶点 u 但未被访问的顶点 w 添加到待检测队列中。如果在添加 w 的同时将
边(u,w)收集起来,那么算法结束时,所有这些边将形成图 G 的一棵生成树。称
为图 G 的宽度优先搜索树。为此,在 BFS 算法的第 1 行增加语句 T:={},在第 7
行增加语句 T:=T∪{(u,w)}即可。


第二章 图与遍历算法 33
图 G 及其邻接链表
➢ 图的深度优先搜索
深度优先搜索是沿着顶点的邻点一直搜索下去,直到当前被搜索的顶点不
再有未被检索的邻点为止,此时,从当前被搜索的顶点原路返回到在它之前被访
问的顶点,并以此顶点作为当前搜索顶点。继续这样的过程,直至不能执行为止。
程序 2-2-6 图的深度优先搜索算法伪代码
DFS(v) //访问由 v 到达的所有顶点,计数器 count 已经初始化为 1;
//数组 visited 标示各顶点被访问的序数,其元素已经初始化为 0。
1. visited(v):=count;
2. for 邻接于 v 的每个顶点 w do
3. if visited(w)=0 then
4. count:=cout+1;
5. DFS(w);
6. end{if}
7. end{for}
8.end{DFS}
B
0
C0
0
A
0
D
0
E0
0
D
0
E
0
F
0
G0
0
A
0
F
0
G0
0
C
0
H0
0
B
0
H0
0
B
0
H0
0
C
0
H0
0
A
B
C
D
E
F
G
H
E FG
C
A
D
B
H
E FG
C
A
D
B
H
56
3
47
2
1
8
图 G 的宽度优先搜索树
56
7
8
2
1
4
E FG
C
A
D
B
H
图 G 的深度优先搜索树
3


34 第二章 图与遍历算法
对于连通图,深度优先算法也能产生一棵生成树,称为深度优先搜索树。读
者可以在算法中添加语句使算法同时获得深度优先搜索树。
比较宽度优先和深度优先搜索算法,发现它们有很大不同。在 BFS 中,当搜
索到某个顶点时,就要同时检索该顶点的所有相邻顶点,并依次放进队列的尾部;
在 DFS 中,当检索到某个顶点时就同时访问了该顶点,继续纵深检索与该顶点相
邻的其它一个未被检索过的顶点;前者用一个队列实现,而后者可以用一个环境
栈来实现。当然,前者也可以用一个栈来实现,称为 D-搜索。然而,D-搜索已
经不同于 BFS 了。
§3 双连通与网络可靠性
通信网络的抽象模型可以是一个无向图:顶点代表通信站,边代表通信线路。
图 2-3-1 和图 2-3-2 是两个通信网络示意图。直观可见,图 2-3-1 的通信网络可
靠性较高,因为即使有一个网站出现问题,其它网站之间的通信仍能够继续进行。
而图 2-3-2 所示的网络则不能,只要网站 F 发生故障,位于其左右两部分的网站
之间就无法连通了。在图 2-3-2 中,象 F 这样的顶点称为割点。
定义 连通无向图 G 中的顶点 v 称为割点,如果在 G 中去掉 v 及其关联的边,
剩下的图就不再连通。
没有割点的连通图称为 2-连通的(也称为块)。图 G 中极大的 2-连通子图称
为 G 的一个 2-连通分支。在图 2-3-2 中除了 F 以外,C 和 G 也都是割点。这个图
有 5 个 2-连通分支(参见图 2-3-3)。图 2-3-1 是 2-连通的。
就通信网络而言,当然希望没有割点。如果现有的网络有割点,则设法增加
一些线路(当然希望尽量少的增加),使之成为 2-连通的。
图 2-3-1 图 2-3-2
ED
AB
F
C
G
B
A
C
DE
F
G
H
I
J


第二章 图与遍历算法 35
添加边的算法:
E1: for 每个割点 u do
E2: 设 B1,B2,... ,Bk,是包含割点 u 的全部 2-连通分支
E3: 设 Vi 是 Bi 的一个顶点,且 Vi≠u,1≤i≤k。
E4: 将边(Vi, Vi+1)添加到 G,1≤i≤k-1。
E5:endfor
问题:设计算法测试一个连通图是否 2-连通;若不是,算法将识别出割点。
解决方法:以深度优先遍历算法为基础,加以割点识别步骤。
当采用深度优先遍历算法时,顶点 v 被访问的序数称为 v 的深索数,记做
DFN(v).
图 2-3-4 添加边使成为二连通图
B
A
C
DE
F
G
H
I
J
图 2-3-3 图 2-3-2 的 5 个 2-连通分支
C
E
B
A
C
F
F
G
I
J
D
C
H
G
假定图的邻 接链表是按
照字母的先
后顺序构造
的
a,b,c,d 是图
G 关于这
棵生成树
的余边
图 2-3-5 图 G 及其深度优先搜索树
18
2 a7
6c
d
9
3
4 5 10
b
B
A
C
DE
F
G
H
I
J


36 第二章 图与遍历算法
按照深度优先搜索树将图中的顶点分层,使得上层是下层的祖先,而同层之间是
兄弟关系:
1.关于深度优先搜索树 T,图 G 的每一条边(u,v)的两个端点 u、v 之间,
或 u 是 v 的祖先,或 v 是 u 的祖先,即不是平辈关系。
2.树 T 的根是图 G 的割点当且仅当其在 T 中至少有两个子节点;
3. 既不是根也不是叶的节点 u 不是 G 的割点当且仅当 u 在 T 中的每个子节
点 w 都至少有一个子孙(或 w 本身)关联着一条边 e(实际上是余边),e 的另一
个端点是 u 的某个祖先(e 一定是树 T 的余边);
4.叶节点不能是割点。
根据性质 3,4,深度优先搜索树 T 的非根节点 u 是 G 的割点当且仅当 u 至
少有一个儿子 w,w 及其子孙都不与 u 的任何祖先相邻。
注意到 u 的深索数一定小于其子孙的深索数,所以深索数 DFN 并不能反映一
个顶点是否是割点的情况。为此,我们递归地定义各个顶点 u 的最低深索数 L(u):
定义 顶点 u 的最低深索数 L(u)定义为
L(u):=min{DFN(u), min{DFN(x)|(u,x)是 T 的余边},
min{L(w)|w 是 u 的子节点} }
可见,如果 L(u)≠DFN(u),则必定 L(u)< DFN(u),此时,L(u)是 u 通过一条子孙
路径(至多后跟一条 T 的余边)所可能到达的顶点的最低深索数。图 2-3-6 中,红
色数字表示了各顶点的最低深索数。
结论:如果 u 不是深度优先搜索树的根,则 u 是图 G 的割点当且仅当 u 有某
个子节点 w,w 的最低深索数不小于 u 的深索数,即存在 v 的子节点 w,使得
L(w)≥DFN(u),
看来要想识别图 G 的所有割点,需要先获得深度优先搜索树 T,然后按后根
8 d
1a
b
6c
45
1
1
6
1
6
A
B
F
E
G
D
C
I
g
H
J
1
2
3
45
7
6
9
8
10
图
2-3-6
深
度 优
先 树 的
分 层


第二章 图与遍历算法 37
优先次序遍历 T,计算出各个顶点的最低深索数。但是,从函数 L 的定义可知这
两步工作可以同时完成。
程序 2-3-1 计算 DFN 和 L 的算法伪代码
DFNL(u,v) //一个深度优先搜索算法,u 是开始顶点。在深度优先树中,
//若 u 有父亲,则 v 即是。数组 DFN 初始化为 0,变量 num 初始
//化为 1,n 是图 G 的顶点数。
global DFN[n],L[n],num,n
1. DFN(u):=num; L(u):=num; num:=num+1;
2. for 每个邻接于 u 的顶点 w do
3. if DFN(w)=0 then
4. DFNL(w,u); //访问 w
5. L(u):=min(L(u),L(w));
6. else
7. if w≠v then L(u):=min(L(u),DFN(w)); end{if}
8. end{if}
9. end{for}
10.end{DFNL}
为了得到图 G 的 2-连通分支,需对 DFNL 作一些修改。注意到,在第 4 行调
用 DFNL 时,如果出现情况:
L(w)≥DFN(u),
就可以断定 u 或是 T 的根,或是图 G 的割点。不论那种情况,都将边(u,w)以及
对 DFNL 这次调用期间遇到的所有树边和余边加在一起(除了包含在子树 w 中其
它 2-连通分支中的边以外),就构成图 G 的一个 2-连通分支。鉴于此,将 DFNL
做如下修改:
// 引进一个存放边的全程栈 S;
// 在 2 到 3 行之间加:
2.1 if v≠w and DFN(w)<DFN(u) then
2.2 将(u,w)加到 S 的顶部;
2.3 end{if}
// 在 4 到 5 行之间加下列语句:
4.1 if L(w)≥DFN(u) then
4.2 print(’new biconnected component’);
4.3 loop


38 第二章 图与遍历算法
4.4 从栈 S 的顶部删去一条边;
4.5 设这条边是(x,y)
4.6 print(“(”,x,“,”,y,“)”);
4.7 until ((x,y)=(u,w) or(x,y)=(w,u));
4.8 end{if}
如果 G 是有 n 个顶点 m 条边的连通图,且 G 用邻接链表表示,那么 DFN 的计
算时间是 O(n+m).一旦算出 L[1:n],G 的割点就能在 O(n)时间识别出来,因此,
识别全部割点总的时间不超过 O(n+m).
当 DFNL 增加了上述语句之后,其计算时间仍然是 O(n+m).
定理 2.3.1 设 G 是至少有两个顶点的连通图,则算法 DFNL 增加了语句
2.1-2.3 和 4.1-4.8 的算法能正确生成 G 的全部 2-连通分支。
证明:略。
§4 对 策 树
在一盘棋中,对弈各方都要根据当前的局势,分析和预见以后可能出现的局
面,决定自己要采取的各种对策,以争取最好的结果。本节我们将用树的模型来
描述对弈局势,并给出产生对策树的算法。先来分析拾火柴棍游戏。
在盘面上放n支火柴,由弈者A和B两人参加比赛。规则:两人轮流
从盘上取走1,2或3支火柴,拿走盘中最后一支火柴者为负。
以盘中剩下的火柴数来表示该时刻的棋局。棋局序列 C1,C2,...,Ck 称为有效(棋
局)序列,如果:
 C1 是开始棋局;
 Ci 不是终止棋局,i=1,2,...,k-1;
 由 Ci 走到 Ci+1 按下述规则:若 i 是奇数,则 A 走一合法步骤;
若 i 是偶数,则 B 走一合法步骤。
以 Ck 为终局的一个有效棋局序列 C1,C2,...,Ck 是此游戏的一盘战例。有限
次博弈游戏的所有可能的实际战例可以用一棵树来表示.
分别用方格与圆圈表示弈者 A 和 B 该走棋的棋局。如果棋局 D 是棋局 C 经过
一次合法步骤的结果,则有一条连结顶点 C 和 D 的边。叶节点表示一个终局,圈
B 标志的地方表示 B 取胜;方格 A 标志的地方表示 A 取胜。从图中可以看出,只
要 A 第一步取 1 根火柴,则不论 B 如何选择,A 都有取胜的应着。否则,A 不保
证取胜。那么,这样取胜的棋着是怎样确定的?是否有一般的规律?对策树在决
定采取什么对策,即确定弈者下一步应走哪步棋上是很有用的。事实上,走哪一


第二章 图与遍历算法 39
步使自己获胜的机会最大,可以用一个估价函数 E(X)来评价,它是棋局 X 对于弈
者价值大小的估计。设 E(X)是弈者 A 的估价函数,若棋局 X 能使 A 有较大的获胜
机会,则 E(X)的值就高,若棋局 X 使得 A 有较大的失败可能,则 E(X)的值就低。
那些使得A获胜的终止棋局或不管B如何应着都保证A能获胜的棋
局,则E(X)取最大值。而对于保证B取胜的棋局,E(X)则取最小值
弈者 A 走棋
弈者 B 走棋
图 2-4-1 n=6 时的拾火柴游戏状态树图
对于其对策树顶点较少的博弈游戏,例如 n=6 的拾火柴棍游戏,可以采用先
对终局定义 E(X),而后逐步确定各个棋局 X 的价值 V(X)的方法给出 A 在各步走
棋参考。在 n=6 的拾火柴棍游戏的对策树中,终止节点是叶顶点,我们给出如
下估值:
1,
() 1,
A
EX B
= 
若 能赢
- 若 赢 (2.4.1)
而对于其它节点,需要给出对于 A 来说能够取胜的价值。例如,若已经知道节点
b,c,d 的价值,则父节点 a 的价值应当取它们的价值的最大值,当节点 a 代表
的棋局处应该 A 走棋时。因为从棋局 a 出发,A 下一着棋的走法应当导致其得胜
可能性最大的下一步棋局。一般地,若 X 不是叶节点,其有子节点 X1,X2,...,
Xd,则定义 X 的价值为
1
1
max{ ( )} ,
( ) min{ ( )} ,
i
id
i
id
VX X
VX VX X


= 

若 是方形节点 若 是圆形节点 (2.4.2)
如此计算出对策树中各节点的价值后,就很容易看出 A 要(想取胜)在其所
/
// / / /
/ BB B
B
B
AA A
A
A
A
AA A
A
/// //
/
//// /// // /// // / // / A
A
/// /
/B
BB B
// / / B
12 3
1
-1
1
1
1
-1
1
-1
1
-1
1
1
-1
1
-1
1
-1
1
-1
1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
-1
1
1
1
1
1 11 1
1
1
11
1 11
1
1
1
1 11
1
1
1
B/ B
/
// //
///// // // / / /


40 第二章 图与遍历算法
处的各个棋局上应该采取的对策了。从图中可以看出 A 有三条取胜的路线。用
(2.4.2)确定各个节点价值的过程称为最大最小过程。
实际上,图 2-4-1 给出的对策树恰好列出了 n = 6 时拾火柴棍游戏所有可能
的棋局。从对策树根节点出发到达每个叶节点的路径恰是一个战例。但是对于较
大规模的博弈,一般很难列出所有可能的棋局序列。比如,国际象棋,它的完整
的对策树的节点数,据估计,将达到 10100,即使用一台每秒能生成 1011 个节点的
计算机,也需要 1080 年以上的时间才能生成完整的对策树。所以,对于具有大规
模对策树的博弈,不是采取考察其完整对策树的办法来确定弈者的对策。这种情
况下,通常采用向前预测几步才决定走一步的策略,实际上是假想一组局面。这
组局面也可以用对策树的子树表示出来.图 2-4-2 就是一盘假想的博弈部分棋局
对策树.用估价函数估定这样的对策树(实际是子树)的叶节点的值,然后根据
公式(2.4.2)逐一确定其它节点的价值,最后确定下一步该走的棋。使用产生数
级对策树确定下一步棋的方法所导致的棋局的质量取决于这两名弈者所采用的
估价函数的功能和通过最大最小过程来确定当前棋局的价值 V(X)所使用算法的
好坏。
图 2-4-2 一盘假想博弈游戏的部分对策树
因为 A、B 两弈者走棋总是交替进行的,在写递归算法时经常要区分 A、B,
以确定是取最大值还是取最小值。为克服这个缺点,只要改变 B 者值的符号就可
以。不妨假定弈者 A 是一台计算机, A 为了确定下一着棋,其应该有一个算法
max
x
min
max
x
min
E(x)
max
A胜 A负 A胜 A负 A负
A 的最优棋着
P11
3
-∞
2
-3
0
32
3 -1 -∞
+∞ -1
1
+∞
3
-∞ -∞
2
3 15 9 2 7 2
-3
0
15
10
P41 P42 P43 P45
P51 P52 P53 P54 P55 P56 P57 P58 P59 P5,10 P5,11
P31 P33 P34
P21 P22 P23
P44
P32 P35 P36 P37
P24
弈者 A 走子
弈者 A 走子


第二章 图与遍历算法 41
计算所有 V(X)。为产生一个递归程序,将公式(2.4.2)中的取最小部分也改成取
最大,为此,需要将 V(X)改为 V(X):
1
e(X) ,
'( ) max{ '( )} ,
i
id
X
VX VX X

=  −

若 是叶节点
若 不是叶节点 (2.4.3)
其中,X1, X2,┄, Xd 是 X 的所有子节点。当 X 是叶节点时,若 X 是 A 走棋的位
置,则 e(X)=E(X);若是 B 走棋的位置,则 e(X)=-E(X)。因为,一个节点的值只
有在它的所有子节点的值求出后才能确定,所以,此算法是按照后根次序遍历对
策树中以 X 为根的 h 级子树。
程序 2-4-1 对策树的后根次序求值算法
VE(X, h )//通过至多向前看 h 着棋计算 V (′X),弈者 A 的估价函数是 e(X)。
//假定由任一不是终局的棋局 X 开始,此棋局的合法棋着只允许将棋
//局 X 转换成棋局 X1,X2,...,Xd.
if X 是终局或 h =0 then return(e(X)) end{if}
ans:= -VE(X1, h -1);//遍历第一棵子树
for i from 2 to d do
ans:=max(ans,-VE(Xi, h -1));
end{for}
return(ans);
end{VE}
只要将偶数级节点的价值改变一下符号,图 2-4-2 中对策树上各棋局的价值即是
调用算法 VE 的计算结果,此时,X=P11, h =4.各棋局的值按如下次序依次确定:
P31, P32, P21, P51, P52, P53, P41, P54, P55, P56, P42, P33, ..., P37, P24, P11 .
算法 VE 的目标是求取在棋局 P11 情况下对于弈者 A 的 V(P11)值,以决定 A 下一步
要采取的决策。但是,从这个例子的计算过程来看,为达此目标不必计算上述所
有棋局的估值。比如,当知道 V(P41)=3 后,就知道 V(P33)≥3,因为 P33 是求最大
值点。当我们知道 P55 处的估值为 2 时,就知道 V(P42)≤2<3,因为 P42 是求最小值
节点。这意味着不必再生成节点 P56 。如果给求最大值点 Y 赋一个值(Y),代表
到目前为止所知道的该节点估值的一个下界,那么,在求其子节点 X 的估价值时
就有了参考,可以省掉不必要的计算。同样地,如果给求最小值点 Y 赋一个值
(Y ) ,代表到目前为止所知道该节点估值的一个上界,那么,在求其儿子节点
X 的估值时就有了参考,可以省掉不必要的计算。这一法则称之为−  截断,
具体叙述如下:设 Y 是 X 的父节点,X 有子节点 X1,X2,...,Xd:


42 第二章 图与遍历算法
 若 X 是取最小值的节点,则一旦知道 V (X k ) (Y ) 就不必再计算以
Xk+1,...,Xd 为根的子树的任何节点的估值;
 若 X 是取最大值的节点,则一旦知道 V (X k )  (Y ) 就不必再计算以
Xk+1,...,Xd 为根的子树的任何节点的估值;
采用− 截断规则可以改进算法 VE。在算法 VE 中,各节点的估值是用公
式(2.4.3)计算的 V′,所以,每个节点都看作是求最大值节点。于是,各节点的
,值可以统一为一个值,(Y ) 代表迄今所知V '(Y ) 的最好下界。−  截断
规则可以重述为:对于任一节点 X,设 Y 是该节点的父节点,而且令 D = −(Y ) ,
那么,如果 X 的估值判断为不小于 D 时,则可以停止生成 X 的其他子节点。
程序 2-4-2 使用−  截断规则的后根次序求值算法
VEB(X, h ,D)//通过至多向前看 h 着棋,使用−  截断规则和
// 公式(2.4.3)计算 V (′X),弈者 A 的估价函数是 e(X)。假定
// 由任一不是终局的棋局 X 开始,此棋局的合法棋着只允许
// 将棋局 X 转换成棋局 X1,X2,...,Xd.
if X 是终局或 h =0 then return(e(X)) end{if}
ans:=-VEB(X1, h -1,∞);// V (′X)到目前可能的最大值
for i from 2 to d do
if ans ≥ D then return(ans)end{if}//使用−  截断规则
ans:= max(ans,-VEB(Xi, h -1,-ans));
end{for}
return(ans);
end{VEB}
如果 A 从 Y 处走子,那么,通过初次调用 VEB(Y,h,∞)就可以预先看 h 着棋
来正确地计算出 V (′Y)。
算法 VEB 还可以进一步改进,能造成更大的截断。这只需要观察孙子节点的
值达到多大才能影响到爷爷节点的值即可得到线索。仍采用公式(2.4.3)来计算
V (′X),用 (Y ) 表示迄今所知 V (′Y)最好下界,并设 Y 是 X 的父节点,X 有子节点
X
1,X2,...,Xd ,要想节点 X 的值对 Y 的值产生影响,就必须要求 X 的每个子节
点 Xi 的值满足:V (′Xi)>(Y ) 。因为,若某个 V (′Xi)≤(Y ) ,则


第二章 图与遍历算法 43
1
'(X) max{ '( )} '( ) ( )
ji
jd
V V X V X Y

= −  −  − ,即 -V (′X) ≤(Y )
而V '(Y )  max{(Y ), −V '(X )} ,所以,V (′Y)不受 V (′X)的影响。这说明(Y ) 是 X
的子节点估值应该有的一个下界。这样,我们在算法中再引入一个参数值 LB,
表示迄今知道的节点 X 的所有子节点都该有的一个下界,一旦判断出节点 X 处的
估值不超过这个下界,就可以停止生成节点 X 的其他子节点。根据上面的分析,
-D 可以充当 LB。这产生了下面的改进算法:
程序 2-4-3 纵深−  截断算法
VLB(X, h ,LB,D) //通过至多向前看 h 着棋,使用−  截断规则和公式
// (2.4.3) 计算 V (′X),弈者 A 的估价函数是 e(X)。假定由任一不是
//终局的棋局 X 开始,此棋局的合法棋着只允许将棋局 X 转换成棋局
// X1,X2,...,Xd. -D 是迄今所知的 X 的父节点估值的最好下界,
//LB 是迄今所知的 X 的子节点估值应该有的下界。
if X 是终局或 h =0 then return(e(X)) end{if}
ans = LB;
for i to d do
if ans ≥ D then return(ans)end{if} //使用−  截断规则
ans = max(ans,-VLB(Xi, h -1,-D,-ans));
end{for}
return(ans);
end{VLB}
不难证明,初次调用 VLB(Y,h,-∞,∞) 与调用 VE(Y,h)得到的结果是相同
的。
图 2-4-3 是一棵假想的对策树,在这棵树中,使用算法 VLB 比使用算法 VEB
产生更大的截断。调用 VEB 时,假定最初的调用为 VEB(P1,h,∞),其中,h 是这
棵树的高度。在检查了 P1 的左子树之后,知道 P1 处估值的一个下界值 10,并且相
继生成节点 P3,P4,P5 和 P6。此后,V (′P6)确定为 9,至此,知道 P5 处估值的一个下
界值-9。算法接下去要计算节点 P7 处的估值。调用算法 VLB 时,假定最初的调用
为 VLB(P1, h ,-∞,∞), 在检查了 P1 的左子树之后,知道 P1 处估值的一个下界值
10,因而知道 P4 处的估值应该不小于 10,根据算法,在检索节点 P5 时所知道的
P4 处估值的最好下界还是 10,因而,P6 处的估值也应该不小于 10。但是,在检
查得知 P6 处的估值为 9 时,算法就结束了,节点 P7 不必生成。


44 第二章 图与遍历算法
图 2-4-3 一棵假想的对策树
习题 二
1.证明下列结论:
1)在一个无向图中,如果每个顶点的度大于等于 2,则该图一定含有圈;
2)在一个有向图 D 中,如果每个顶点的出度都大于等于 1,则该图一定含
有一个有向圈。
2.设 D 是至少有三个顶点的连通有向图。如果 D 中包含有向的 Euler 环游
(即是通过 D 中每条有向边恰好一次的闭迹),则 D 中每一顶点的出度和入度
相等。反之,如果 D 中每一顶点的出度与入度都相等,则 D 一定包含有向的 Euler
环游。这两个结论是正确的吗?请说明理由。如果 G 是至少有三个顶点的无向
图,则 G 包含 Euler 环游的条件是什么?
3.设 G 是具有 n 个顶点和 m 条边的无向图,如果 G 是连通的,而且满足 m
= n-1,证明 G 是树。
4.假设用一个 n×n 的数组来描述一个有向图的 n×n 邻接矩阵,完成下
面工作:
1) 编写一个函数以确定顶点的出度,函数的复杂性应为 (n) ;
2) 编写一个函数以确定图中边的数目,函数的复杂性应为 (n2 ) ;
3) 编写一个函数删除边 (i, j) ,并确定代码的复杂性。
5.下面的无向图以邻接链表存储,而且在关于每个顶点的链表中与该顶点
P7
≥10
-10
≥10
9
P1
P3
P2
P4
P5
P6


第二章 图与遍历算法 45
相邻的顶点是按照字母顺序排列的。试以此图为例描述讲义中算法 DFNL 的执行
过程。
6.对图的另一种检索方法是 D-Search。该方法与 BFS 的不同之处在于将队
列换成栈,即下一个要检测的节点是最新加到未检测节点表的那个节点。
1)写一个 D-Search 算法;
2)证明由节点 v 开始的 D-Search 能够访问 v 可到达的所有节点;
3)你的算法的时、空复杂度是什么?
7.考虑下面这棵假想的对策树:
1) 使用最大最小方法(2-4-2)式获取各节点的值;
2) 弈者 A 为获胜应该什么棋着?
3) 列出算法 VEB 计算这棵对策树节点的值时各节点被计算的顺序;
4) 对树中每个节点 X,用(2-4-3)式计算 V (′X);
5) 在取 X=根, l = 10, LB = −, D =  的情况下,用算法 VLB 计算此树的
根的值期间,这棵树的哪些节点没有计算?
一个无向图 G
A
B
E
D
G
C
F
20
10
5
15 6 4 8 15 5 10 30 5 9 20 50 18


第三章 分治算法
46
第三章 分 治 算 法
§1. 算法基本思想
先来分析折半搜索算法
程序 3-1-1 折半搜索
BiFind(a,n)
//在数组 a[1..n]中搜索 x,数组中的元素满足 a[1]  a[2]  ...  a[n]。
//如果找到 x,则返回所在位置(数组元素的下标),否则返回 –1
global a[1..n], n;
integer left,right,middle;
left:=1; right:=n;
while left  right do
middle:=(left+right)/2;
if x=a[middle] then return(middle); end{if}
if x>a[middle] then left:=middle+1;
else right:=middle-1;
end{if}
end{while}
return(–1); //未找到 x
end{BiFind}
while 的每次循环(最后一次除外)都将以减半的比例缩小搜索范围,所
以,该循环在最坏的情况下需要执行 (log n) 次。由于每次循环需耗时 (1) ,因
此在最坏情况下,总的时间复杂度为 (log n) 。
折半搜索算法贯彻一个思想,即分治法。当人们要解决一个输入规模,比
如 n,很大的问题时,往往会想到将该问题分解。比如将这 n 个输入分成 k 个不
同的子集。如果能得到 k 个不同的可独立求解的子问题,而且在求出这些子问题
的解之后,还可以找到适当的方法把它们的解合并成整个问题的解,那么复杂的
难以解决的问题就可以得到解决。这种将整个问题分解成若干个小问题来处理的
方法称为分治法。一般来说,被分解出来的子问题应与原问题具有相同的类型,
这样便于算法实现(多数情况下采用递归算法)。如果得到的子问题相对来说还
较大,则再用分治法,直到产生出不用再分解就可求解的子问题为止。人们考虑


第三章 分治算法 47
和使用较多的是 k=2 的情形,即将整个问题二分。以下用 A[1..n]来表示 n 个输
入,用 DiCo(p,q)表示用分治法处理输入为 A[p..q]的问题。
分治法控制流程
DiCo(p,q)
global n,A[1..n];
integer m,p,q; // 1pqn
if Small(p,q) then return(Sol(p,q));
else m:=Divide(p,q); // pm<q
return(Combine(DiCo(p,m),DiCo(m+1,q)));
end{if}
end{DiCo}
这里,Small(p,q)是一个布尔值函数,用以判断输入规模为 q-p+1 的问题
是否小到无需进一步细分即可容易求解。若是,则调用能直接计算此规模下子问
题解的函数 Sol(p,q). 而 Divide(p,q)是分割函数,决定分割点;Combine(x,y)
是解的合成函数。如果假定所分成的两个问题的输入规模大致相等,则 DiCo 总
的计算时间可用下面的递归关系来估计:
() ,
( ) 2 ( / 2) ( ) , ( )
g n if n is small
T n T n f n f n is the time of Combine
=  +

(3.1.1)
例 3.1.1 求 n 元数组中的最大和最小元素
最容易想到的算法是直接比较算法:将数组的第 1 个元素分别赋给两个临
时变量:fmax:=A[1]; fmin:=A[1]; 然后从数组的第 2 个元素 A[2]开始直到第 n
个元素逐个与 fmax 和 fmin 比较,在每次比较中,如果 A[i] > fmax,则用 A[i]
的值替换 fmax 的值;如果 A[i] < fmin,则用 A[i]的值替换 fmin 的值;否则保
持 fmax(fmin)的值不变。这样在程序结束时的 fmax、fmin 的值就分别是数组
的最大值和最小值。这个算法在最好、最坏情况下,元素的比较次数都是 2(n-1),
而平均比较次数也为 2(n-1)。 如果将上面的比较过程修改为:
从数组的第 2 个元素 A[2]开始直到第 n 个元素,每个 A[i]都是首先与 fmax 比较,
如果 A[i]>fmax,则用 A[i]的值替换 fmax 的值;否则才将 A[i]与 fmin 比较,如
果 A[i] < fmin,则用 A[i]的值替换 fmin 的值。
这样的算法在最好、最坏情况下使用的比较次数分别是 n-1 和 2(n-1),而平均比
较次数是 3(n-1)/2,因为在比较过程中,将有一半的几率出现 A[i]>fmax 情况。


第三章 分治算法
48
如果采用分治的思想,可以构造算法,其时间复杂度在最坏情况下和平均用时均
为 3n/2-2:
程序 3-1-2 递归求最大最小值算法伪代码
MaxMin(i,j,fmax,fmin)//A[1:n]是 n 个元素的数组,参数 i,j
//是整数,1≤i≤j≤n,使用该过程将数组 A[i..j]中的最大最小元
//分别赋给 fmax 和 fmin。
global n, A[1..n];
integer i, j;
if i=j then
fmax:=A[i]; fmin:=A[i]; //子数组 A[i..j]中只有一个元素
elif i=j-1 then //子数组 A[i..j]中只有两个元素
if A[i]<A[j] then
fmin:=A[i]; fmax:=A[j];
else fmin:=A[j]; fmax:=A[i];
end{if}
else
mid:=(i+j)/2; //子数组 A[i..j]中的元素多于两个
MaxMin(i, mid, lmax, lmin);
MaxMin(mid+1, j, rmax, rmin);
fmax:=max(lmax, rmax);
fmin:=min(lmin, rmin);
end{if}
end{Maxmin}
如果用 T(n)来表示 MaxMin 所用的元素比较次数,则上述递归算法导出一个
递归关系式:
 



+ +
=
=
=
( /2 ) ( /2 ) 2 2
12
01
()
Tn Tn n
n
n
T n (3.1.2)
当 n 是 2 的方幂时,设 k
n = 2 ,有
( ) 2 ( / 2) 2
2(2 ( / 4) 2) 2
4 ( / 4) 4 2
Tn Tn
Tn
Tn
=+
= ++
= ++


第三章 分治算法 49
1
11
1
2 (2) 2
2 22
3 /2 2
ki
ik
kk
T
n
−
 −
−
=+
= +−
=−

无论是最好、最坏、还是平均情况,MaxMin 所用的比较次数都是 3n/2-2,
比前面提到的算法(在最坏情况下)节省了 25%的时间。实际上,任何一种以元
素比较为基础的找最大最小元素的算法,其元素比较次数的下界是 3n / 2 − 2 。
从这种意义上来说,MaxMin 算法是最优的。然而,由于需要 log n +1级的递归,
每次递归调用需要将 i,j,fmax,fmin 和返回地址的值保留到栈中,需要多占
用内存空间。而且由于这些值出入栈时也会带来时间开销,特别当 A 中元素的比
较次数和整数 i 与 j 的比较次数相差无几时,递归求最大最小值算法未必比直接
求最大最小值算法效率高。
例 3.1.2 搜索算法的时间下界
分析上节提到的折半搜索算法,我们已经知道其时间复杂度是 O(log n) 。事
实上,我们可以用一个二元比较树来分析折半搜索算法的时间复杂性。以下是
n=9 的二元比较树:
由图可见,当 x 在数组 A 中时,算法在圆形结点结束;不在 A 中时,算法
在方形结点结束。因为 23  9  24 ,所以比较树的叶结点的深度都是 3 或 4。
49
5
7
1 3 68
2
N=9 情况下,折半搜索的二元比较树


第三章 分治算法
50
而元素比较的最多次数为 4。一般地有:
当  k k)
n 2 −1,2
 时,成功的折半搜索至多做 k 次比较,而不成功的折半搜索
或者做 k-1 次比较,或者做 k 次比较。
现在假设数组 A[1..n]满足:A[1]< A[2]< ...< A[n]。要搜索元素 x 是否在
A 中。如果只允许进行元素间的比较而不允许对它们进行其它的运算,则所设计
的算法称为以比较为基础的算法。
任何以比较为基础的搜索算法的执行过程都可以用一棵二元比较树来描
述。每次可能的比较用一个内结点表示,对应于不成功的结果有一个外结点(叶
结点)与之对应。线性搜索和折半搜索的二元比较树如下:
定理 3.1.1 设数组 A[1..n]的元素满足 A[1]< A[2]< ...< A[n]。则以比较
为基础,判断 x  A[1..n] 的任何算法,在最坏情况下所需的最少比较次数 F(n)不
x:A[1]
x:A[2]
x:A[n]
不成功
不成功
不成功 不成功
图 3-1-1 模拟线性搜索过程
x:A[(n+1)/2]
x:A[(n+1)/4] x:A[(3n+1)/4 ]
x:A[(n+1)/2-1]
x:A[1] x:A[(n+1)/2+1] x:A[n]
不成功 不成功 不成功 不成功 不成功 不成功 不成功 不成功
····
····
·····
·
··
·
··
·
图 3-1-2 模拟折半搜索过程


第三章 分治算法 51
小于log(n+1)。
证明 通过考察模拟求解搜索问题的各种可能算法的比较树可知,F(n)不大于
树中由根到叶子的最长路径的距离,即树的高度。也就是说,在最坏情况下每种
搜索算法的比较次数都是比较树的高度 k。对于每个二叉比较树,必有 n 个内结
点与 x 在 A 中的 n 种可能的情况相对应。而每个内结点的深度都不会超过该树的
高度减 1,即 k-1。因而,内结点的个数不超过 2k −1,即  2k −1
n 。由此得 F(n)=
k  log(n+1)。 证毕
定理 3.1.1 说明,任何一种以比较为基础的搜索算法,其最坏情况下所用时
间不可能低于 (log n) 。不可能存在其最坏情况下时间比折半搜索数量级(阶)
还低的算法。事实上,折半搜索所产生的比较树的所有叶结点都在相邻的两个层
次上,而且这样的二叉树使得比较树的高度最低。因此,折半搜索是解决搜索问
题在最坏情况下的最优算法。
§2. 排序算法
问题:已知 n 个元素的数组 A[1..n],将 A 中元素按不降顺序排列。
⚫ 归并排序算法
先来分析插入排序算法
程序 3-2-1 向有序数组插入元素 程序 3-2-2 插入排序
Insert(a, n, x) InSort(a, n)
//向数组 a[1..n]中插入元素 x //对 a[1..n]进行排序
//假定 a 的大小超过 n for i from 2 to n do
int i; t:=a[i];
for i from n by -1 to 1 do Insert(a, i-1, t);
if x<a[i] then end{for}
a[i+1]:=a[i]; end{InSort}
end{if}
end{for}
a[i+1]:=x; 将上述两个算法合并在一起,
end{Insert} 得到下述插入排序算法


第三章 分治算法
52
程序 3-2-3 插入排序算法
InSort(a, n)
for i from 2 to n do
t:=a[i];
integer j;
for j from i-1 by -1 to 1 do
if t<a[j] then a[j+1]:=a[j]; end{if}
end{for}
a[j+1]:=t;
end{for}
end{InSort}
内层的 for 循环语句可能执行 i 次( i = 1, 2, , n −1 ),因此最坏情况下的时
间是
( 1) / 2 ( 2 )
11
i nn n
in
= − =

 −
在这个算法中,大部分的时间都用在挪动元素上,随着已经排好顺序的数
组的增长,被挪动的元素的个数也在增加,而且在整个过程中,很多元素不止一
次被挪动。以下程序从某种程度上减少了这种浪费。这一算法的基本思想是采用
分治的方法,将要排序的数组分成两部分,先对每部分进行排序,然后再将两部
分已经排好序的子数组的元素按照从小到大的顺序逐一摆放在一个新的数组中。
这一过程也许需要多次分解和组合,是一个递归过程。
程序 3-2-4 归并排序主程序伪代码
MergeSort(low, high) // A[low .. high]是一个全程数组,含有
// high-low+1 个待排序的元素。
integer low, high;
if low < high then
mid:= (low+high)/2 //求当前数组的分割点
MergeSort(low, mid) //将第一子数组排序
MergeSort(mid+1, high) //将第二子数组排序
Merge(low, mid, high) //归并两个已经排序的子数组
end{if}
end{MergeSort}
这里我们使用了辅助程序 Merge:


第三章 分治算法 53
程序 3-2-5 合并过程伪代码
Merge(low, mid, high) //已知全程数组 A[low .. high], 其由
//两部分已经排好序的子数组构成:A[low .. mid]和 A[mid+1 .. high]。
//本程序的任务是将这两部分子数组合并成一个整体排好序的数组,
//再存于数组 A[low .. high].
integer h, i, j, k, low, mid, high;
global A[low .. high];
local B[low .. high]; //借用临时数组 B
h:=low, i:=low, j:=mid+1;
// h, j 是拣取游标, i 是向 B 存放元素的游标
while hmid and jhigh do //当两个集合都没有取尽时
if A[h]A[j] then B[i]:=A[h], h:=h+1;
else B[i]:=A[j], j:=j+1;
end{if}
i:=i+1;
end{while}
if h>mid then
//当第一子组元素被取尽,而第二组元素未被取尽时
for k from j to high do
B[i]:=A[k]; i:=i+1;
end{for}
else
//当第二子组元素被取尽,而第一组元素未被取尽时
for k from h to mid do
B[i]:=A[k]; i:=i+1;
end{for}
end{if}
//将临时数组 B 中元素再赋给数组 A
for k from low to high do
A[k]:=B[k];
end{for}
end{Merge}
可见,归并排序由分解与合并两部分组成,整个过程可用两棵树表示出来(参见
本章附页“归并排序树”)。如果用 T(n)表示归并排序所用的时间,并假定合并


第三章 分治算法
54
过程所用时间与 n 成正比:cn,其中 c 是一个正数,则有

+
=
= 2 ( / 2) 1
1
( ) T n cn n
an
T n (3.2.1)
其中, a 是一个常数。若 n 是 2 的方幂: k
n = 2 ,直接推导可得
an cn n
T kcn
T n cn
T n T n cn cn
k
log
2 (1)
4 ( / 4) 2
( ) 2(2 ( / 4) / 2)
=+
=+
=+
= ++

对于一般的整数 n ,我们可以假定 1
22
kk
n+
  ,于是,由 1
(2 ( ) (2 )
kk
T Tn T +
)  ,
得 T (n) = O(n log n) 。
⚫ 以比较为基础的排序时间的下界
类似于估计以比较为基础的搜索算法的时间下界,也可以用树来模拟以比
较为基础的排序算法,在此我们考虑最坏情况下的时间下限,并假定数组中的元
素互不相同。在树的内部结点上,算法执行一次比较,并根据比较的结果移向它
的某一个子结点。由于每两个元素 A[i]和 A[j]的比较只有两种可能:A[i]<A[j]
或 A[j]<A[i],所以这颗树是二叉树。当 A[i]<A[j]时进入左分支,当 A[j]<A[i]
进入右分支。各个叶结点表示算法终止。从根到叶结点的每一条路径与一种唯一
的排列相对应。由于 n 个不同元素的不同排列共有 n!个,因此比较树有 n!个
外部结点(参看本章附页“排序比较树”)。直接观察可知,由根到外结点路径即
描述了该外结点所代表的排列生成过程,路径的长度即是经历的比较次数。因此,
比较树中最长路径的长度(其是比较树的高)即是算法在最坏情况下所做的比较
次数。要求出所有以比较为基础的排序算法在最坏情况下的时间下界,只需求出
这些算法所对应的比较树的最小高度。如果比较树的高是 k,则该二叉树的外结
点至多是 2k 个。于是, n! 2k 。注意到
! ( 1) ( / 2) ( / 2) / 2−1
−  n
n n n  n n (3.2.2)
因而
k  (n / 2 −1)log(n / 2) = (nlog n) (3.2.3)
T (n)  (nlog n) ,即 (nlog n) 是以比较为基础的排序算法在最坏情况下的时间
下界。


第三章 分治算法 55
从上式看出,归并排序是时间复杂度最低的排序算法(以比较为基础)。然
而,仔细观察可以发现,归并排序有两个地方值得商榷:一是分解直到只有一个
元素。事实上,当元素比较少时,直接进行排序,比如用插入排序算法,比起进
一步分拆、合并手续要快得多。因为,在这种情况下,大量的时间都花在调用分
解、合并函数上。所以,在归并排序算法中,对于归并起点的规模 应该有适当
的限制,即加 Small(p,q)判断。二是辅助数组 B 的借用,虽然不可避免,但应
该采用另一种方式,以避免数组 A 中的元素的频繁换位。为此,我们可以采用链
表(该表中存储的是数组元素的下标),将数组 A 中的元素位置变动转化成链表
值的变化。例如
LINK:
假定前 4 个已经排好,后 4 个也已经排好,链表如上,头指针分别是 2,5。
下面是在此基础上将两个排好的子链表连接起来的过程。
q=2; r=5
A[2]<A[5]: LINK[0]:=2; k:=i(=2); i:=LINK[i](=3);
A[3]>A[5]: LINK[k]:=5; k:=j(=5); j:=LINK[j](=7);
A[3]<A[7]: LINK[k]:=3; k:=i(=3); i:=LINK[i](=4);
A[4]<A[7]: LINK[k]:=4; k:=i(=4); i:=LINK[i](=1);
A[1]>A[7]: LINK[k]:=7; k:=j(=7); j:=LINK[7](=8);
A[1]<A[8]: LINK[k]:=8; k:=i(=1); i:=LINK[i](=0);
k:=j(=8); j:=LINK[j](=6)
k:=j(=6); j:=LINK[j](=0)
程序
 k=0  k =2
位置 (0) (1) (2) (3) (4) (5) (6) (7) (8)
数据 50 10 25 30 15 70 35 55
指针 2 0 3 4 1 7 0 8 6
k: →2→5→3→4→7→1→8→6
if A[i]A[j] then
LINK[k]:=i; k:=i; i:=LINK[i];
else
LINK[k]:=j; k:=j; j:=LINK[j];
end{if}
i=2 i=4
Q = ( 10, 25, 30, 50 )
j=5
R = ( 15, 35, 55, 70 )
指针移动过程 一般规则


第三章 分治算法
56
3-2-6 使用链接的归并排序算法
MergeSortL(low, high, p) // Link 是全程数组 A[low..high]
//的下标表, p 指示这个表的开始处。利用 Link 将 A 按非降顺序排列。
global A[low..high]; Link[low..high];
if high-low+1<16 then //设定子问题的最小规模 Small
InSort(A,Link, low,high,p);
else mid:=(low+high)/2;
MergeSortL(low,mid,q); //返回 q 表
MergeSortL(mid+1,high,r); //返回 r 表
MergeL(q,r,p); 将表 q 和 r 合并成表 p
end{if}
end{MergeSortL}
其中,合并程序 MergeL 是合并函数 Merge 的改进:
程序 3-2-7 使用连接表的合并程序
MergeL(q,r,p) // 由链接表 q 和 r 构造新的连接表。p、q、r 是
//全程数组 Link[0..n]中两个表指针,这两个链表指出被划分的
//两个子组的地址排序,而 p 指针指出两组归并后的地址排序。
global n,A[1..n], Link[0..n];
local integer i, j, k;
i:=q; j:=r; k:=0; // 初始化,新表在 Link[0]处开始
while i0 and j0 do //当两个表皆非空时
if A[i]A[j] then
Link[k]:=i; k:=i; i:=Link[i]; //加一个新元素到此表
else Link[k]:=j; k:=j; j:=Link[j];
end{if}
end{while}
if i=0 then
Link[k]:=j;
else Link[k]:=i;
end{if}
p:=Link[0];
end{MergeL}


第三章 分治算法 57
例 3.2.1 考虑将数组 A=[50,10,25,30,15,70,35,55]按非降次序排列问题,
采用改进的归并算法。这里主要说明链接表在合并函数 MergeL 被调用时的变化
过程(参看本章附页“归并链接表”)。
⚫ 快速排序算法
另一个利用分治法排序的例子是快速排序,是由计算机科学家 C.A.R.Hoare
提出的。基本策略是:将数组 A[1..n]分解成两个子数组 B[1..p]和 B[p+1..n],
使得 B[1..p]中的元素均不大于 B[p+1..n]中的元素,然后分别对这里的两个数
组中的元素进行排序(非降的),最后再把两个排好序的数组接起来即可。一般
的分解是从 A 中选定一个元素,然后将 A 中的所有元素同这个元素比较,小于或
等于这个元素的放在一个子组里,大于这个元素的放在另一个子组里。这个过程
叫做划分。
程序 3-2-8 划分程序伪代码
Partition(m,p) // 被划分的数组是 A[m,p-1],
//选定做划分元素的是 v:=A[m]。
integer m, p, i;
global A[m ..p-1];
v:=A[m]; i:=m;
loop
loop i:=i+1; until A[i]>v; end{loop} //自左向右查
loop p:=p-1; until A[p]v; end{loop} //自右向左查
if i<p then
Swap(A[i],A[p]); //交换 A[i]和 A[p]的位置
else go to *;
end{if}
end{loop}
*: A[m]:=A[p]; A[p]:= v; // 划分元素在位置 p
end{Partition}
例 3.2.2 划分程序的执行情况: m=1, p=10 的情形
原数组: 65 70 75 80 85 60 55 50 45 (+∞)被划分成: (60,
45, 50, 55) , 65, ( 85, 80, 75, 70) (参看本章附页划分程序执行过程)。


第三章 分治算法
58
程序 3-2-9 快速排序算法伪代码
QuickSort(p,q) //将数组 A[1..n]中的元素 A[p], A[p+1],  , A[q]
//按不降次序排列,并假定 A[n+1]是一个确定数,且大于 A[1..n]中所
// 有的数。
integer p,q;
global n, A[1..n];
if p<q then
j:=q+1; Partition(p,j); // 划分后 j 成为划分元素的位置
QuickSort(p,j-1);
QuickSort(j+1,q);
end{if}
end{QuickSort}
由前面关于以比较为基础的排序算法在最坏情况下的时间下界可知,快速
排序算法在最坏情况下的时间复杂度应不低于 (nlog n) 。事实上,在快速算法
中元素比较的次数,在最坏情况下是 O(n2) 。这是因为,在 Partition(m,p)的每
一次调用中,元素的比较次数是 p-m.把 QuickSort 过程按照划分来分层,则第
一层只调用 Partition 一次,即 Partition(1,n+1),涉及的元素为 n 个; 在第
二层调用 Partition 两次,所涉及到的元素是 n-1 个,因为在第一层被选定的划
分元素不在其中。若用 Nk 表示第 k 层调用 Partition 时所涉及的元素总个数,
则 Nkn-k+1。这样在第 k 层调用 Partition 时发生的元素比较次数应不大于 n-k.
注意到 1kn,因此 QuickSort 算法在最坏情况下总的元素比较次数不超过
n(n-1)/2,即 QuickSort 最坏情况下的时间复杂度为 O(n2) 。
为了得到时间复杂性的平均值,我们不妨假设
1. 参加排序的 n 个元素互不相同;
2. Partition 中的划分元素 v 是随机选取的。
以 CA(n)记时间复杂性的平均值。在上述假设条件下,调用 Partition(m,p)时,
所取划分元素 v 是 A[m, p-1]中第 i(1ip-m)小元素具有相等的概率,因而留下
待排序的两个子组为 A[m..j-1]和 A[j+1..p-1]的概率是 1/(p-m),mjp-1。由
此得递归关系式
( ( 1) ( ))
1
() 1
1
Ck Cnk
n
Cn n A A
kn
A = − +  − + −
(3.2.4)
其 中 , n −1 是 Partition 第 一 次 被 调 用 时 所 需 要 的 元 素 比 较 次 数 ,


第三章 分治算法 59
CA(0) = CA(1) = 0 。将(3.2.4)式两端乘以 n 得
nCA (n) = n(n − 1) + 2(CA (0) + CA (1) +  + CA (n − 1)) (3.2.5)
用 n-1 替换(3.2.5)中的 n 得
(n − 1)CA (n − 1) = (n − 1)(n − 2) + 2(CA (0) + CA (1) +  + CA (n − 2)) (3.2.6)
再用(3.2.5)减去(3.2.6)式得
Cn n n
nn
n
Cn n Cn n
A
AA
( 1) / 2 /
( 1)
2( 1)
( ) /( 1) ( 1) /
 −+
+
−
+ = − + (3.2.7)
由递推关系式(3.2.7),并注意到 CA(0) = CA(1) = 0 ,得


+ +
in
CA n n CA i
2
( ) /( 1) (1) / 2 2 1/ (3.2.8)
利用积分不等式
1
2
1/ ln
n
in
dx
in
x

=

得 CA (n)  2(n + 1) ln n = O(n log n)
看来快速排序与归并排序具有相同的平均时间复杂性。但是在实际表现中
却是有所不同的。实验表明,快速排序一般要比归并排序效率更高些(参看《数
据结构、算法与应用》,Sartaj Sahni 著,汪诗林 孙晓东 译 p.457)。
关于排序的算法我们已经接触了 5 种:冒泡排序、插入排序、选择排序、
归并排序和快速排序,它们的时间复杂性列出如下:
算 法 最坏复杂性 平均复杂性
冒泡排序 n2 n2
插入排序 n2 n2
选择排序 n2 n2
快速排序 n2 n log n
归并排序 n log n n log n


第三章 分治算法
60
§3.选 择 问 题
问题:已知 n 元数组 A[1..n],试确定其中第 k 小的元素。
最容易想到的算法是采用一种排序算法先将数组按不降的次序排好,然后
从排好序的数组中捡出第 k 个元素。这样的算法在最坏情况下时间复杂度是
O(n log n) 。实际上,我们可以设计出在最坏情况下的时间复杂度为 O(n) 的算法。
为此,考察上节提到的算法 Partition。假设在一次划分中,划分元素 v 处于第
j 个位置。如果 k<j,则要找的第 k 小元素在新数组 A[1..j-1]中,而且是 A[1..j-1]
的第 k 小元素;如果 k=j,则划分元素 v 即是要找的第 k 小元素;如果 k>j,则
要找的第 k 小元素在新数组 A[j+1..n]中,而且是 A[j+1..n]的第 k-j 小元素。
程序 3-3-1 采用划分的选择算法
PartSelect(A, n, k) //在数组 A[1..n]中找第 k 小元素 t,并将其存
//放于位置 k,即 A[k]=t。而剩下的元素按着以 t 为划分元素的划分
//规则存放。再令 A[n+1]=+∞.
integer n, k, m, r, j;
m:=1; r:=n+1; A[n+1]:= +∞;
loop
j:=r;
Partition(m,j);
case
k=j : return // 返回 j,当前数组的元素 A[j]是第 j 小元素
k<j : r:=j; // j 是新的下标上界
else : m:=j+1; //j+1 是新的下标下界
end{case}
end{loop}
end{PartSelect}
(参看本章附页 PartSelect 程序的执行过程)
这个算法在最坏情况下的时间复杂度是 2
O(n ) 。事实上,假定数组 A[1..n]
中的元素互不相同,而且假定划分元素是随机选取的。注意,在每次调用
Partition(m, j)都要耗去 O( j − m) 的时间。而下一次被划分的数组的元素个数
至少比上一次减少 1。因而,从最初的划分中 m=1, j=n+1 开始,至多需要做 n-1
次划分。第一次划分,耗去时间至多为 n,第二次耗去时间至多是 n-1,... .所以,


第三章 分治算法 61
PartSelect 在最坏情况下的时间复杂度为 2
O(n ) 。但是,可以推出,PartSelect
的平均时间复杂度为 O(n) 。事实上,我们可以改进 PartSelect 算法,通过精心
挑选划分元素 v,得到在最坏情况下的时间复杂度为 O(n) 的算法。
程序 3-3-2 改进的选择算法伪代码
Select(A, m, p, k) // 返回一个 i 值,使得 A[i]是 A[m..p]中第
// k 小元素。r 是一个大于 1 的整数。
global r;
integer n, i, j;
if p-m+1r then
InSort(A, m, p);
return(m+k-1);
end{if}
loop
n:=p-m+1;
for i to n/r do //计算中间值
InSort(A, m+(i-1)*r, m+i*r-1);
//将中间值收集到 A[m..p]的前部:
Swap(A[m+i-1], A[m+(i-1)*r+r/2-1]);
end{for}
j:=Select(A, m, m+n/r-1, n/r/2);
Swap(A[m], A[j]); //产生划分元素
j:=p+1;
Partition(m, j);
case:
j-m+1=k : return(j);
j-m+1>k : p:=j-1;
else m:=j+1;
end{case}
end{loop}
end{Select}
这里,程序 Select 只在划分元素的选取上做了改进,其余部分沿用
PartSelect 的步骤。划分元素的选取方案是:取定正整数 r(>1),将原始数组按
r 个元素一段的原则分成n/r段(可能剩余 n-r*n/r个元素)。对每一段求取中


第三章 分治算法
62
间元素,并把这n/r个中间元素搜集在数组 A[m..p]的前部(免去另开空间收存
的操作)。现在调用程序
Select(A, m, m+n/r-1, n/r/2),
就产生了所要的划分元素。因为n/r一定小于 n,这样的递归过程是可行的。为
了直接应用程序 PartSelect,将刚刚找到的划分元素放在数组 A[m..p]的首位。
我们以 r=5 来分析 Select 算法的时间复杂性。假设数组 A 中的元素都是互
不相同的。由于每个具有 5 个元素的数组的中间值 u 是该数组的第 3 小元素,此
数组至少有 3 个元素不大于 u;n/5个中间值中至少有n/5/2个不大于这些中
间值的中间值 v。因而,在数组 A 中至少有
3*n/5/2  1.5*n/5
个元素不大于 v。换句话说,A 中至多有
n-1.5*n/5= n-1.5*(n/5-e/5)  0.7n+1.2
个元素大于 v。同理,至多有 0.7n+1.2 个元素小于 v。这样,以 v 为划分元素所
产生的新的数组至多有 0.7n+1.2 个元素。当 n24 时,0.7n+1.20.75n=3n/4。
注意到程序 Select 中,从一层到下一层递归时,实际上相当于两次调用了
Select:一次体现在语句
j:=Select(A, m, m+n/r-1, n/r/2);
另一次体现在 Partition(m, j)及后面的 case 语句组,其关键操作为(n)次。主
程序接着就要调用自身,执行规模不超过 3n/4 的选择问题。这两步涉及的数组
规模分别是 n/5 和  3n/4。程序中其它执行步的时间复杂度都至多是 n 的倍数。
如果用 T(n)表示算法在数组长度为 n 的时间复杂度,则当 n24 时,有递归关系
T (n)  T (n / 5) + T (3n / 4) + cn (3.3.1)
其中 c 是常数。从递推关系式(3.3.1)出发,用数学归纳法可以证明
T (n)  20cn (3.3.2)
所以,在最坏情况下,Select 算法的时间复杂度是 O(n) 。
§4.关于矩阵乘法
假定 A, B 都是 n×n 矩阵,它们的 i 行 j 列交叉处的元素分别记为 A(i,j)
和 B(i,j)。如果用 S 和 C 分别记 A+B 和 A*B, 则有
Ci j Ai k Bk j i j n
S i j Ai j Bi j i j n
n
k
= 
= + 

=
( , ) ( , )* ( , ) 1 ,
(, ) (, ) (, ) 1 ,
1
(3.4.1)


第三章 分治算法 63
可见,矩阵加法运算的时间复杂度是 (n2 ) ,而矩阵乘法的时间复杂度是 (n3) 。
后者是因为求每个元素 C(i, j) 都需要 n 次乘法和 n-1 次加法运算,而 C 共有 n2 个
元素。
如果用分治法解决矩阵的乘法问题,可以设想将矩阵分块,然后用分块矩阵
乘法完成原矩阵的乘法运算。不妨假定 n 是 2 的方幂, k
n = 2 ,将矩阵 A 和 B 等
分成四块,于是

 
 = 
 
 
 
=
21 22
11 12
21 22
11 12
21 22
11 12
* CC
CC
BB
BB
AA
AA
AB
其中
21 21 11 22 21 22 21 12 22 22
11 11 11 12 21 12 11 12 12 22
C AB AB C AB AB
C AB AB C AB AB
=+ =+
= + = + (3.4.2)
如果用 T(n)记两个 n 阶矩阵相乘所用的时间,则有如下递归关系式:

+

= 8 ( / 2) 2
2
( ) T n dn2 n
bn
T n (3.4.3)
这是因为在计算 C 的块 Cij 时,需要计算 8 次 n/2 阶矩阵的乘法计算和 4 次 n/2
阶矩阵的加法计算,后者需要 2
dn 加法运算,这里 d 是一个常数。直接递推关系
式(3.4.3)得
T (n) = bn3 / 8 + 4d(n2 −16) / 3
因为 b  0 ,所以T (n) = (n3) 。
虽然没有降低时间复 杂度,但给我们一个 启示。 1969 年,斯 特拉森
(V.Strassen)发现了降低矩阵乘法时间复杂度的可能性。注意到,计算矩阵的加
法比计算乘法的时间复杂度具有较低的阶 (n2 : n3) ,而在用分块矩阵乘法时,既
有矩阵加法又有矩阵乘法。如果能通过增加加法次数来减少乘法次数,则可能达
到降低矩阵乘法的时间复杂度的目的。为此他设计了一个算法用以计算(3.4.2)
式中的 Cij,共用了 7 次乘法和 18 次加(减)法。令
11 22 11 22 11 12 22
21 22 11 21 11 11 12
11 12 22 12 22 21 22
22 21 11
( )( ), ( )
( ) , ( )( )
( ), ( )( )
()
P A A B B T A AB
Q A AB U A A B B
R AB B V A A B B
S AB B
=+ + =+
=+ =− +
= − =− +
=−
(3.4.4)


第三章 分治算法
64
则
C P RQU
C QS
C RT
C PSTV
=+−+
=+
=+
= +−+
22
21
12
11
(3.4.5)
由此得到的递推关系式为

+

= 7 ( / 2) 2
2
( ) T n an2 n
bn
T n (3.4.6)
直接推导可得
()
() ()
( 2.81 )
log7 2
log 7
4
log 7
2
log
log 2
2 2 21
3
4
21 7
16
37
4
21
16
7
37
4
4
7
21
16
( ) (1 7 / 4 (7 / 4) (7 / 4) ) 7 (2)
n
an
n
ab
n
b
an n
b
an
T n an T
n
n
kk
=
−



= +
 +


= −
 +




−




=
= + + + + −+ −

(3.4.7)
从所得的结果看出,Strassen 算法的时间复杂度依赖于 2×2 矩阵的乘法运算所
使用的乘法数。然而 Hoperoft 和 Kerr 在 1971 年已经证明:计算 2×2 矩阵的乘
积,7 次乘法是必要的。因而,降低矩阵乘法运算的时间复杂度应改用其它分块
的阶数,如采用 3×3 或 5×5 的块等。目前已知的最低的时间复杂度是 O(n2.36 ) 。
而目前所知道的矩阵乘法的最好下界仍是它的平凡下界 (n2 ) 。因此,到目前为
止还无法确切知道矩阵乘法的时间复杂性。
Strassen 矩阵乘法采用的技巧也可以用于计算大整数的乘积。参看《计算
机算法设计与分析》-王晓东编著,电子工业出版社,2001。
§5 快速 Fourier 变换
连续函数 a(t) 的 Fourier 变换
2
( ) ( ) ift
A f a t e dt


−
=


第三章 分治算法 65
A( f ) 的逆变换为
2
1
() ( )
2
ift
a t A f e dt


−
−
=
N 个数据 0 1 1
(,, , )
N
a a a a−
= 的离散 Fourier 变换
2/
01
,0
ijk N jk kN
A ae j N

 −
= 

其逆变换为
2/
01
1 ,0
ijk N kj jN
a Ae k N
N
−
 −
= 

这里,i 是虚数单位,N 是正整数。如果令 2 i/ N
e
= ,则是复数域上的 N
次本原单位根,此时,计算 Aj 相当于求多项式
01
() k
k kN
ax ax
 −
=
在j
 处的值。根据 Horner 法则,需要做 2(N −1) 次加法和乘法运算,因而,N 个
数据的离散 Fourier 变换需要做 2N (N −1) 次复数的加法和乘法运算。但是,我们
可以设计一个分治算法,其时间复杂度为 O(N log N ) 。
首先,若是 N = 2n 次本原单位根,则 2
 是 n 次本原单位根,而且,
, 0,1, , 1
j n j j n
+ =− = − 。
将多项式 a(x) 的奇次项和偶次项分开,则
( )( )
2 2( 1) 2 2( 1) 1 3 2 1 0 2 2( 1)
22
()
() ()
nn nn
ax a ax a x x a ax a x
bx x cx
−− −−
= + ++ + + ++
=+
于是,
22
22
() ( ) ( )
( ) () ()
j jj j
jn j j j
ab c
ab c
  
  
+
=+
=− +
, j = 0,1, , n −1
其中,
21 1 3 21
1 0 2 2( 1)
()
()
n n
n n
by a ay a y
cy a ay a y
− −
− −
=+ ++
=+ ++
这样,求 N = 2n 个数据的 Fourier 变换就归结为求两次具有 n 个数据的 Fourier 变 换。


第三章 分治算法
66
程序 3-5-1 快速 Fourier 变换 FFT(N, a,w,A)
# N=2m,w 是 n 次单位根,a 是已知的 N 元数组,代表多项式 a(x)的系数,
# A 是计算出来的 N 元数组,A[j]=a(wj), A[j]=a(-wj),j=0,1,...,N-1. real b[ ], c[ ]; int j; complex B[ ], C[ ], wp[ ]; if N=1 then A[0]:=a[0]; else
n:=N/2;
for j from 0 to n-1 do
b[j]:=a[2*j+1]; c[j]:=a[2*j]; end{for} end{if}
FFT(n,b,w*w,B); FFT(n,c,w*w,C); wp[0]:=1;
for j from 0 to n-1 do wp[j+1]:=w*wp[j]; A[j]:= C[j]+B[j]*wp[j]; A[j+n]:= C[j]-B[j]*wp[j]; end{for} end{FFT}
以T (N ) 记算法 FFT 的时间复杂度,则
, if 1
( ) 2 ( / 2) ,if 1
aN
T N T N cN N
=
=  + 

所以,算法的复杂度为T (N ) = O(N log N ) 。
利用快速 Fourier 变换可以计算出两个多项式 f (x), g(x) 的乘积,其时间复杂
度为T (N ) = O(N log N ) ,这里 N 是两个多项式的次数之和加 1。这可以分三步完
成:第一步,采用 Fourier 变换计算出 f (x), g(x) 在 j 2 ij/ N
e
 = 处的值 ( ), ( )
jj
f  g ,
j = 0,1, , N −1 , 这 需 要 O(N log N ) 的 计 算 量 ; 第 二 步 , 构 造 N 个 数 据
0 0 11 1 1
( ) ( ), ( ) ( ), , ( ) ( )
NN
A f  g f  g f  g
−−

=   ,它们实际上是乘积多项式
a(x) = f (x)g(x) 在 j 2 ij / N
e
 = , j = 0,1, , N −1,处的值,这步需要 O(N ) 的计算
量 ; 第 三 步 , 利 用 Fourier 变 换 的 逆 变 换 求 出 乘 积 多 项 式 的 系 数
, 0,1, , 1
ak k = N − ,这需要执行一次快速 Fourier 变换 FFT 即可,只不过那里的


第三章 分治算法 67
取为 2 i / N
e−  ,因而,这一步需要 O(N log N ) 的计算量。
需要指出的是,快速 Fourier 变换需要本原单位根,被变换的数据的个数是
2m
N = ,在复数域中任何 N 次本原单位根都是存在的,复数 2 i/ N
e
= 就是一个。
但是计算机对复数的计算是近似的,因此,快速 Fourier 变换得到近似结果。象 多项式乘积这样的问题(比如有理系数多项式)需要精确计算,这时我们需要能 够进行精确计算的本原单位根,这需要我们考虑一般交换环上的本原单位根。
定义 3.5.1 设 R 是一个有单位元的交换环, n 是正整数, R ,
1)称为一个 n 次单位根,如果 1
n
= ;
2)称为一个 n 次本原单位根,如果是 R 的可逆元,是一个 n 次单位根,
但对于 n 的任何素因子 p , / 1
np
 − 都不是环 R 的零因子。
n 次本原单位根具有如下性质:
I. 对于任何正整数 0  l  n , 1
l − 都不是零因子;
II.
0
0
lj
jn


=
 , l = 0,1, , n −1;
III. 如果是 n 次本原单位根,则 1
− 也是;
IV. 如果是 n = 2m 次本原单位根,则 2
 是 m 次本原单位根,而且
, 0,1, , 1
j m j j m
+ =− = − 。
根据上述 4 条性质,我们有一般形式的 Fourier 变换和逆变换,快速 Fourier 变换, 及应用 Fourier 变换设计求解其它问题的快速算法。
§6 最接近点对问题
已知空间中的 n 个点,如何找到最近的两个点即为最近点对问题。在直线
上,最近点对问题可以通过一次排序和 1 维扫描来解决,这样做最好的时间复杂
度为 O(n log n) 。实际上,可以设计一个分治算法来解决直线上的最近点对问题。
程序 3-6-1 求一维最近点对距离分治算法
ClosPair1(S,d)
//S 是实轴上点的集合,参数 d 表示 S 中最近点对的距离
global S,d;
integer n;


第三章 分治算法
68
float m,p,q;
n:=|S|;
if n<2 then d:=; return(false); end{if}
m:=S 中各点坐标的中位数;
//划分集合 S
S1:={xS| xm}; S2:={xS| x>m};
ClosPair1(S1,d1);
ClosPair1(S2,d2);
p:=max(S1); q:=min(S2);
d:=min(d1,d2,q-p);
return(true);
end{ClosPair1}
以 T(n)记算法的时间复杂度,则有如下的递归关系式
(1), 4;
( ) 2 ( / 2) ( ), 4
On
T n T n On n

=  + 

因为求中位数的时间复杂度可为 O(n) 。
上述解决一维最近点对问题的分治算法可以推广解决二维最近点对问题。这
里有两个地方需要加工:
一是集合的划分,因为两个坐标,我们只能选取一个坐标作为划分的参考,
比如选择集合 S 中各点的 x 坐标的中位数作为划分的标准
1: { | ( ) }, 2 : { | ( ) }
xx
S = pS x p m S = pS x p m
二是假设 S1, S 2 中最近点对的距离分别是 1 2
d , d ,令 1 2
d = min{d , d },而且 d 不
是 S 中最近点对的距离,则 S 中最近的点对 ( p, q) 的两个点应该分布在 S1, S 2 两
个集合中,譬如 1 2
p  S , q  S 。与一维的情形不同,为找到这样的点对 ( p, q) ,需
要比照的点对有许多,最坏情况下会有 n2 / 4 对。为此,需要通过分析缩小检查
的范围。取定 S1 中一点 p ,则 S2 中使得点对 ( p, q) 的距离不超过 d 的点 q 应该在
下面的集合中
{ | () , ( ) () ( ) }
p xx
S = qS m  x q m +d y p −d  y q  y p +d
S p 处在一个 d  2d 的矩形区域中。因为 S p 中任意两点的距离都不小于 d ,所以,


第三章 分治算法 69
S p 中至多有 6 个点。事实上,我们可以将这个矩形区域均分成 6 个子区域:纵
向三等分,水平方向二等分,则每个区域中两点间的距离不超过:
22
(d / 2) + (2d / 3) = 5d / 6 ,因而,每个区域中至多有 S p 的一个点。这样,为找
到最近的点对 ( p, q) ,其中 1 2
p  S , q  S ,只需检查至多 6 n / 2 = 3n + 6

  个点对。
根据以上分析,可以设计一个分治算法,求解平面上最近点对问题。
程序 3-6-2 求一维最近点对距离分治算法
ClosPair2(S,d)
//S 是平面上点的集合,但是已经按照 y − 坐标不降的次序排好,假定不同
//点的 x − 坐标是不同的。参数 d 表示 S 中最近点对的距离,dist(p,q)表示
//点对(p,q)之间的距离。
global S,d;
integer n;
float m,p,q;
n:=|S|;
if n<2 then d:=; return(false); end{if}
mx:=S 中各点 x − 坐标的中位数;
//划分集合 S 成 S1 和 S2,它们中的点也都是按 y − 坐标不降地排列。
S1:={pS| x(p)mx}; S2:={qS| x(q)>mx};
ClosPair2(S1,d1);
ClosPair2(S2,d2);
dm:=min{d1,d2}; d:=dm;
//检查距离直线 x=mx 不远于 dm 的两个条形区域中的点对
P1:={pS1|mx-dmx(p)}; P2:={qS2| x(q)mx+dm};
flag:=1;
for i to |P1| do
k:=flag;
while y(P2[k])<y(P1[i])-dm do
k:=k+1;
end{while}
flag:=k;
for j from flag to |P2| do


第三章 分治算法
70
if y(P2[j])>y(P1[i])+dm then break;
else d:=min{d,dist(p,P2[j])};
end{if}
end{for}
end{for}
return(true);
end{ClosPair2}
分析这个算法的时间复杂度,假定为 T(n)。集合 S 划分成集合 S1 和 S2 只
需要对集合 S 进行一次扫描即可,复杂度为(n)次操作;程序本身的两次自调
用复杂度为 2T(n/2);形成集合 P1 和 P2 的复杂度为(n);在外部的 for 循环中
包含两部分,while 循环和一个内部 for 循环。while 循环总的循环次数不会超
过 n,因而复杂度为(n);每个内部 for 循环的循环次数不会超过 6,而外部循
环次数不超过 n / 2
  ,故所有的内部 for 循环的循环次数总起来不超过 3n+6。程
序的其它操作总起来都是常数,因而,
,4
( ) 2 ( / 2) , 4
an
T n T n cn n

  + 

其中, c 为正实数。据此可解出T (n) = O(n log n) 。
习题 三
1. 编写程序实现归并排序算法 MergeSortL 和快速排序算法 QuickSort;
2. 用长分别为 10000、30000、50000、80000、100000、200000 的 6 个数组
(可用机器随机产生)的排列来统计这两种算法的时间复杂性;
3.讨论归并排序算法 MergeSort 的空间复杂性。
4.说明算法 PartSelect 的平均时间复杂性为 O(n) 。
提示:假定数组中的元素各不相同,且第一次划分时划分元素 v 是第 i 小元
素的概率为1/ n 。因为 Partition 中的 case 语句所要求的时间都是 O(n) ,所以,
存在常数 c ,使得算法 PartSelect 的平均时间复杂度 ( )
k
CA n 可以表示为
1
1
( ) ( ) ( 1)
k ki k A AA ik kin
C n cn C n i C i
n
−
 

 + −+ −


  (1)
令 ( ) max( ( ))
k A
k
R n = C n ,取 c  R(1) ,试证明 R(n)  4cn 。


第三章 分治算法 71
附页
归并排序的 C++语言描述
#include<iostream.h>
template<class T>void MergeSort(T a[],int left,int right);
template<class T>void Merge(T c[],T d[], int l,int m,int r);
template<class T>void Copy(T a[],T b[],int l,int r);
void main()
{
int const n(5);
int a[n];
cout<<"Input "<<n<<"numbers please:";
for(int i=0;i<n;i++)
cin>>a[i];
//for(int j=0;j<n;j++)
//b[j]=a[j];
MergeSort(a,0,n-1);
cout<<"The sorted array is"<<endl;
for(i=0;i<n;i++)
cout<<a[i];
cout<<endl;
}
template<class T>
void MergeSort(T a[],int left,int right) //
{
if(left<right)
{
int i=(left+right)/2;
T *b=new T[];
MergeSort(a,left,i);
MergeSort(a,i+1,right);
Merge(a,b,left,i,right);
Copy(a,b,left,right);
}


第三章 分治算法
72
}
template<class T>
void Merge(T c[],T d[],int l,int m,int r)
{
int i=l;
int j=m+1;
int k=l;
while((i<=m)&&(j<=r))
{
if(c[i]<=c[j])d[k++]=c[i++];
else d[k++]=c[j++];
}
if(i>m)
{
for(int q=j;q<=r;q++)
d[k++]=c[q];
}
else
for(int q=i;q<=m;q++)
d[k++]=c[q];
}
template<class T>
void Copy(T a[],T b[], int l,int r)
{
for(int i=l;i<=r;i++)
a[i]=b[i];
}
快速排序的 C++语言描述
#include<iostream.h>
template<class T>void QuickSort(T a[],int p,int r);


第三章 分治算法 73
template<class T>int Partition(T a[],int p,int r);
void main()
{
int const n(5);
int a[n];
cout<<"Input "<<n<<"numbers please:";
for(int i=0;i<n;i++)
cin>>a[i];
QuickSort(a,0,n-1);
cout<<"The sorted array is"<<endl;
for(i=0;i<n;i++)
cout<<a[i]<<" ";
cout<<endl;
}
template<class T>
void QuickSort(T a[],int p,int r)
{
if(p<r)
{
int q=Partition(a,p,r);
QuickSort(a,p,q-1);
QuickSort(a,q+1,r);
}
}
template<class T>
int Partition(T a[],int p,int r)
{
int i=p,j=r+1;
T x=a[p];
while(true)
{
while(a[++i]<x);
while(a[--j]>x);


第三章 分治算法
74
if(i>=j)break;
Swap(a[i],a[j]);
}
a[p]=a[j];
a[j]=x;
return j;
}
template<class T>
inline void Swap(T &s,T &t)
{
T temp=s;
s=t;
t=temp;
}


第三章 分治算法 75
附页:PartSelect 程序的执行过程
数组 A[1:9]=[65,70,75,80,85,60,55,50,45] 的划分过程
60 45 50 55 65 85 80 75 70 +
(1) (2) (3) (4) (5) (6) (7) (8) (9) (10) i p
65 70 75 80 85 60 55 50 45 + 2 9
65 45 50 80 85 60 55 75 70 + 4 7
65 45 50 55 85 60 80 75 70 + 5 6
6>5
65 45 50 55 60 85 80 75 70 + 1 5
65 45 75 80 85 60 55 50 70 + 3 8


第三章 分治算法
76
例子, 数组 A[1:9]=[65,70,75,80,85,60,55,50,45],求第 7 小元素
(1) (2) (3) (4) (5) (6) (7) (8) (9) (10) i p
60 45 50 55 65 85 80 75 70 + 10 9
Partition(1,10)
j=5
Partition(6,10)
j=9
60 45 50 55 65 70 80 75 85 + 7 6
Partition(6,9)
j=6
60 45 50 55 65 70 80 75 85 + 9 8
Partition(7,9)
j=8
Partition(7,8)
j=7 60 45 50 55 65 70 75 80 85 + 8 7


第三章 分治算法 77
(含有 10 个元素数组的)MergeSort 调用(分拆)过程
Merge 调用(合并)过程
1,1,2
6,8,10
1,2,3 4,4,5 6,7,8 9,9,10
1,3,5
1,5,10
6,6,7
4:5
1:10
1:5
9:10
6:10
1:3 6:;8
7:7
1:2 3:3 4:4 6:7 8:8
6:6
5:5
1:1 2:2
9:9 10:10
附页:归并排序树


第三章 分治算法
78
A = [ 5 0 , 1 0 , 2 5 , 3 0 , 1 5 , 7 0 , 3 5 , 5 5 ] 数据表
(0) , (1) , (2) , (3) , (4) , (5) , (6) , (7) , (8)
Link=[ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] 初始化为零,逐步修改
qrp
1>2→ 2 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 [10,50]
3<4→ 3 , 0 , 1 , 4 , 0 , 0 , 0 , 0 , 0 [10,50], [25,30]
2<3→ 2 , 0 , 3 , 4 , 1 , 0 , 0 , 0 , 0 [10,25,30,50]
5<6→ 5 , 0 , 3 , 4 , 1 , 6 , 0 , 0 , 0 [10,25,30,50],[15,70]
7<8→7, 0, 3 , 4 , 1 , 6 , 0 , 8, 0 [10,25,30,50],[15,70],[35,55]
5<7→5, 0, 3 , 4 , 1 , 7 , 0 , 8, 6 [10,25,30,50],[15, 35,55,70]
2<5→2, 8 , 5 , 4 , 7 , 3 , 0 , 1, 6 [10, 15,25,30, 35,50, 55,70]
1:8
1:4
1:4
1:1
3:4
2:2 3:3 4:4
5:8
5:6
5:5
7:8
6:6 7:7 8:8
MergeSort 调用(分 拆)过程
链 表 的 归 并 过 程
附页:链表归并过程


第三章 分治算法 79
附页:排序比较树
4321
1:2
2:3
2:3
3:4
3:4
4:1
3:4
3:1
3:4
4:1
4:2 4:2
1:3
4:1
1:4
3:1
3:1
1234
4123
1423 1243
3412
1342 3142 3124 1324
4312
1432 4132
2134
2314 2341
4213 4231
2143
2431
4:1
1:4 4:2 4:2
1:3 3:1
2413
3214
3421 3241
N=4 时的一棵比较树 另一棵比较树


第四章 贪心算法
80
第四章 贪心算法
§1.贪心算法基本思想
找零钱 假如售货员需要找给小孩 67 美分的零钱。现在,售货员手中只有
25 美分、10 美分、5 美分和 1 美分的硬币。在小孩的催促下,售货员想尽快将
钱找给小孩。她的做法是:先找不大于 67 美分的最大硬币 25 美分硬币,再找不
大于 67-25=42 美分的最大硬币 25 美分硬币,再找不大于 42-25=17 美分的
最大硬币 10 美分硬币,再找不大于 17-10=7 美分的最大硬币 5 美分硬币,最
后售货员再找出两个 1 美分的硬币。至此,售货员共找给小孩 6 枚硬币。售货员
的原则是拿尽可能少的硬币找给小孩。
装载问题 有一艘大船用来装载货物。假设有 n 个货箱,它们的体积相同,
重量分别是 1 2
, , ,n
w w w ,货船的最大载重量是 c。目标是在船上装更多个数的货
箱该怎样装?当然,最简单的做法是“捡重量轻的箱子先往上装”,这是一种贪
心的想法。如果用 xi = 1 表示装第 i 个货箱,而 xi = 0 表示不装第 i 个货箱,则上
述问题是解优化问题:
求 x1, x2 ,, xn ,使得

=
n
i
xi
1
max (4.1.1)
满足条件
1
w , 0,1
n
ii i i
xcx
=
=
 (4.1.2)
贪心算法,顾名思义,是在决策中总是做出在当前看来是最好的选择。例
如找零钱问题中,售货员每捡一个硬币都想着使自己手中的钱尽快达到需要找钱
的总数。在装载问题中,每装一个货箱都想着在不超重的前提下让船装更多的箱
子。但是贪心方法并未考虑整体最优,它所做出的选择只是在某种意义上的局部
最优。当然,在采用贪心算法时未必不希望结果是整体最优的。事实上,有相当
一部分问题,采用贪心算法能够达到整体最优,如前面的找零钱问题以及后面将
要讲到的单点源最短路径问题、最小生成树问题、工件排序问题等。为了更好理
解贪心算法,我们将装载问题稍加推广,考虑可分割的背包问题。
背包问题 已知容量为 M 的背包和 n 件物品。第 i 件物品的重量为 wi ,价值
是 pi 。因而将物品 i 的一部分 xi 放进背包即获得 pi xi 的价值。问题是:怎样装包
使所获得的价值最大?即是如下的优化问题:


第四章 贪心算法 81

in
pi xi
1
max (4.1.3)
x p w in
wx M
i ii
in
ii
    



0 1, 0, 0, 1
1 (4.1.4)
采用贪心算法,有几种贪心准则可循:a)每次捡最轻的物品装;b)每次
捡价值最大的物品装;c)每次装包时既考虑物品的重量又考虑物品的价值,也
就是说,每次捡单位价值 pi wi 最大的物品装。按原则 a)来装只考虑到多装些物
品,但由于单位价值未必高,总价值可能达不到最大;按原则 b)来装,每次选
择的价值最大,但同时也可能占用了较大的空间,装的物品少,未必能够达到总
价值最大。比较合理的原则是 c)。事实上,按照原则 c)来装,确实能够达到总
价值最大。
程序 4-1-1 背包问题贪心算法
GreedyKnapsack (p, w, M, x, n) //价值数组 p[1..n]、重量数组 w[1..n],
//它们元素的排列顺序满足 p[i]/w[i]≥p[i+1]/w[i+1]; M 是背包容量,
// x 是解向量
float p[1..n], w[1..n], x[1..n], M, rc;
integer i, n;
x:= 0; // 将解向量初始化为零
rc:= M; // 背包的剩余容量初始化为 M
for i to n do
if w[i]  rc then
x[i]:=1; rc:=rc-w[i];
else break;
end{if}
end{for}
if in then
x[i]:=rc/w[i];
end{if}
end{GreedyKnapsack}
定理 4.1.1 如果 p[1]/ w[1]  p[2]/ w[2]    p[n]/ w[n] ,则 GreedyKnapsack
对于给定的背包问题实例产生一个最优解。
证明 设 x = (x1, x2 ,, xn ) 是 GreedyKnapsack 所生成的解,但不是最优解。


第四章 贪心算法
82
因而必有某个 xi 不为 1。不妨设 x j 是第一个这样的分量。于是,当1  i  j 时,
xi = 1;当 i = j 时,0  xi  1;当 j  i  n 时,xi = 0 ,而且 wi xi = M
 。因为 x 不
是最优解,必存在可行解 y = ( y1, y2 ,, yn ) ,使得  pi yi   pi xi 。设 k 是使得
yk  xk 的最小下标,则 yk< xk. 这是因为,当 k  j 时, xk = 1 ,不等式自然成立;
当 k  j 时,若 xk<yk,则由 x1 = y1,, xk−1 = yk−1, xk+1 = 0, xn = 0 ,可推出
11
1 11
k nk
i i k k i i ii kk i ik i
wy w y wy wx w x
−−
= =+ =
++  +=
  1
n
ii i
wx M
=
=

y 不是可行解,矛盾。
因 y 是比 x 更优的解,不失一般性,可以假定 w y M
n
i
i i=

=1
。于是
kk
k
i
ii
n
ik
kk ii
k
i
 wi yi + w y +  w y =  w x + w x
−
=+ =
−
=
1
11
1
1
1
11
nk
ii ii kk ik i
wx wx w x
−
=+ =
+ +
 。
再由 yk  xk 有 ( ) 0
1
 −

=+
kk k
n
ik
wi yi w x y 。现在取新的向量 z = (z1, z2 ,, zn ) 满足
11 1 1
,, ,
k kk k
zy z yzx
−−
= = = , 0  zk+1  yk+1,,0  zn  yn ,
( )( )
1
kk k k in
wi yi − zi = w z − y

+
这样的向量 z 是可以取到的,而且是背包问题的可行解,因为
wy M
wy wy
wz wy w z wz
in
ii
kin
ii ik
ii
k in
kk ii ik
ii in
ii
=
=+
= ++


 

 − 
  − +
1
11
1 11 1
以下证明可行解 z 的总价值不小于 y 的总价值:
11 1
( ) / ( )/
ii i i k k k k k i i i i i in in k in
pz py z y w p w y z wp w
  +
= +− − −
 
11
1
( ) () /
ii k k k i i i k k in k in
ii in
py z y w y z w p w
py
 +


 +− − −


=




第四章 贪心算法 83
中间的不等式是由于当 i  k 时有 p[k]/ w[k]  p[i]/ w[i]而得。但是 z 与 x 的第一个
不同分量的位置比 y 与 x 的第一个不同的分量的位置至少向后推迟了一个。以 z
代替 y 进行上面的讨论,我们又可以找到新的解向量 z' ,如此等等,由于分量的
个数 n 有限,这样的过程必到某一步停止,最后找到解向量 y *,它和 x 有相同的
分量,但是,比 x 有更大的目标值,矛盾。 ▋
贪心算法主要用于处理优化问题。每个优化问题都是由目标函数和约束条
件组成。满足约束条件的解称为可行解,而那些使得目标函数取得最大(最小)
值的可行解称为最优解。如背包问题是一个优化问题,式(4.1.3)中的函数是目
标函数,而(4.1.4)式描述的要求是约束条件,这里优化是使目标函数取最大值。
贪心算法在每一步的决策中虽然没有完全顾及到问题整体最优,但在局部
择优中是朝着整体最优的方向发展的。为此,贪心算法首先要确定一个度量准则
(称为贪心准则),每一步都是按这个准则选取优化方案。如背包问题的贪心准
则是选取单位价值p/w最大物品;而装载问题的贪心的准则是选取最轻的货箱;
找零钱问题所用的贪心准则是选取面值最大的硬币。对于一个给定的问题,初看
起来,往往有若干种贪心准则可选,但在实际上,其中的多数都不能使贪心算法
达到问题的最优解。如背包问题的下面实例:
n=3, M=20, p=(25, 24, 15), w=(18,15,10)
如果以价值最大为贪心准则,则贪心算法的执行过程是:首先考虑将物品 1 装包,
此时获得效益值 25,包的剩余容量是 2。然后考虑将物品 2 装包,但物品 2 的重
量 15 超出包的剩余容量,只能装入该种物品的 2/15,此时获得的总效益值为
25+24×2/15=28.2。
这样得到的可行解(1,2/15,0)并不是最优解。
事实上,如果以单位价值最大为贪心准则,则贪心算法的执行过程是:先
计算出各个物品的单位价值(25/18, 24/15, 15/10)=(1.389, 1.6, 1.5)。首先
考虑单位价值大的物品装包,即将物品 2 装包,此时获得效益值 24,背包的剩
余容量是 5。然后考虑装物品 3,由于物品 3 的重量超出背包的剩余容量,只能
装入该物品 5/10 =1/2, 至此背包已经装满,所得的总的效益值为 24+15/2=31.5。
比前面的装法的效益值大。实践证明,选择能产生最优解的贪心准则是设计贪心
算法的核心问题。以下给出贪心算法流程的伪代码。
程序 4-1-2 贪心算法抽象化控制流程
Greedy(A, n) // A[1:n]代表那个输入
solution={}; //解向量初始化为空集


第四章 贪心算法
84
for i to n do
x:=Select(A);
if Feasible(solution, x) then
solution:=Union(solution, x);
end{if}
end{for}
return(solution);
end{Greedy}
这里 Select(A)是按照贪心准则选取 A 中的输入项;Feasible(solution, x)
是判断已知的解的部分 solution 与新选取的 x 的结合 Union(solution, x)是否
是可行解。过程 Greedy 描述了用贪心策略设计算法的主要工作和基本控制流程。
一旦给出一个特定的问题,就可将 Select,Feasible 和 Union 具体化并付诸实
现。
§2. 调度问题
⚫ 活动安排问题
我们首先从活动安排这一简单问题入手。该问题要求高效安排一系列争用某
一公共资源的活动。贪心算法提供了一个简单、漂亮的方法使得尽可能多的活动
能够兼容地使用公共资源。
问题:已知 n 个活动 E={1, 2, ... ,n},要求使用同一资源,第 k 个活动
要求的开始和结束时间为 sk, fk, 其中 sk <fk, k=1, 2, ... , n .活动 k 与活动 j
称为相容的如果 sk >fj 或者 sj >fk。活动安排问题就是要在所给的活动集合中选
出最大(活动个数最多)的相容活动子集(集合中任何两个活动都相容)。
解决这个问题的基本思路是在安排时应该将结束时间早的活动尽量往前安
排,好给后面的活动安排留出更多的时间,从而达到安排最多活动的目的。据此,
贪心准则应当是:在未安排的活动中挑选结束时间最早的活动安排。在贪心算法
中,将各项活动的开始时间和结束时间分别用两个数组 s 和 f 存储,并使得数组
中元素的顺序按结束时间非降排列:f1 f2... fn。
算法 4-2-1 活动安排贪心算法伪代码
GreedyAction(s, f,n) // s[1..n]、f[1..n]分别代表 n 项活动的
//起始时间和结束时间, 并且满足 f[1] f[2]... f[n]
j:=1; solution:={1}; //解向量初始化
for i from 2 to n do


第四章 贪心算法 85
if sifj then
solution:=solution  {i}; // 将 j 加入解中
j:=i;
end{if}
end{for}
return(solution);
end{GreedyAction}
例 4.2.1 待安排的 11 个活动的开始时间和结束时间按结束时间的非减次
序排列如下:
表 1 一个作业安排表
k 1 2 3 4 5 6 7 8 9 10 11
s[k] 1 3 0 5 3 5 6 8 8 2 12
f[k] 4 5 6 7 8 9 10 11 12 13 14
解集合为 {1,4,8,11}.容易证明算法 GreedyAction 所得到的解是最优解。
⚫ 带期限的单机作业调度问题
为使问题简化,我们假定完成每项作业所用的时间都是一样的,如都是 1。
带期限的单机作业安排问题陈述如下:
已知 n 项作业 E={1, 2, ... ,n},要求使用同台机器完成(该台机器在同一
时刻至多进行一个作业),而且每项作业需要的时间都是 1。第 k 项作业要求在
时刻 fk 之前完成, 而且完成这项作业将获得效益 pk,k=1, 2, ... , n 。作业集
E 的子集称为相容的,如果其中的作业可以被安排由一台机器完成。带限期单机
作业安排问题就是要在所给的作业集合中选出总效益值最大的相容子集。
这个问题可以考虑用贪心算法求解。容易想到贪心准则应该是:尽量选取
效益值大的作业优先安排。
用两个数组 f 和 p 分别存放作业的期限值和效益值,并使得数组 p 中元素按照不
增的顺序排列。按照上述贪心准则,算法由前向后逐个考察各个作业是否可以加
入到可行解集 J 中。J 初始为空集,按照相容性要求,作业 i 可以加入 J 只要当
前解集 J 中期限值不大于 fi 的作业少于 fi 个。由该算法取得的解集 J 具有性质:
若作业 k 不属于 J,则 J 中恰有 fk 个期限不超过 fk、而效益值不小于 pk 的作业。
该算法在程序 4-2-2 中实现。可以证明算法 GreedyJob 获得的解集是带期限单机
作业调度问题的最优解。下面的伪代码给出带期限作业调度问题贪心算法的概略


第四章 贪心算法
86
描述,其中没有给出相容性检验的具体步骤。
程序 4-2-2 带限期作业调度的贪心算法(概略)
GreedyJob(f, p, n) //f[1..n]和 p[1..n]分别代表各项作业的
//限期和效益值,而且 n 项作业的排序满足:p1  p2  ...  pn
local J;
J:={1};//初始化解集
for i from 2 to n do
if J  {i} 中的作业是相容的 then //此步验证需要认真设计
J:= J  {i}; // 将 i 加入解中
end{if}
end{for}
end{GreedyJob}
定理 4.2.1 算法 GreedyJob 对于单机作业调度问题总是得到最优解。
证明:假设贪心算法所选择的作业集 J 不是最优解,则一定有相容作业集
I,其产生更大的效益值。假定 I 是具有最大效益值的相容作业集中使得|IJ|
最大者,往证 I = J 。
反证法:若 I = J 不成立,则这两个作业集 I 和 J 之间没有包含关系。这是
因为算法 GreedyJob 的特性和假定 I 产生的效益值比 J 的效益值更大。假设 a
是 J\I 中具有最大效益的作业,即 J 中比 a 具有更大效益的作业(如果有的话)
都应该在 I 中。如果作业 b  I \ J 且 b a
p  p ,那么由算法中对 J 中作业的选取办
法(相容性要求), J 中至少有 fb 个效益值  pb 的作业,其期限值  fb 。这些作
业一定在 I 中,因而 I 中至少有 1
fb + 个作业,其期限值  fb ,这与 I 的相容性矛
盾。所以, I \ J 中作业的效益值均不超过 pa 。
称区间[k −1, k] 为时间片 k ,相容作业集 I 的一个调度表就是指定 I 中各个
作业的加工时间片。如果 I 有一个调度表 S 将 fa 时刻前的时间片安排的都是
I  J 中的作业,且 I \ J 中最早被安排的是作业 b ,在时间片 k 上,则 a
k  f 。前
k −1个时间片上安排的都是 J 中的作业,这些作业的集 A1再添上作业 a 得到 J 中
k 个作业。由作业集 J 的相容性, A1中至少有一个作业其期限值  k 。将这个作


第四章 贪心算法 87
业与作业 b 交换安排的时间片,得到新的调度表 S1 。如果在调度表 S1 中作业 b 安
排在时间片 k1 , 1 a
k  f ,则同理,可以将作业 b 再向前移,得到新的调度表 S2 。
如此做下去,必得到 I 的调度表 S ' ,其在 fa 时刻前的时间片安排有 I \ J 中作业 b 。
令 I ' = (I \{b}) {a},则 I ' 也是相容的作业集。而且,由于 b a
p  p , I ' 的效益总
值不小于 I 的效益总值,因而 I ' 具有最大的效益总值,但| I ' J || I  J | ,与 I 的
选取相悖。因而, J = I , J 是最优解。 ▋
算法 GreedyJob 能够找到达到最大效益值的相容作业集,若按照作业期限
的先后排序,就产生一个作业调度表。可以在算法中添加建立调度表的步骤:把
被选中的作业安排在其期限允许的、而且期限晚于它的已安排作业之前的时间片
上。如果用 J(r)表示安排在第 r 个时间片上的解集 J 中的作业,D(i)表示作业 i
的期限值,则相容性条件要求 D(J(r))r。根据上面分析,可以如下设计算法:
首先将作业 1 存入解数组 J 中,然后依次处理作业 2 到作业 n。假设已经处
理了前 i-1 个作业,其中有 k 个作业 J(1),...,J(k)被选入 J 中,对它们的安排
满足 D(J(1)) ... D(J(k))。为了检验作业集 J{i}的相容性,只需看能否找
到按期限的非降次序插入作业 i 的适当位置,即,使得作业 i 在此处插入后有
D(J(r))r , 1rk+1 。 找 插 入 位 置 可 以 将 作 业 i 与 J 中 作 业 依
D(J(k)),D(J(k-1)),...,D(J(1)) 的 次 序 逐 个 比 较 。 如 果 D(i)>D(J(j)) 或
D(i)=D(J(j))>j,则选取作业 i 并将作业 i 插到作业 J(j)后面的位置上;如果
D(i)D(J(j))且 D(J(j))=j,则此番查找插入位置结束,作业 i 不被选入。这样
得到的作业集是相容的,而且作业是按期限的非降次序安排的。程序 4-2-3 给出
了单机带期限作业调度贪心算法的伪代码。
程序 4-2-3 带期限作业调度问题贪心算法
GreedyJob(D,J,n,k)
//D(1),...,D(n)是期限值,作业已按 p1  p2  ...  pn 排序。J(i)是
//最优解中的第 i 个作业。终止时,D(J(i)) D(J(i+1)),1ik
integer D[0..n],J[0..n],i,k,n,r
D(0):=0; J(0):=0; //初始化
k:=1; J(1):=1; //计入作业 1,k 表示当前选择的作业个数
for i from 2 to n do
//按 p 的非增次序考虑作业,检查作业 i 可否被选入,并找出插入位置
r:=k;
while D(J(r))>D(i) and D(J(r))<>r do


第四章 贪心算法
88
r:=r-1;
end{while};
//期限不晚于 D(i)的作业个数小于 D(i)时
if D(J(r)) D(i) and D(i)>r then
for j from k to r+1 by –1 do //给作业 i 腾出位置
J(j+1):=J(j);
end{for};
J(r+1):=i; k:=k+1;
end{if};
end{for};
end{GreedyJob}
例 4.2.2 设 n=7, (p1, p2,... , pn)=(35,30,25,20,15,10,5),
(d1, d2,... ,dn)=(4,2,4,3,4,7,3),
算法 GreedyJob 的执行过程可描述如下:
作业 1; 2,1;2,1,3;2,4,1,3; 2,4,1,3,6;
期限值 4; 2,4;2,4,4;2,3,4,4; 2,3,4,4,7;
算法的关键操作是比较和相应移动作业的位置,都是围绕着判断作业集 J 
{i}的相容性。考察 J 外的作业 i 该加入 J 时,作业至多和 J 中的每个作业都比
较一次。因而,J  {i}的相容性判断最坏情况下需要|J|次比较。上述算法在
最坏情况下的时间复杂度为 2
O(n ) 。
为了避免上述算法反复移动作业的排序位置,可以考虑在算法中建立作业调
度表,而且采取“将作业尽量安排在期限允许的最后面空闲时间片上”的策略。
显然,所需要的时间片数不会超过 q:=min{n,max{D(i)|i=1,...,n}}。为了检验
作业集 J 添加作业 i 是否还是相容的,只需检查时刻 k:=min{n,D(i)}前面是否
还有空闲的时间片即可。例 4.2.2 按上述算法执行的情况如下:
作业 1; 2,1; 2,3,1; 4,2,3,1; 4,2,3,1,6;
期限值 4; 2,4; 2,4,4; 3,2,4,4; 3,2,4,4,8;
时间片 4; 2,4; 2,3,4; 1,2,3,4; 1,2,3,4,7;
其中,时间片 k 指区间[k-1,k]。
将时间片作为集合的元素,采用集合的并 Union 和查找 Find(参考附录“数
据结构”)技术实现上述算法,可使时间复杂度达到 O(m (n)) ,其中,m 是算


第四章 贪心算法 89
法执行 Find 和 Union 的次数,函数(n) 定义为

( ) min (1)
k
n = k A n
而 ()
Ap q 是修订的 Ackermann 函数:
( 1) 1
1, if 0
( ) ( ), if 1
q
p p
qp
Aq A q p
+ −
+=
=  

其中, ( )
1
i
Ap− 是函数 Ap−1 的 i 次方。直接推导可知, 80
A4 (1) 10 ,而且
4
0, for 0 2
1, for 3
( ) 2, for 4 7
3, for 8 2047
4, for 2048 (1)
n
n
nn
n
nA



=
=   

 



所以,在一般情况下(n)  4 ,因而,通常情况下,快速调度算法的时间复杂
度应该为 O(n) 。
程序 4-2-4 带期限作业调度快速算法
proc FastJob(D,J,n,q,k)
//找最优解 J=J(1),...,J(k).假定 p1 p2 ...  pn.
//q:=min{n,max{D(i)|i=1,2,...,n}}.
integer q,D(n),J(n),F(0..q),P(0..q)
for i from 0 to q do //将集合树置初值
F(i):=i; P(i):=-1;
end{for}
k:=0 //初始化
for i to n do //使用贪心规则
j:=Find(min{n,D(i)});
if F(j)0 then
k:=k+1; J(k):=i; //选择作业 i
s:=Find(F(j)-1); Union(s,j);
F(j):=F(s); P(s):=P(s)+P(j);
end{if}
end{for}
end{FastJob}


第四章 贪心算法
90
算法中 P(i)将作业链接到它的集合树上,同时指出该树上作业的个数。为了
便于描述算法,还引进了 0 时间片[-1,0]。例 4.2.2 的执行情况在本章附页“快
速作业调度算法”中描绘出来。
⚫ 多机调度问题
设有 n 项独立的作业{1,2,..., n},由 m 台相同的机器加工处理。作业 i 所需
要的处理时间为 ti。约定:任何一项作业可在任何一台机器上处理,但未完工前
不准中断处理;任何作业不能拆分更小的子作业分段处理。多机调度问题要求给
出一种调度方案,使所给的n个作业在尽可能短的时间内由m台机器处理完。
这是一个 NP 完全问题,到目前为止还没有一个有效的解法。利用贪心策略,
有时可以设计出较好的近似解。可以采用贪心准则:需要长时间处理的作业优先
处理。
例 4.2.3 设有 7 项独立的作业{1,2,3,4,5,6,7},要由三台机器 M1, M2 , M3
处理。各个作业所需要的处理时间分别为{2,14,4,16,6,5,3}.将作业标号按它们
所需时间的长短排列:[4, 2, 5, 6, 3, 7,1].首先将作业 4 安排给机器 M1 处理,
此时,机器 M1 被占用的时间是 16,而机器 M2 , M3 被占用的时间都是零,所以,
应将作业 2 安排给机器 M2 来处理,作业 5 应安排给机器 M3 来处理,至此,机器
M1, M2 , M3 被占用的时间分别是 16、14、6。接下去应安排作业 6,因为机器 M3
最早空闲,所以作业 6 应安排给机器 M3。此时,机器 M1, M2 , M3 分别在 16、14、
11 时刻开始空闲。所以下面将要安排的作业 3 安排给机器 M3。此时,机器 M1, M2 ,
M3 分别在 16、14、15 时刻开始空闲。即将安排的作业 7 应安排给机器 M2,此时,
机器 M1, M2 ,M3 分别在时刻 16、17、15 开始空闲。即将安排的作业 1 应安排给
机器 M3。如此全部作业均已安排完毕,所需要的时间是 17。这里采用的调度方
案是:
将需要时间最长的未被安排作业首先安排给能够最早空闲下来的机器处理。
下面的图描述了上述例子的算法执行过程。
机器 M1 16 所用时间
机器 M2 14+3 所用时间
机器 M3 6+5+4+2 所用时间
§3. 最优生成树问题
考虑无向图 G=(V, E),不妨假定该图代表城市间的交通情况,顶点代表城
市,边代表连接两个城市的可能的交通线路。现在将每条边赋予一个权值,这些
作业 2 7
作业 4
作业 5 6 3 1


第四章 贪心算法 91
权可以代表建造该条线路的成本、交通线的长度或其它信息,这样得到一个赋权
图。在实际问题中,人们往往希望在结构上选择一组交通线,它们连通所有的城
市并且具有最小的建造成本。这个问题相当于求取连通赋权图的具有最小权值的
生成树。我们称之为最优生成树。贪心方法可以很好地解决此类问题。在此介绍
两种算法:Prim 算法和 Kruskal 算法。
Prim 算法的基本思想:
1). 选择图 G 的一条权值最小的边 e1,形成一棵两点一边的子树;
2). 假设 G 的一棵子树 T 已经确定;
3). 选择 G 的不在 T 中的具有最小权值的边 e,使得 T{e}仍是 G 的一棵子
树。
Kruskal 算法的基本思想:
1). 选择图 G 的一条权值最小的边 e1;
2). 假设已经选好 G 的一组边 L={e1,e2,...,ek};
3). 选择 G 的不在 L 中的具有最小权值的边 ek+1,使得 L{ek+1}诱导出的 G
的子图不含 G 的圈。下面两个图给出 Prim 算法和 Kruskal 算法的最优生成树产
生过程。
12
45
6
3
10
20
30 40
50
25
35
55
45
15
1
2
3
5
4
(1,2)
(2,6)
(6,3)
(6,4)
(3,5)
Prim 算法
(1,2)
(6,3)
(6,4)
(6,2)
(5,3)
5
4
6
3
12
10
20
30 40
50
25
35
55
45
15
1
2
3
5
4
Kruskal 算法


第四章 贪心算法
92
程序 4-3-1 Prim 最小生成树算法
PrimTree(E,COST,n,T,mincost) //E 是图 G 的边集,COST 是 G 的带权
//邻接矩阵。计算一棵最小生成树 T 并把它作为一个集合存放到二维
//数组 T[1..n-1,1..2]中,这棵树的权值赋给 mincost
1 real COST[1..n,1..n],mincost;
2 integer NEAR[1..n],n,i,j,k,s,T[1..n-1,1..2];
3 (k,s):= 权值最小的边;
4 mincost:=COST[k,s];
5 (T[1,1],T[1,2]):=(k,s); //初始子树
6 for i to n do //将 NEAR 赋初值(关于初始子树 T)
7 if COST[i,s]<COST[i,k] then
8 NEAR(i)=s;
9 else NEAR(i)=k;
10 end{if}
11 end{for}
12 NEAR(k):=0,NEAR(s):=0;
13 for i from 2 to n-1 do //寻找 T 的其余 n-2 条边
14 choose an index j such that
NEAR(j)0 and COST[j,NEAR(j)] is of minimum value;
15 (T[i,1],T[i,2]):=(j,NEAR(j)); // 加入边(j,NEAR(j))
16 mincost:=mincost+COST[j,NEAR(j)];
17 NEAR(j):=0;
18 for t to n do //更新 NEAR(关于当前子树 T)
19 if NEAR(t)0 and COST[t,NEAR(t)]>COST[t,j] then
20 NEAR(t):=j;
21 end{if}
22 end{for}
23 end{for}
24 if mincost   then
25 print(‘no spanning tree’);
26 end{if}
27 end{PrimTree}
这里,树 T 的元素为(T[i,1],T[i,2]),其中 T[i,1],T[i,2]代表第 i 条边的两个
端点。NEAR(j)表示顶点 j 的以最小权的边邻接 T 的一个顶点。


第四章 贪心算法 93
PrimTree 算法的时间复杂度分析:
语句 3 需要 O(|E|)的时间;语句 6 至语句 11 的循环体需要时间为 O(n);
语句 18 至 22 的循环体需要时间 O(n);
语句 14 至 17 需要时间 O(n);
语句 13 至 23 的循环体共需要时间 O(n2)。
所以,PrimTree 算法的时间复杂度为 O(n2).
为叙述 Kruskal 算法,我们引进数据结构 min-堆:它是一个完全二叉树,
其中每个节点都有一个权值,而且该二叉树满足:每个节点的权值都不大于其儿
子的权值。min-堆的根具有最小的权值。
程序 4-3-2 Kruskal 最优生成树算法伪代码
KruskalTree(E,COST,n,T,mincost)//说明同算法 PrimTree
1 real mincost, COST[1..n,1..n];
2 integer Parent[1..n],T[1..n-1],n;
3 以带权的边为元素构造一个 min-堆;
4 Parent:=-1; //每个顶点都在不同的集合中;
5 i:= 0; mincost:= 0;
6 while i<n-1 and min-堆非空 do
7 从堆中删去最小权边(u,v)并重新构造 min-堆
8 j:= Find(u); k:= Find(v);
9 if jk then //保证不出现圈
10 i=:i+1; T[i,1]:=u; T[i,2]:=v;
11 mincost:=mincost+COST[u,v];
12 Union(j,k); //把两个子树联合起来
13 end{if}
14 end{while}
15 if in-1 then
16 print(‘no spanning tree’);
17 end{if}
18 return;
19 end{KruskalTree}


第四章 贪心算法
94
定理 4.3.1 Kruskal 算法对于每一个无向连通赋权图产生一棵最优树。
证明:设 T 是用 Kruskal 算法产生的 G 的一棵生成树,而 T’是 G 的一棵最
优生成树且使得|E(T)E(T)|最大。用 E(T)表示树 T 的边集,w(e)表示边 e 的
权 值 ,而边集 E 的权值之和用 w(E) 表示。以下证明 E(T))=E(T).反假设
E(T)E(T),因为|E(T)|=|E(T)|,所以 E(T)与 E(T)没有包含关系。设 e 是
E(T)\E(T)中权值最小的边。将 e 添加到 T中即得到 T的一个圈:e,e1 ,e2 ,...,ek。
因为 T 是树,诸 ei 中至少有一个不属于 E(T)。不妨设 ei 不属于 E(T),则必然有
w(e)w(ei)。否则,由 w(e)>w(ei)以及 E(T)中比 e 权值小的边都在 T中,ei 同这
些边一起不含有圈,因而,按 Kruskal 算法,ei 将被选到 E(T)中,矛盾。在 T
中去掉边 ei,换上边 e,得到 G 的一棵新的生成树 T,这棵树有两个特点:
a). T的权值不大于 T的权值,因而与 T有相等的权值;
b).|E(T)E(T)| > |E(T)E(T)|.
a)说明 T也是一棵最优生成树,而 b)说明与 T取法相悖。因此 E(T) = E(T),T
是最优生成树。 ▋
§4 单点源最短路径问题
问题:已知一个赋权有向图 G=(V,E,w),求由 G 中某个指定的顶点 v0 出发
到其它各个顶点的最短路径。
5
4
6
3
12
10
20
30 40
50
25
35
55
45
15
一个赋权图和它的
边的最小堆
(1,2)
(6,3) (6,4)
(6,2) (4,1) (5,3) (5,2)
(5,1) (3,2) (6,5)
10
15 20
25 30
35 40
0
50 55
45
45
50 10
35
30
30
20
15
10
20
15
V0
V2
V1 V4
V5
V3
路径 长度
(1) v0v2 10
(2) v0v2v3 25
(3) v0v2v3v1 45
(4) v0v4 45
从 v0 到其它各顶点的最短距离


第四章 贪心算法 95
对于一般的单点源最短路径问题,我们采用逐条构造最短路径的办法, 用
“迄今已生成的所有路径长度之和为最小”作为贪心准则,这要求,每一条已被
生成的单独路径都必须具有最小长度。假定已经构造了 k 条最短路径,则下面要
构造的路径应该是下一条最短长度的最短路径。现记这 k 条最短路径的终点之集
为 S,为陈述方便,也将 v0 放于 S 中。如果 V\S 不是空集,则从 v0 到 V\S 中顶点
的最短路径中应该有一条最短的,比如是 v0 到 vk+1 的最短路径 P:
P=v0u1...us-1usvk+1 (4.4.1)
显然,P1=v0u1...us-1us 应是 v0 到 us 的最短路径,因而由 S 的定义和选定的贪心准
则,us 应属于 S。同理,路径 P 上其它顶点 ui 也都在 S 中。所以,由 v0 出发的新
的最短路径一定是某个已有的最短路径向前延伸一步。如果用 Dist(vi)记从 v0
到 S 中顶点 vi 的最短路径的长度,而图 G 中的顶点 w 依其属于 S 与否分别记之
为 S(w)=1 或 S(w)=0,则从 v0 出发,新的最短路径的长度应该是
D(S ) = ( )m1,in( ) 0{Dist(u) COST (u, w)}
Su Sw +
==
(4.4.2)
满足(4.4.2)式的顶点 w 被选择加入 S,新的最短路径就是从 v0 出发到 w 的最短
路径,而此时的 Dist(w)=D(S),S 被更新为 S'= S {w},后者可以由更新 w 的(集
合)特征值来实现:S(w)=1(原来 S(w)=0).上述算法思想是 Dijkstra(迪杰斯特)
提出的。
程序 4-4-1 Dijkstra 最短路径算法伪代码
DijkstraPaths(v,COST,n,Dist,Parent)//G 是具有 n 个顶点
//{1,2,...,n}的有向图, v 是 G 中取定的顶点,COST 是 G 的邻接矩阵,
//Dist 表示 v 到各点的最短路径之长度,Parent 表示各顶点在最短路径
//上的前继。
bool S[1..n]; float COST[1..n,1..n],Dist[1..n];
integer u,v,n,num,i,w;
1 for i to n do //将集合 S 初始化为空
2 S[i]:=0; Parent[i]:=v; Dist[i]:=COST[v,i];
3 end{for}
4 S[v]:=1; Dist[v]:=0; Parent[v]:=-1;//首先将节点 v 记入 S
5 for i to n-1 do //确定由节点 v 出发的 n-1 条最短路
6 选取顶点 w 使得 Dist(w) S(mui)=n0{Dist(u)}
=
7 S[w]:=1;
8 while S[u]=0 do
//修改 v 通过 S 到达 S 以外的节点 u 的最小距离值


第四章 贪心算法
96
9 if Dist[u]> Dist[w]+COST[w,u] then
10 Dist[u]:=Dist[w]+COST[w,u];
11 Parent[u]:=w;
12 end{if}
13 end{while}
14 end{for}
15 End{DijkstraPath}
这里需要注意语句 6 和 10。根据(4.4.2)式,被选择的新的最短路径的长度应该
等于语句 6 中的 (mi)n0{Dist(u)}
Su=
,这可由语句 10 中的 Dist 值更新语句看出。假设
S 变成 S=S{w}后,下一次被选中的节点是 u,如果 Dist(u)在 S 变成 S=S{w}
后值发生了变化,则必然等于 Dist(w)+ COST(w,u)。事实上,假如在 w,u 的中
间还有顶点 p,使得 w 通过 p 到 u 的距离比 COST(w,u)还小,则 v 到 p 的距离必
然比 v 到 u 的距离更短,这与 u 被选中矛盾。所以,COST(w,u)是从 w 到 u 的最
短路径的长度,进而 Dist(w)+ COST(w,u)是 v 到 u 的最短路径长度。因此 S 变
成 S=S{w}后,S之外各顶点 Dist 值的更新采用
Dist(u)=min{Dist(u),Dist(w)+ COST(w,u)}
必将使下一步选点得到 v 到 S之外各顶点最短路径之最小的顶点,这保证了算法
DijstraPath 的正确性。对于每个不是 v 的顶点 u,可以通过回溯 Parent(u)得
到由 v 到达 u 的最短路径。
算法的时间复杂度为 2
O(n ) 。这是因为,在 for 循环中,求得元素 w 需要做
(n − i −1) 比较;而在 while 循环中考虑更新 Dist 的值时,也需要 (n − i −1) 操
作,因而总的操作次数应该是 2
O(n ) 。
所有由 v 到达各顶点的最短路径并起来构成图 G 的一棵生成树,称为单点源
1
234
5
6
7
8
55 45
25
5 40 20
30
50
15
10
35
1
234
5
6
7
8
55 45
5
30
15
10
赋权连通图 G G 的最优生成树 G 的一棵单点源
最短路径生成树
1
234
5
6
7
8
25
5 40 20
15
10
30
25


第四章 贪心算法 97
最短路径树。上页的图给出了一个连通赋权图 G 及它的两棵生成树:最优生成树
和单点源最短路径树。
§5 Huffman 编码
哈夫曼编码是用于数据文件压缩的一个十分有效的编码方法,其压缩率通
常在 20%~90%之间。哈夫曼编码算法使用字符在文件中出现的频率表来建立
一个 0,1 串,以表示各个字符的最优表示方式。下表给出的是具有 100,000 个字
符文件中出现的 6 个不同的字符的出现频率统计。
表 4-5-1 字符出现频率表
如果采用定长码,则每个字符至少需用三位,该文件总共需要 300,000 位;
如果采用上面所列变长码,则该文件需用
(45×1+13×3+12×3+16×3+9×4+5×4)×1000=224,000 位,
总码长减少了 25%。
一般的编码都是沿一个方向连续地写下 0,1 字串,比如从左到右、从上到下。
解码时也是以同样的方向逐字地搜索。为了使解码唯一,必须使用一个规则。前
缀码即是一种规则,它要求表示任何一个字符的 0,1 字串都不能是表示另一个字
符的 0,1 字串的前部。比如,若用 01 表示字符 a,则表示其它字符的字串不能
是具有形式:01...。
可以用一棵二叉树来表示前缀编码。用树叶代表给定的字符,并将给定字符
的前缀码看作是从树根到代表该字符的树叶的一条道路。代码中每一位的 0 或 1
分别作为指示某节点到左儿子或右儿子的“路标”。
在一般情况下,若 C 是编码字符集,则表示其最优前缀码的二叉树中恰有
|C| 个叶节点,每个叶节点对应于一个字符。这样的二叉树的每个不是叶的节点
恰有两个子节点,因而,该二叉树恰有 |C|-1 个内部节点。给定编码字符集 C
及其频率分布 f,即 C 中任一字符 c 以频率 f(c)在数据文件中出现。C 的一个前
缀编码方案对应于一棵二叉树 T。字符 c 在树中的深度记为 dT(c)。dT(c)也是字
符 c 的编码长度。该编码方案的平均码长定义为


=
cC
B(T ) f (c)dT (c) (4.5.1)
使平均码长达到最小的编码方案称为 C 的一个最优编码。
不同的字符 a b c d e f
频率(千次) 45 13 12 16 9 5
定长码 000 001 010 011 100 101
变长码 0 101 100 111 1101 1100